: Внедрение изменений, промышленность, бережливые изменения, lean change, ADKAR. Основные проблемы [1] внедрения изменений в организациях и предприятиях могут быть связаны со следующими аспектами: Отсутствие понимания необходимости изменений: люди часто не видят необходимости внедрения изменений [2] или считают, что текущие методы и процессы работают достаточно хорошо, чтобы не требовать изменений. Недостаток ресурсов: для реализации изменений может понадобиться дополнительное время, деньги и другие ресурсы. Компании могут столкнуться с проблемой нехватки ресурсов для успешной реализации планов. Сопротивление изменениям: люди часто боятся и не любят изменения, поэтому могут быть недовольными или несогласными с предлагаемыми изменениями. Однако, необходимость изменений может быть крайне важной для компании, поэтому сопр отивление может замедлить процесс и усложнить его реализацию. Ошибки при планировании [3]: недостаточно точное или неадекватное планирование может привести к неудачным результатам. Важно понимать, какие изменения необходимы, и разработать точный план дейст вий, чтобы добиться нужных результатов. Недостаточная коммуникация: недостаток коммуникации и связи между работниками может привести к непониманию целей и планов, что может затруднить процесс внедрения изменений. Недостаток лидерства [4]: нехватка руководс тва, отсутствие четкого плана действий и проблемы с координацией могут привести к неправильному распределению ресурсов и недостаточной поддержке изменений в организации. Сложности с привлечением и удержанием талантов: некоторые изменения могут требовать от компании новых навыков и компетенций, которые могут быть трудными для нахождения и удержания в компании. Управление изменениями (Change Management) это процесс планирования, координации, реализации и контроля изменений, связанных с бизнес процессами, те хнологиями, структурами и/или культурой организации. Управление изменениями  необходимо для того, чтобы организация могла адаптироваться к новым условиям, решать возникающие проблемы, повышать эффективность и качество своей деятельности. Процесс управления изменениями включает в себя следующие шаги: Определение изменения. В этом шаге необходимо определить, какое изменение необходимо внести, а также определить причину, цели и ожидаемые результаты изменения. Оценка изменения. В этом шаге необходимо проанализир овать влияние изменения на организацию, оценить возможные риски и выработать стратегию для минимизации этих рисков. Разработка плана изменений. В этом шаге необходимо разработать план, который будет описывать, как изменения будут внедряться, кто будет отве тственен за их внедрение и какие ресурсы будут необходимы для успешной реализации. Реализация изменений. В этом шаге необходимо провести практическую реализацию изменений, включая все необходимые технические и организационные мероприятия. Оценка результато в. В этом шаге необходимо оценить результаты изменений и сравнить их с ожидаемыми результатами. Если необходимо, то произвести корректировки. Контроль изменений. В этом шаге необходимо внедрить систему контроля за изменениями и отслеживать их воздействие н а организацию. Ключевые элементы успешного управления изменениями включают понимание необходимости изменений, вовлечение сотрудников, коммуникацию и обучение, планирование и оценку рисков, а также эффективное управление процессом изменений. Важно понимать, что управление изменениями это непрерывный процесс, который не заканчивается после внедрения изменений. Он должен включать систему контроля и оценки результатов, чтобы обеспечить успешное функционирование организации в условиях постоянно меняющейся внеш ней среды. Сопротивление изменениям является естественной реакцией большинства людей на новые ситуации, так как изменения могут вызывать страх, неопределённость, беспокойство и неудобства. Это может быть вызвано такими факторами, как: Неопределенность: Изм енения могут создавать неопределенность и неясность в будущем, что может вызвать у людей страх и тревогу. Привычка: Люди могут быть привыкли к существующему порядку и не хотят менять привычки, даже если они неэффективны. Контроль: Люди могут чувствовать п отерю контроля при изменениях, что может привести к беспокойству и неудобству. Необходимость усилий: Люди могут чувствовать, что изменения потребуют от них дополнительных усилий и времени, что может вызвать сопротивление. Негативный опыт: Предыдущий негати вный опыт с изменениями может вызвать у людей опасения и сопротивление новым изменениям. Для управления изменениями важно понимать причины сопротивления и принимать меры для преодоления этих препятствий. Это может включать такие действия, как обеспечение четкой и открытой коммуникации, вовлечение сотрудников в процесс изменений, предоставление обучения и поддержки, а также создание мотивации и вознаграждения за успешное внедрение изменений. Важно также иметь терпение и понимание, что изменения могут потреб овать времени для принятия и адаптации. Есть множество моделей управления изменениями. Сравним две из них: ADKAR и Lean change. ADKAR и бережливые изменения (Lean Change) являются двумя разными методологиями управления изменениями в организациях. ADKAR это методология, разработанная компанией Prosci [6], которая помогает организациям планировать и реализовывать изменения, учитывая пять этапов принятия изменений: осознание необходимости изменений, желание изменений, знание, умение и поддержка. Каждый этап ADKAR является необходимым условием для успешного принятия изменений в организации. Бережливые изменения, с другой стороны, основаны на методологии Lean, которая используется для улучшения производительности и эффективности организации. Бережливые изменен ия предлагают более гибкий и адаптивный подход к управлению изменениями, который включает в себя обратную связь и участие сотрудников в процессе изменений, что позволяет быстро определять и реагировать на изменения внутри и вне организации. Одно из отличий между ADKAR и бережливыми изменениями заключается в том, что ADKAR является более структурированной и последовательной методологией, в то время как бережливые изменения предлагают более гибкий и адаптивный подход к управлению изменениями. ADKAR более подх одит для организаций, которые требуют строгого контроля и документирования процесса управления изменениями, в то время как бережливые изменения лучше подходят для организаций, которые нуждаются в более гибком [6] и быстром реагировании на изменения внутри и вне организации. Однако, как и с любой методологией управления изменениями, обе подходы могут быть эффективными при правильном использовании и адаптации к конкретным потребностям и особенностям организации. 

: центр компетенций цифровых трансформаций, SMM , социальные сети, таргетированная реклама Annotation: This article analyzes the existing promotion of the services of the competence center for digital transformations, with a focus on the B2C segment of the market. The definition of SMM is given and the goals related to promotion are presented. An overview of the «VKontakte» social network is also provided and the steps for setting up targeted advertising are considered. The results of targeted advertising settings and their effectiveness are presented. Key words: competence center for digital transformations, SMM, social networks, targeted advertising Центр компетенций цифровых трансформаций входит в состав кафедры ИМ и предоставляет образовательные и консалтинговые услуги частным лицам, предприятиям и организациям [1]. В настоящее время продвижение ЦКЦТ выполняется совместными силами сотрудников кафедры ИМ и бюро аналитической наукометрии (БАН). ЦКЦТ не имеет независимой и выделенной маркетинговой службы. Сегодня при продвижении центра компетенций осуществляется лишь информирование об услугах центра. Не проводится сегментация, таргетирование и позиционирование услуг, а также не осуществляется оценка результатов продвижени я. В итоге размещенная информация не обеспечивает привлечение потенциальных партнеров, не нацелена на конкретных потребителей и лишена конкретных целей, а также неясно, будет ли она действительно полезна для продвижения центра компетенций. Главная цель пр одвижения услуг ЦКЦТ – установление деловых контактов и заключение договоров на НИР и консалтинговые услуги, а также договоров на обучение. Для обеспечения задач продвижения услуг ЦКЦТ прежде всего требуется определиться с типом рынка. В данной статье пре длагается реализовать работу по концепции B2C [2]. B2C (business to consumer) это сегмент бизнеса, в котором компании предлагают продукты и услуги непосредственно конечному потребителю. Основными каналами продвижения в B2C являются реклама в социальных с етях, поисковое продвижение сайта, email маркетинг. Основная цель продвижения в B2C – увеличение продаж и привлечение новых клиентов. В процессе продвижения в сегменте B2C не выполняются ряд мероприятий, связанных c маркетингом социальных сетей (SMM), что приводит к низкой осведомленности потенциальных клиентов. SMM – это комплекс мероприятий, направленных на продвижение продукта или услуги в социальных сетях. Основной целью SMM является увеличение узнаваемости бренда, привлечение новы х клиентов и удержание старых. SMM позволяет организовать более тесное взаимодействие с потенциальными клиентами, точечно настраивать рекламные кампании на определенную аудиторию, что повышает вероятность привлечения заинтересованных клиентов. Отсутствие продвижения услуг ЦКЦТ с использованием социальных сетей ограничивает охват целевой аудитории, что влечет за собой недостаток потенциальных партнеров и инвесторов. Ведь на сегодняшний день социальные сети являются одним из наиболее эффективных инструментов продвижения. Следует рассмотреть возможность использования каналов продвижения, таких как социальные сети, например, «ВКонтакте» [3]. «ВКонтакте» имеет несколько ключевых преимуществ, среди которых выделяется возможность создания сообществ для людей с общими интересами. Это по зволяет повысить узнаваемость и видимость бренда, а также поддерживать связь с аудиторией. Кроме того, на платформе «ВКонтакте» доступны инструменты для настройки таргетированной рекламы, которые позволяют выбирать аудиторию по различным параметрам, включа я возраст, пол, местоположение и интересы. Такой подход позволяет более эффективно использовать бюджет на рекламу, так как рекламные объявления будут показываться только тем пользователям, которые могут быть заинтересованы в продукте или услуге. Так же «ВК онтакте» предлагает удобный функционал для мобильных устройств и планшетов, а также комфортные сервисы для отслеживания статистики [4]. Таким образом, социальная сеть «ВКонтакте» выбрана для продвижения услуг ЦКЦТ, так как она обладает отличными рекламными инструментами, доступной ценой, удобным функционалом для мобильных устройств, и широкой аудиторией. Для настройки таргетированной рекламы во ВКонтакте необходимо выполнить следующие шаги: 1. Зайти в рекламный кабинет «ВКонтакте» и создать новую рекламную кам панию. Выбор целевого действия. Рисунок 1 – Начало настройки рекламы 2. Выбрать тип рекламного объявления, который наилучшим образом соответствует целям кампании (баннер, текстовое объявление, видео и т.д.). 3. Определить параметры целевой аудитории: возраст, пол, местоположение, интересы и другие параметры. Возможно использование готовых целевых аудиторий или создание своих. Рисунок 2 – Выбор региона показа Рисунок 3 – Выбор возраста и пола Рисунок 4 – Выбор интересов аудитории и ключевых фраз 4. Выбрат ь формат показа рекламы: в новостях, на боковой панели или в сообщениях. Рисунок 5 – Настройка размещения рекламы 5. Установить продолжительность кампании. Рисунок 6 – Продолжительность кампании 6. Создать и загрузить рекламный контент. Рисунок 7 – Пример рекламного контента 7. Запустить рекламную кампанию и отслеживать ее эффективность через статистику. Рисунок 8 – Предварительная статистика Кроме того, «ВКонтакте» предоставляет дополнительные инструменты для настройки таргетированной рекламы, такие как Lookalike аудитории, которые позволяют находить пользователей, похожих на уже существующих клиентов, и Retargeting, который позволяет направлять рекламу тем пользователям, которые уже проявляли интерес к вашему продукту или услуге. Важно также следить за э ффективностью таргетированной рекламы и вносить необходимые корректировки в параметры таргетирования, бюджет и контент, чтобы достичь наилучших результатов. 

: разработка чат бота, экспертные заключения, цифровая трансформация, образовательная организация. Annotation: The article considers the creation of a chat bot in the Telegram social network for working with expert opinions. An overview of existing methods for developing and creating bots, which are implemented both with the help of programming languages and No code development, is given. The selected method for the implementation of the task is disclosed, its advantages are described. The result of creating a chat bot by the selected method is shown, using the script as an example. Key words: chatbot development, expert opinions, digital transformation, educational organization. В настоящие время во многих российских образовательных организациях проводятся научные мероприятия среди студентов и сотрудников. Это несомненно требует большой объём работы с документами в организации. Для публикации статьи в сборники или участия в конференции необходимо пройти ряд организационных этапов: подписать статьи у всех авторов, подписать заключение у руководителя эксперта, подписать эксп ертное заключение в экспортном контроле. И в случае, если статья на английском языке, предварительно перевести её в центре международной академической мобильности, и предоставлять заверенный перевод с остальными документами на каждом из этапов. В данной ст атье будет рассмотрена проблема отслеживания состояний экспертных заключений в Санкт Петербургском Государственном Электротехническом Университете «ЛЭТИ» имени В. И. Ульянова (Ленина) (СПбГЭТУ «ЛЭТИ»). Данная проблема приводит к задержкам сбора статей на к онференциях, а также к дублированию заключений в случае их потери. Для решения этой проблемы одним из вариантов является разработка чат бота в социальной сети Телеграмм. Существует множество вариантов разработки чат ботов, разберём некоторые из них. 1. Гото вые боты и шаблоны Готовые боты – это готовые решения для конкретных задач. Готовые боты зачастую очень простые, без ветвления в сценарии и с несложной логикой. Простые решения могут проводить опросы, модерировать чаты, оформлять заказы, записать пользова телей на встречи или выдавать необходимую информацию по запросу. Основной плюс готовых решений – это скорость внедрения и небольшая работа по настройке. К минусам относятся узкая направленность, данный вариант неспособен реализовывать сложные функции и за частую ограничен количеством пользователей. Кроме того, при необходимости настроить готовый бот будет очень сложно за счёт отсутствия доступа к коду и возможности пользоваться визуальным редактором. Поэтому данный вариант не подходит для задачи по работе с экспертными заключениями. 2. Конструктор ботов. Конструктор ботов – это набор уже готовых «коробочных» решений, которые позволяют создавать ботов без навыков программирования и разработки. Конструкторы бывают no code , иначе называются визуальные конструктор ы, или low code .  В данном варианте разработчик может сам с помощью необходимых блоков расписать и построить сценарий работы с пользователем. Основным преимуществом конструктора выступает скорость создания бота, даже если бот будет с разветвлённым сценар ием на более, чем 100 блоков, это займёт гораздо меньше времени, чем разработка с нуля с помощью фреймворка. Также к преимуществам относится готовые интеграции с различными сервисами: чаты, мессенджеры,  C RM и инструменты аналитики, сервисы для рассылок. В зависимости от выбранного конструктора можно создавать разные типы ботов: чат бота, голосового помощника или бота для обзвона клиентов. С помощью различных инструментов в конструкторе можно отправлять изображения, писать по расписанию, осуществлять рас сылку, отправлять видео, запрашивать оплату. Кроме того, огромным преимуществом по сравнению с первым вариантом является возможность реализовывать HTTP запросы и вебхуки, математические операции и подсчеты во время диалога — все это возможно с помощью JS выражений, которые прописываются прямо в сценарии. Исходя из всех преимуществ, для реализации был выбран именно этот способ. 3. Диалоговые платформы Диалоговые платформы – набор решений для разработки и сопутствующих действий в жизненном цикле бота в одном окне. Работа в платформах рассчитана на пользователей, у которых уже есть опыт и навыки в разработке и команда. Основное отличие от конструкторов в том, что платформы отвечают за интеграции с внешними сервисами, такими как, собственные сервисы, подключаемые по API , CRM системы, любые каналы, собственные ASR и TTS, собственную BI систему. Платформы поддерживают разработку любого вида бота, но при это м на разработку одного уходит достаточно много времени. Среди самых распространённых решений выделяют:  Чат боты техподдержки, которые понимают естественную речь и переводят на оператора  Голосовые ассистенты  Виртуальные операторы для входящих и исходящих звонков, которые правильно реагируют на перебивание пользователем, вносят изменения в CRM систему и перезванивают по запросу. 4. Open source фреймворки Фреймворк – это набор инструментов с открытым исходным кодом высокой степенью контроля над разработкой. Основное отличие от диалоговых платформ в том, что фреймворки имеют открытый исходный код. Если в базовой версии отсутствуют нужные функции, интеграции или каналы, их можно добавить за дополнительную плату или разработать самостоятельно. Использование фре ймворка имеет смысл тогда, когда по какой то причине уже сформированы другие практики и сервисы внутри компании, которые решают задачи, которые не решала бы платформа. Таким образом, исходя из проведённого сравнения вариантов реализации бота, в рамках выс шего учебного заведения для бизнес процесса «работы с экспертными заключениями» наиболее подходящим вариантом является конструктор чат ботов. Рисунок 1. Общий сценарий бота в конструкторе Основываясь на его преимуществах, данный способ помогает реализовать бота без углублённых знаний языков программирования за относительно небольшой временной промежуток. Таким образом, в рамках статьи был создан чат бот по работе с экспертными заключениями (см. Рисунок 1). В визуальном сценарии бота стрелки показ ывают переходы от одного действия или сообщения к другому, что упрощает построение логики взаимодействий с пользователями. 

: технологическое предпринимательство, вызовы, возможности, бизнес процессы, качество, инновации, технологии, технологический предприниматель. Введение Существует в озможность повышения каче ства бизнес процессов, и это может привести к повышению эффективности и результативности компании. Для этого необходимо провест и анализ текущих бизнес процессов, выявить их слабые места и проблемы, а затем разработать и внедрить стратегии и методы для их оптимизации. Компании должны контролировать протекающие бизнес процессы , анализировать данные и получать обратную связь от своих клиентов и сотрудник ов, чтобы улучшать показатели управленческих решений и оставаться конкурентоспособными на рынке [1] . Выбор подхода для повышения качества бизнес процессов зависит от с пецифики компании. Наиболее распространенные из них включают: 1. Lea n подход методика устранения избыточных операций и ресурсов в бизнес процессах, что позволяет снизить издержки, повысить эффективность и ускорить время выполнения задач [ 6 ] . 2. Six Sigma методика, которая помогает устранять дефекты в бизнес процессах, снижать вариацию и улучшать качество продукции и услуг [3] . 3. Total Quality Management (TQM) это система управления, основанная на производстве качественной с точки зрения заказчика продукции и услуг [ 2 ] . 4. Бизнес процессный реинжиниринг (BPR) методика, которая позволяет пересмотреть и оптимизировать все бизнес процессы компании, начиная с нуля [ 4 ] . 5. Инновационные методы, такие как Design Thinking, Agile, Scrum, которые позволяют быстро прототипировать новые продукты и услуги и ускорить время их выхода на рынок [ 7 ] . 6. Использование информационных технологий, таких как программное обеспечение для управления бизнес процессами (BPM), которое позволяет автоматизировать, упростить и ускорить выполнение процессов в компании [ 5 ] . П еред тем как выбира ть конкретный подход , необходимо провести анализ текущих процес сов и определить, какой из них б удет наиболее эффективным . Метод исследования В данном исследовании буде рассмотрено технологическое предпринимательство, как один из инструментов осуществления подхода об использовании информационных технологий. Технологическое предпринимательство это создание и коммерциализация инновационных технологий, которые могут быть применены в различных областях бизнеса и промышленности. Технологические предприниматели это люди, которые используют свои  знания, навыки и опыт, чтобы разработать новые продукты или усовершенствовать существующие технологии. Целью исследования значится выявление механизмов, повышающих качество бизнес процессов и обоснование вызовов, с кото рыми может столкнуться компания, так как их также необходимо учитывать для дальнейшего формирования бизнес стратегии. Результаты исследования Одним из ключевых элементов успеха технологических стартапов является команда. Обычно она состоит из экспертов в своей области, которые обладают опытом в разработке и коммерциализации технологий, а также специалистов по продажам, маркетингу, финансам и другим областям, которые могут помочь компании успешно войти на рынок. Кроме того, для технологических стартапов важ на финансовая поддержка инвесторов, которые могут вложить средства в развитие компании и помочь ей выйти на новые рынки. Технологические предприниматели также могут получать поддержку от акселераторов и инкубаторов, которые помогают им развивать свои бизне с идеи и привлекать инвесторов. Технологическое предпринимательство может повысить качество бизнес процессов через следующие механизмы: 1. Создание новых продуктов и услуг. Технологические предприниматели могут создавать новые продукты и услуги, которые дают эксклюзивное конку рентное преимущество и позволяют без особых рисков и значительных маркетинговых расходов получить максимальную прибыль от реализации. 2. Ускорение экономического роста. Технологическое предпринимательство может стимулировать экономический рост, создавая новые рабочие места и стимулируя инвестиции. 3. Решение сложных проблем. Технологическое предпринимательство может помочь решить сложные проблемы , связанные с оптимизацией бизнес процессов в различных отраслях, таких как медици на, энергетика и окружающая среда. 4. Поддержка инноваций. Технологические предприниматели могут помочь поддержать инновации и содействовать развитию научных исследований за счет материальной составляющей . 5. Глобальный рынок. Технологическое предпринимате льство предоставляет возможности для выхода на глобальный рынок и привлечения международных инвесторов и клиентов , по средствам разработки уникальной стратегии, которая сопровождается от посевной стации до стадии выхода . Таким образом, технологическое пред принимательство может стать мощным инструментом для повышения качества бизнес процессов в компании. Технологическое предпринимательство имеет большой потенциал для создания новых рабочих мест, ускорения экономического роста и решения сложных проблем в разл ичных отраслях. Несмотря на достаточно положительные возможности , у технологического предпринимательства имеются и свои вызовы. Среди вызовов можно выделить: 1. Неопределенность спроса . Технологическое предпринимательство связано с высокой степенью неопределенности, что может привести к неудачам и потере времени и денег. 2. Высокий уровень финансового риска. Создание новой технологии или продукта часто связано с высокими затратами, что может привести к высокому уровню финансового риска . 3. Нехватка р есурсов. Технологические стартапы часто испытывают нехватку ресурсов, таких как финансы, время и экспертиза, что может затруднить развитие компании. 4. Конкуренция. Технологическое предпринимательство часто связано с высокой степенью конкуренции, особенно в отраслях с высокой степенью инноваций , так как технологическое предпринимательство находится в условиях быстрого развития технологий, что приводит к тому, что конкурентные преимущества одних компаний становятся устаревшими в течение короткого времени [ 8 ] . Выводы На основе исследования вызовов и возможностей в технологическом предпринимательстве для повышения качества бизнес процессов можно сделать следующие выводы: Технологическое предпринимательство может значительно повысить качество бизнес процессов, т ак как новые технологии и инновации могут значительно улучшить производительность и эффективность за счет следующих механизмов: создание новых продуктов и услуг; ускорение экономического роста; решение сложных проблем; поддержка инноваций и глобальный рыно к . Однако, для того чтобы успешно заниматься технологическим предпринимательством и повышать качество бизнес процессов, необходимо учитывать ряд вызовов, таких как высокие издержки на исследование и разработку новых технологий, неопределенность в отношении спроса на продукты и услуги, сложности в получении финансирования и другие. Существуют также возможности для технологического предпринимательства в повышении качества бизнес процессов, такие как доступ к глобальному рынку благодаря интернет технологиям, в озможность быстрой адаптации к изменяющимся рыночным условиям и возможность использования больших данных для повышения эффективности бизнес процессов. Для того чтобы успешно заниматься технологическим предпринимательством и повышать качество бизнес процесс ов, необходимо учитывать все вызовы и возможности и разрабатывать стратегию, которая поможет управлять рисками и максимизировать возможности. 

: Цифровая трансформация бизнеса, дополненная реальность, ARKit фреймворк. Понятие цифровой трансформации бизнеса. В современной экономике многим компаниям понадобится переосмыслить свои бизнес модели и проводить значите льные изменения в своих организациях. Это связано с цифровой революцией, которая подрывает традиционные устои практически во всех областях. Выживание компании в эпоху цифровизации обеспечивает цифровая трансформация бизнеса. Цифровая трансформация бизнеса (англ. digital transformation, DT или DX) — это глобальный процесс внедрения инновационных цифровых решений во все сферы компании. Основная цель цифровой трансформации ускорение принятия решений на всех уровнях и сохранение конкурентоспособности фирмы в стремительно меняющемся мире [1]. Цифровая трансформация предполагает [1]: ● перенесение в цифровую среду всей стратегии развития бизнеса; ● полное или частичное перенесение в цифровую среду товаров и услуг компании; ● глобальное переобучение сотрудников; ● переход на новый уровень взаимодействия с клиентами; ● цифровизацию корпоративной культуры. В цифровую трансформацию хорошо вписываются мобильные технологии, так как мобильные устройства широко распространены и доступны, имеют огромную перспективу в будущем. Одной из таких технологий является дополненная реальность (AR). Однако, на данный момент её мало используют для повседневного применения. Это происходит из за недостатка мощностей мобильных устройств, но развитие дополненной реальности в бизнесе является очень перспективным направлением.  Виды реальностей. В нашем мире существуют несколько видов реальности [2]: 1. Материальная реальность — это мир, в котором мы живем и о котором у нас есть понимание, благодаря нашим органам чувств. 2. Дополненная реальность (Augmented Reality, AR) — это среда, в реальном времени дополняющая физический мир, каким мы его видим, цифровыми данными с помощью различных устройств (планшетов, смартфонов и др.) и определенного программного обеспечения. 3. Виртуальная реальность (Virtual Reality, VR) реальность, искусственно воссозданная с помощью технических средств, возде йствующих на органы чувств человека (зрение, слух, обоняние, осязание и др.). В отличии от AR, виртуальная реальность только создает иллюзию нахождения в другом мире. Человек никак не взаимодействует с реальным миром. 4. Смешанная реальность (Mixed Reality, M R) — это термин, обозначающий объединение реального и виртуального миров с помощью цифровых технологий. В смешанной реальности цифровые объекты могут взаимодействовать с объектами окружающего физического мира и влиять на них. Принцип работы дополненной ре альности в операционной системе iOS. На данный момент самым лучшим инструментом, по мнению разработчиков приложений для мобильных устройств, для работы с дополненной реальностью является фреймворк ARKit от компании Apple [3], реализованный в операционной системе iOS для мобильных устройств компании Apple.  Дополненная реальность (AR) в iOS работает с помощью технологии ARKit от Apple. ARKit — это программная платформа, которая позволяет разработчикам создавать приложения с AR возможностями для iOS устройс тв. На основание статьи “Как работает инструмент Apple ARKit” [4] и официальной документации от Apple [5] опишем основные принципы работы ARKit. ARKit использует камеру и датчики гироскопа и акселерометра на устройстве для отслеживания позиции и ориентации устройства в пространстве. Затем ARKit сопоставляет и анализирует изображение с визуальной базой данных (VDB) с помощью компьютерного зрения и алгоритмов глубинного обучения, чтобы определить поверхности и объекты в реальном времени. После этого приложени я с AR возможностями могут размещать виртуальные объекты на реальных поверхностях и выполнять другие AR функции. Технология постоянно развивается, так в мобильном телефоне iPhone 13 инженеры добавили лазерный дальномер. Это помогает создать более точную тр ехмерную карту окружающего пространства [6]. Техническая составляющая ARKit включает в себя следующие элементы [7]: 1. Датчики: ARKit использует датчики устройства, такие как ускорометр и гироскоп, чтобы определить поворот и перемещение устройства. 2. Камера: A RKit использует камеру устройства для отслеживания и распознавания визуальных маркеров, которые используются для определения положения объектов в пространстве. 3. Визуальные маркеры: ARKit использует визуальные маркеры, такие как QR коды, для определения поло жения и ориентации объектов в пространстве. 4. Моделирование поверхности: ARKit может использовать информацию о поверхности, полученную из камеры и датчиков устройства, для моделирования трехмерных поверхностей и создания объектов, например, на полу или на ст оле. 5. Точечное облако: ARKit может создавать точечное облако, используя информацию из камеры и датчиков. Это позволяет приложению учитывать пространство и перемещение устройства. 6. Интерфейсы программирования приложений: для создания приложений на ARKit используются инструменты Xcode, Swift и Objective C. 7. Машинное обучение: ARKit использует машинное обучение, чтобы обрабатывать информацию о визуальных маркерах и создавать трехмерные объекты в реальном времени. В частности, с машинным обучением была продел ана огромная работа. ARKit использует алгоритмы машинного обучения для распознавания объектов в сцене. Алгоритмы машинного обучения обучаются на большом количестве образцов изображений, и определяют признаки, которые характерны для конкретного объекта. Эти признаки затем используются для определения присутствия объекта в кадре камеры. ARKit распознает объекты на основе особенностей их формы и текстуры, а также на основе контекста, в котором они находятся. Например, если в сцене есть обеденный стол, ARKit мо жет распознать различные предметы на нем, такие как стулья и тарелки, на основе их формы и размера, а также на основе их положения относительно стола [8]. Дополненная реальность в контексте цифровой трансформации. Из всего вышесказанного можно предположит ь, что цифровая трансформация бизнеса и дополненная реальность (AR) существенно изменят взаимодействие между компаниями и их клиентами. AR технологии позволяют создавать интерактивные виртуальные объекты и добавлять их в реальное окружение, что может быть полезно для различных бизнес процессов. Компании могут использовать AR для создания виртуальных магазинов и витрин, позволяющих клиентам просмотреть товары в деталях, выбрать нужный вариант и оформить заказ. Опишем концепцию мобильного приложения, которое поможет производителям мебели повысить свои онлайн продажи и привлечь новых клиентов с помощью нового способа выбора мебели. В современном бизнесе, доходность дистрибьютора (40%) в среднем выше, чем у производителя (33%) [10]. Приложение станет прямым каналом связи между покупателем и производителем мебели и позволит повысить его доходность. Дистрибьюторами в данном примере выст упают магазины мебели.  Обычно магазины мебели имеют своих дизайнеров интерьера, которые предоставляют покупателям дополнительную услугу 3D визуализация интерьера. Это очень дорогостоящая услуга, ведь дизайнеру нужно создать множество 3D моделей и расст авить их в проекте помещения. По расчетам, выполненным автором на основе информации из открытых источников, цена этой услуги будет составлять примерно 700 рублей за 1 кв.м. площади. При этом будет представлено всего 3 5 ракурсов. Производитель мебели с по мощью приложения позволит покупателю самому взять на себя роль такого дизайнера и сэкономить на этой услуге. Достаточно предоставить API c 3D моделями, которые разработчик встроит в приложение с модулем дополненной реальности. Прямо у себя дома, клиент смо жет отсканировать свою комнату и визуализировать  пространство, расставляя и перетаскивая 3D модели, а также перемещаться вокруг виртуального пространства и посмотреть на дизайн с разных ракурсов. Данное приложение даст новый пользовательский опыт клиенту и повысит его удовлетворенность. В настоящий момент автор статьи разрабатывает приложение дополненной реальности для iOS устройств для последующего тестирования и внедрения в приложения магазинов мебели. Вывод. Дополненная реальность представляет собой уни кальную технологию, которая приводит к цифровой трансформации бизнеса и создает совершенно новый уровень взаимодействия между потребителем и брендом. Развивая приложения и устройства, которые работают на базе дополненной реальности, компании могут использо вать эту технологию для улучшения продаж, обучения персонала, продвижения товаров и многого другого. 

: устойчивое развитие, экология, переработка, окружающая среда В жизненный цикл любого продукта, помимо маркетинга, разработки, производства и эксплуатации также входит утилизация Вместе с тем, основная ответственность за утилизацию со стороны производителя заключается в маркировке продукции специальными символами с к одом упаковки Производители не всегда включают в свою производственную систему рециклинг. Рециклинг это деятельность, заключающаяся в обращении с отходами с целью обеспечения их повторного использования в народном хозяйстве и получения сырья, энергии, из делий и материалов. Является экологичной альтернативой обычному захоронению отходов. Таким образом, основная масса твердых бытовых отходов не подвергается сортировке и переработке и переходит на захоронение в мусорных полигонах.  На текущий момент система переработки мусора в России имеет следующие черты: недостаточное количество перерабатывающих предприятий. Существует неравномерное распределение таких предприятий по всей стране, что приводит к транспортировке мусора на большие расстояния и значительно уве личивает затраты на его переработку. Еще одной проблемой является низкая культура распределения отходов в раздельные контейнеры, что затрудняет переработку мусора во вторичное сырье и повышает расходы на вывоз и переработку общего мусора. Еще одной пробле мой является низкая эффективность процессов переработки в некоторых предприятиях, что приводит к высокой производственной стоимости и затратам на ремонт и эксплуатацию оборудования. Также существует проблема отсутствия единой технологической базы переработ ки отходов, что затрудняет создание современных перерабатывающих комплексов и приводит к использо ванию устаревшего оборудования. Рис.1 Маркировка переработки Кроме того, проблемой является недостаточное финансирование перерабатывающих предприятий и низкая экономическая эффективность данного бизнеса. В результате многие компании в этой сфере не в состоянии выйти на прибыль, что делает инвестиции в эту область менее привлекательными. И наконец, существует проблема ответственности за переработку отходов , которая часто лежит на муниципалитетах и региональных властях Разработка и внедрение современных технологий переработки мусора. Россия должна уделить большее внимание использованию новых инновационных методов переработки мусора, таких как биотехнологии, гидромеханические системы и другие методы, которые могут помочь сократить количество отходов и позволить перерабатывать мусор более эффективно. Рассмотрим возможные пути решения данных проблем: ● Создание экологически чистых производств. Многие отходы можно использовать как вторичное сырье для производства новых товаров, а также использовать при производстве энергии. Следует взять на вооружение производственные методы, которые эффективно сокращают и перерабатывают отходы. ● Взимание адекватной платы за сбор и у тилизацию мусора от предприятий и населения. Существующая система тарификации должна быть изменена для того, чтобы понизить стоимость сбора и переработки мусора. Кроме того, важно улучшить контроль и мониторинг всех компаний, занимающихся сбором и вывозом мусора. ● Развитие экологического образования. Необходимо проводить более активное просвещение граждан о вопросах утилизации и переработки мусора. Важно обучать население, начиная с детей, правильной сортировке мусора и популяризировать переработку отходов. ● Улучшение контроля за самовольными свалками. Существуют множество незаконных свалок на территории России. Необходимо создавать условия, чтобы предотвратить откладывание мусора в неположенных местах. Административные и юридические механизмы должны быть улуч шены, чтобы ограничить разрушительное воздействие на окружающую среду. ● Стимулирование использования экологичных материалов и упаковок. Российские производители и дистрибьюторы могут использовать биоразлагаемые материалы для упаковки продукции, чтобы сократ ить количество отходов. Также следует поощрять производство биоупаковки путем предоставления налоговых льгот и других стимулов. Вопрос в переработке мусора в городе Санкт Петербург является актуальным. Так как в городе существует проблема свалок, то переработка является решением данной проблемы. В ЖК Калина парк присутствуют урны с разделением биомусора и пластикового мусора, тем самым у жильцов каждого подъезда есть возможность в разделении мусора. В связи с этим был проведен опрос фокус группы, кото рая состояла из 108 человек по следующим вопросам. 1. Знаете ли Вы о порядке сбора мусора для переработки в вашем жилом комплексе (ЖК)? 2. Если знаете, то пользуетесь? Если бы знали, то пользовались бы? 3. Разделяете ли вы мусор? Данные вопросы были выбраны для отс леживания следующих факторов: 1. Существует ли переработка мусора в ЖК Калина парк где проживает около 5 тыс человек . 2. Как эффективно управляющая компания продвигает разделение мусора. 3. Готовы люди к разделению мусора. На следующих рисунках представлены результаты опроса фокус группы: Рис.2 Опрос осведомленности На данной диаграмме видно, что 67 человека (62%) не знают, что в их ЖК происходит разделение мусора с будущей переработкой. 17 человек (16%) знают о переработке, 24 (22%) что то слышали, но точный ответ дать не могут. Рис. 3 Если знаете, то пользуетесь? Если бы знали, то пользовались бы? На данной диаграмме видно, что 84 человек (78%) не пользуются данной возможност ью, только 24 (22%) пользуются. Рис.4 Разделяете ли вы мусор? Данная диаграмма показывает, что 55 человек (51%) не разделяют мусор, 32 человек (30%) иногда разделяют мусор, и всего 15 человек (14%) разделяют пластиковый мусор. Опираясь на результаты опроса фокус группы отдельно взятого жилого комплекса, можно сделать следую щие выводы: в Санкт Петербурге есть проблемы с осведомленностью о возможностях разделения и переработки мусора. Большинство опрошенных не знают о такой возможности на территории своего жилого комплекса. Многие не разделяют мусор, несмотря на предоставленну ю возможность. Тем самым стоит сделать возможность для разделения и переработки мусора там, где это в данный момент не предусмотрено и оповещать жильцов о такой возможности там, где переработка существует. Дальнейшие исследования могут быть направлены на уточнение возможностей переработки основных видов упаковки потребительских продуктов и интеграцию этих возможностей в работу организаций, обеспечивающих сбор и вывоз мусора, а также разработку методики оценки сложности раздельного сбора и переработки мусо ра и рекомендаций по изменению дизайна продуктов для разных уровней сложности его переработки. 

: конкурентоспособность предприятия, качество, стандарт, требов ания. В современном мире, где конкуренция на рынке становится все более жесткой, качество продукции является одним из ключевых факторов, определяющих уровень конкурентоспособности предприятия. Это особенно важно для предприятий медицинского профиля, где вы сокое качество продукции является главным приоритетом, поскольку от этого зависит жизнь и здоровье пациентов. Актуальность темы исследования обусловлена тем, что в последние годы в Росси йской Федерации наблюдается рост производства медицинских изделий, кот орый может быть обусловлен, прежде всего, увеличением спроса на них, а также снижением уровня их доступности. В связи с этим, одной из наиболее актуальных проблем для любого производителя является повышение конкурентоспособности своей продукции. Цель иссле дования: изучить взаимосвязь качества производства медицинских изделий и уровня их конкурентоспособности . Основные задачи исследования: рассмотреть и проанализировать стандарты, применяемые при производств е медицинских изделий; исследовать ситуацию на рын ке медицинских изделий; и зучить опыт ведущих предприятий медицинского профиля в г. Санкт Петербург; В качестве первой задачи был проведен анализ литературных источников, посвященных данной теме. А именно были изучены стандарты применяемые в производстве ме дицинских изделий , чтобы получить наиболее полное представление о взаимосвязи между качеством продукции и конкурентоспособностью предприятий медицинского профиля. В рамках этой задачи было установлено, что организации, занимающиеся изготовлением медицински х изделий, должны следить за каждым этапом производства: от разработки ди зайна и выбора материалов до упаковки и контроля качества готовой продукции. Для обеспечения высокого качества производства предприятиям медицинской необходимо соответствовать : требов аниям Федерального агентства по здравоохранению и развитию человека (FDA); требованиям ГОСТ Р ИСО 13485:2017 «Медицинские изделия. Системы менеджмента качества» [1] ; требованиям сертификация системы менеджмента качества по международному стандарту ISO 9001:2015 [ 2 ]; Федеральный закон "Об основах охраны здоровья граждан в Российской Федерации" от 21.11.2011 N 323 ФЗ (последняя редакция) [ 3 ] . Необходимо дать определения терминам, конкурентоспособность предприятия — это его свойство, характеризующееся степенью реального или потенциального удовлетворения им конкретной потребности по сравнению с аналогичными объектами, представленными на данном ры нке . А в свою очередь к ачество — это степень соответствия совокупности присущих характеристик объекта требованиям . Были выявлены следующие признаки конкурентоспособности: с оответствие качественных характеристик и конкурентоспособности товара, т.е. сопостав ление товара по качественным характеристикам с товарами аналогами для достижения конкурентоспособности . о тличительные черты в свойствах качества и конкурентоспособности товара, которые определяются как характеристики, необходимые при выявлении и удовлетво рении конкретной потребности . развитие качественных характеристик товара, которое обуславливается неоднородностью товарной структуры [ 4 ] . Данные признаки свидетельствуют, о том, что качество производства нераздельно связано с конкурентоспособностью производимых изделий, и с уровнем конкурентоспособности предприятия в целом.  В качестве реализации второй и третьей было выявлено, что конкуренция на рынке медицинской продукции все более жесткая, поэтому слишком высокие цены могут оттолкнуть потенциальн ых клиентов, а слишком низкие цены могут повлиять на качество продукции и, как следствие, на уровень доверия к компании . Также б ыли проведены интервью с представителями компаний, которые имеют высокую конкурентоспособность на рынке медицинской продукции в городе Санкт Петербург . Анализ производился в организациях занимающихся производством стоматологических медицинских изделий. Это позволило выявить ключевые факторы, влияющие на качество продукции и уровень конкурентоспособности , а именно: наличие современн ы х технологи й и оборудовани я , обеспеч ение высо кого уров ня квалификации персонала, работающего на предприятии, а также необходимо учитывать особенности целевой аудитории и использовать соответствующие каналы коммуникации . Кроме того, для повышения качества продукции необходимо обеспечить полный контроль качества на всех этапах производства. Все эти меры позволят компаниям медицинского профиля удерживать своих клиентов и привлекать новых, что повысит их конкурентоспособность на рынке медицинской продукции. Та кже  Таким образом, можно говорить о том, что к ачество производства существенно влия е т на конкурентоспособность предприятия медицинского профиля . Организации, которые инвестируют в качество производства могут получать высокие оценки от клиентов и экспертов , что в свою очередь повышает их репутацию и доверие у клиентов, а значит и конкурентоспособность. Успешные организации обращают особое внимание на качество производства медицинских изделий и создание эффективной системы менеджмента качества для управления организацией , адаптируясь к быстро изменяющейся конкурентной среде, они устанавливают стандарты высокого качества продукции и управления процессами. Важно понимать, что производство медицинских изделий требует не только высокого качества пр одукции, но и строгого соответствия нормативным требованиям, их безопасности и эффективности. Организации, занимающиеся производством медицинских изделий, должны следовать соответствующим требованиям и стандартам, чтобы гарантировать безопасность и эффекти вность этих изделий для пациентов , и повышать уровень конкурентоспособности. 

: система менеджмента качества, производительность деятельности, эффективность, результативность, затраты на качество. В настоящих условиях санкционного воздействия на б изнес среду, особую важность представляют вопросы принятия правильных управленческих решений для обеспечения гибкости и адаптивности организации, сохранения своих позиций на рынке и обеспечения бесперебойности производственного процесса. В большей степени санкционные ограничения повлияли на крупные организации промышленного сегмента, включая предприятия телекоммуникационной отрасли. Данные организации в соответствии с масштабами деятельности практически все внедрили интегрированную систему менеджмента качес тва. Таким образом, оценка функционирования данной системы является основным источником информации о проблемах деятельности организации в целом. В соответствии с чем, процесс правильной и точной оценки системы менеджмента качества является вопросом первост епенной важности, решение которого позволит контролировать деятельность предприятия, принимать своевременные решения, основанные на фактах и, как следствие, позволит адаптировать систему деятельности с минимальными потерями в условиях повышенного риска нео пределенности. Методика оценки построена на принципах менеджмента качества, выступающих критериями оценки. Особенность оценки заключается в наличии общих показателей системы менеджмента качества, а также показателей измерения бизнес – процессов, отражающих специфику рассматриваемой отрасли. Каждый показатель определен с соответствующим коэффициентом (весом) влияния на критерий (рассчитанный экспертным путем с учетом коэффициента конкордации, определяющего степень согласованности экспертов). Оценка критериев производится в рамках балльно рейтинговой системы, где 1 – наименьший результат оценки, 5 – наивысший. В рамках соответствия определению термина «эффективность», отражающего не только результативность системы, но и соотношение полученных результатов с за траченными ресурсами производится оценка затрат на качество, классифицируемых на три группы: затраты на предупреждение, затраты на оценку (контроль) и потери от несоответствия. Оценка затрат на качество производится в рамках процентного соотношения каждого вида затрат в соответствии с моделью оптимальных затрат (где наилучшим раскладом считается приблизительное равенство доли затрат на предупреждение и доли затрат на оценку, а также минимальную долю потерь от несоответствия (менее 10%)). Для определения эко номической эффективности системы менеджмента качества также производится оценка динамики финансовых результатов деятельности предприятия (выручки, чистой прибыли и рентабельности) – как соответствие положительного результата функционирования системы менедж мента качества. Итоговые значения (баллы) оценки результативности системы и уровня управления затратами на качество переносятся в матрицу сопоставления результатов и затраченных ресурсов (аналог матрицы Бостонской консалтинговой группы) и, в соответствии с зоной размещения делается вывод об эффективности системы менеджмента качества. Рассмотрим процесс оценки на примере конкретной организации телекоммуникационной отрасли. Результаты оценки каждого критерия, вес показателей и структура методики представлена на рис.1. В скобках рядом с названием показателя указан вес важности, рассчитанный экспертным путем (посредством опроса сотрудников, задействованных (ответственных) с соответствующим этапом жизненного цикла предприятия). В столбце «О» (оценка) каждого критерия (показателей) указан результат оценки с учетом веса важности каждого показателя. Серым цветом выделен итоговый результат оценки критерия. Источником информации в рамках проведения оценки является внутренняя документация организации, результаты опрос ов заинтересованных сторон (включая сотрудников и  конечных потребителей), отчеты по результатам аудита, карты процессов и финансовая отчетность организации. После оценки каждого критерия производится измерение динамики финансовых результатов деятельности п редприятия с применением весовых коэффициентов по принципу зависимости: выручка и чистая прибыль оцениваются с коэффициентом 0,25, а рентабельность по чистой прибыли с коэффициентом 0,5 – как итоговый коэффициент взаимосвязи двух других показателей. Резуль таты оценки представлены на рис.2. За основу оценки взяты итоговые результаты деятельности предприятия с 2018 по 2021 гг. Динамика показателей оценивается по принципу стабильности изменений по шкале от 1 до 5, где 1 – стабильный спад показателей, 5 – стаби льный рост. Рис. 1. Оценка критериев и показателей функционирования СМК в ПАО «Ростелеком» Рис.2. Оценка динамики финансовых результатов деятельности в ПАО «Ростелеком» Следующим этапом методики является оценка уровня управления затратами на качество в соответствии с классификацией Джурана Фейгенбаума (превентивные затраты, затраты на оценку и контроль, потери от несоответствия). Оценка затрат производится в два этапа: оценка структуры затрат по классификации (вес важности 0,6) и оценка объема затрат п о отношению к выручке предприятия (вес важности 0,4). Результаты оценки затрат на качество в ПАО «Ростелеком» представлены на рис.3. Рис.3. Оценка затрат на качество в ПАО «Ростелеком» Заключительным этапом методики является определение интегрального показателя результативности системы менеджмента качества на основе результатов оценки критериев и сопоставление общего результата с итогом по оценке затрат на качество. Поскольку система менеджмента качества представляет собой сбалансированную систему, методика построена на принципе равной важности выделенных критериев оценки, поэтому общий результат функционирования системы определяется как среднее арифметическое результатов оценки каждого критерия и динамики финансовых результатов (итоговый результат п редставлен на рис.4. Рис.4. Результативность системы менеджмента качества ПАО «Ростелеком» Для соотношения полученных результатов деятельности системы с затраченными ресурсами используется матрица (система координат) по оси абсцисс, которой располагается результат по оценке затрат на качество (от 1 до 5), по оси ординат – итоговое значение результативности системы. Данная матрица разделена на 4 зоны (низкий уровень управления затратами – низкие результаты (зона высоких вложений в систему и низких результатов); низкие результаты высокий уровень затрат (низкие результаты при низких вложе ниях); высокие результаты при высоких затратах (зона, требующая особого внимания к затратам на качество); высокие результаты при низких затратах (зона эффективной системы). Результат представлен на рис.5. Рис.5. Эффективност ь системы менеджмента качества ПАО «Ростелеком» По результатам оценки эффективность системы менеджмента качества ПАО «Ростелеком» можно оценить как хорошо функционирующую. В данном случае необходима раз работка корректирующих мероприятий особо проблемных зон (лидерство, ориентация на потребителя, программы устойчивого развития и компетентности персонала, внедрение инноваций). Таким образом, разработанная методика оценки эффективности систем менеджмента ка чества позволяет получить общий результат функционирования системы, учитывает затраты на качество и предоставляет исчерпывающую информационную базу для разработки мероприятий и принятия правильных управленческих решений в целях улучшения деятельности. Спис ок л итератур ы 1. ГОСТ Р ИСО 9000 2015. Системы менеджмента качества. Основные положения и словарь – М.: Стандартинформ, 2015. – 47 с. 2. Медведева, М. Показатели оценки эффективности системы менеджмента качества организаций сферы телекоммуникаций / М. М едведева, В. Семенов – Екатеринбург: Издательский дом "Ажур", 2022. – С. 67 73. 3.  Медведева, М. В. Регулирование затрат на управление качеством / М. В. Медведева, В. П. Семенов // – 2021. – Т. 2. – С. 274 275. АНАЛИЗ КЛЮЧЕВЫХ ПРОБ ЛЕМ УПРАВЛЕНИЯ ИЗМЕН ЕНИ ЯМИ В ОРГАНИЗАЦИИ ПРИ СРАВ НЕНИИ ДВУХ МОДЕЛЕЙ У ПРАВЛЕНИЯ ИЗМЕНЕНИЯМИ. 1 Ш АХОВ О. Ю. , А ВТОР 2 ( А ХМЕТОВА А.Э. ) 1 ООО «Оптимальное Движение» 2 СПбГЭТУ «ЛЭТИ» Аннотация . В статье рассматриваются подходы при внедрении изменений, снижающие риски внедрения изменений. Проводится сравнение двух моделей управления и внедрения изменений: ADKAR и Lean Change . 

: Внедрение изменений, промышленность, бережливые изменения, lean change, ADKAR. Основные проблемы [1] внедрения изменений в организациях и предприятиях могут быть связаны со следующими аспектами: Отсутствие понимания необходимости изменений: люди часто не видят необходимости внедрения изменений [2] или считают, что текущие методы и процессы работают достаточно хорошо, чтобы не требовать изменений. Недостаток ресурсов: для реализации изменений может понадобиться дополнительное время, деньги и другие ресурсы. Компании могут столкнуться с проблемой нехватки ресурсов для успешной реализации планов. Сопротивление изменениям: люди часто боятся и не любят изменения, поэтому могут быть недовольными или несогласными с предлагаемыми изменениями. Однако, необходимость изменений может быть крайне важной для компании, поэтому сопротивление может замедлить процесс и усложнить его реализацию. Ошибки при планировани и [3]: недостаточно точное или неадекватное планирование может привести к неудачным результатам. Важно понимать, какие изменения необходимы, и разработать точный план действий, чтобы добиться нужных результатов. Недостаточная коммуникация: недостаток комму никации и связи между работниками может привести к непониманию целей и планов, что может затруднить процесс внедрения изменений. Недостаток лидерства [4]: нехватка руководства, отсутствие четкого плана действий и проблемы с координацией могут привести к не правильному распределению ресурсов и недостаточной поддержке изменений в организации. Сложности с привлечением и удержанием талантов: некоторые изменения могут требовать от компании новых навыков и компетенций, которые могут быть трудными для нахождения и удержания в компании. Управление изменениями (Change Management) это процесс планирования, координации, реализации и контроля изменений, связанных с бизнес процессами, технологиями, структурами и/или культурой организации. Управление изменениями необход имо для того, чтобы организация могла адаптироваться к новым условиям, решать возникающие проблемы, повышать эффективность и качество своей деятельности. Процесс управления изменениями включает в себя следующие шаги: Определение изменения. В этом шаге необ ходимо определить, какое изменение необходимо внести, а также определить причину, цели и ожидаемые результаты изменения. Оценка изменения. В этом шаге необходимо проанализировать влияние изменения на организацию, оценить возможные риски и выработать страте гию для минимизации этих рисков. Разработка плана изменений. В этом шаге необходимо разработать план, который будет описывать, как изменения будут внедряться, кто будет ответственен за их внедрение и какие ресурсы будут необходимы для успешной реализации. Реализация изменений. В этом шаге необходимо провести практическую реализацию изменений, включая все необходимые технические и организационные мероприятия. Оценка результатов. В этом шаге необходимо оценить результаты изменений и сравнить их с ожидаемыми р езультатами. Если необходимо, то произвести корректировки. Контроль изменений. В этом шаге необходимо внедрить систему контроля за изменениями и отслеживать их воздействие на организацию. Ключевые элементы успешного управления изменениями включают понимани е необходимости изменений, вовлечение сотрудников, коммуникацию и обучение, планирование и оценку рисков, а также эффективное управление процессом изменений. Важно понимать, что управление изменениями это непрерывный процесс, который не заканчивается пос ле внедрения изменений. Он должен включать систему контроля и оценки результатов, чтобы обеспечить успешное функционирование организации в условиях постоянно меняющейся внешней среды. Сопротивление изменениям является естественной реакцией большинства люде й на новые ситуации, так как изменения могут вызывать страх, неопределённость, беспокойство и неудобства. Это может быть вызвано такими факторами, как: Неопределенность: Изменения могут создавать неопределенность и неясность в будущем, что может вызвать у людей страх и тревогу. Привычка: Люди могут быть привыкли к существующему порядку и не хотят менять привычки, даже если они неэффективны. Контроль: Люди могут чувствовать потерю контроля при изменениях, что может привести к беспокойству и неудобству. Необ ходимость усилий: Люди могут чувствовать, что изменения потребуют от них дополнительных усилий и времени, что может вызвать сопротивление. Негативный опыт: Предыдущий негативный опыт с изменениями может вызвать у людей опасения и сопротивление новым измене ниям. Для управления изменениями важно понимать причины сопротивления и принимать меры для преодоления этих препятствий. Это может включать такие действия, как обеспечение четкой и открытой коммуникации, вовлечение сотрудников в процесс изменений, предоста вление обучения и поддержки, а также создание мотивации и вознаграждения за успешное внедрение изменений. Важно также иметь терпение и понимание, что изменения могут потребовать времени для принятия и адаптации. Есть множество моделей управления изменениями. Сравним две из них: ADKAR и Lean change. ADKAR и бережливые изменения (Lean Change) являются двумя разными методологиями управления изменениями в организациях. ADKAR это методология, разработанная компанией Prosci [6], которая помогает орга низациям планировать и реализовывать изменения, учитывая пять этапов принятия изменений: осознание необходимости изменений, желание изменений, знание, умение и поддержка. Каждый этап ADKAR является необходимым условием для успешного принятия изменений в ор ганизации. Бережливые изменения, с другой стороны, основаны на методологии Lean, которая используется для улучшения производительности и эффективности организации. Бережливые изменения предлагают более гибкий и адаптивный подход к управлению изменениями, к оторый включает в себя обратную связь и участие сотрудников в процессе  изменений, что позволяет быстро определять и реагировать на изменения внутри и вне организации. Одно из отличий между ADKAR и бережливыми изменениями заключается в том, что ADKAR являет ся более структурированной и последовательной методологией, в то время как бережливые изменения предлагают более гибкий и адаптивный подход к управлению изменениями. ADKAR более подходит для организаций, которые требуют строгого контроля и документирования процесса управления изменениями, в то время как бережливые изменения лучше подходят для организаций, которые нуждаются в более гибком [6] и быстром реагировании на изменения внутри и вне организации. Однако, как и с любой методологией управления изменения ми, обе подходы могут быть эффективными при правильном использовании и адаптации к конкретным потребностям и особенностям организации. 

: рабочая неделя, сокращение, бизнес процессы, производительность, эффективность, преобразования, офис, выгорание В марте 2023 года Государственная Дума выдвинула идею сокращения рабочей недели с 40 до 36 часов. По данным портала Superjob [1], 46% россиян поддержали эту идею. По задумке, компании переведут своих сотрудников на сокращенный рабочий день в пятницу – они будут уходить домой после обеда. Хотя впервые идея сокращения рабочей недели была упомянута Дмитрием Медведевым в июне 2019 года [2], никаких явных подвижек в эту сторону не производилось до марта 2023 года. Речи о четырехдневной рабочей неделе пока не ид ет: по предположению Д. Медведева это сможет произойти только к 2035 году. Однако шаги в эту сторону уже начали предприниматься. У многих руководителей компаний может возникнуть логичный вопрос: не повлияет ли такое новшество на производительность труда и финансовые показатели? Смогут ли работники выполнять задачи в более короткие сроки? Для ответа на этот вопрос стоит сначала обратиться к истории СССР. [3] В дореволюционный период рабочая неделя составляла 6 дней, смена составляла от 10 до 11,5 часов. Одна ко после взятия Зимнего дворца почти сразу был подписан декрет о сокращении рабочего дня до 8 часов. После рабочий режим также претерпевал изменения до тех пор, пока в 1967 году [4] не появился привычный режим – 8 часов в день, 5 дней в неделю. Такой опыт положительно сказался на психологическом состоянии людей и их здоровье. Если говорить о сокращении рабочей недели в современной России, то и такой опыт уже был в некоторых компаниях. Пример – « Mirax Group », частично убравший рабочий день в пятницу еще в 20 09 году [5], говорит, что производительность нисколько не упала. По словам главного директора компании, работникам не хватает двух дней в неделю, чтобы отдохнуть от интенсивной и напряженной работы, и это негативно сказывается на функционировании компании. Также предполагают, что компания имеет задолженности и таким образом хочет сэкономить – и это также «плюс» для четырехдневки, поскольку сразу можно сделать вывод, что это как минимум экономно. Другой пример – Совкомбанк, в 2022 году также перешедший на че тырехдневку в качестве эксперимента [6]. 97% руководителей отметили рост продуктивности всех сотрудников: 76% сделали все по плану, а 20% перевыполнили рабочую норму. Так почему, если успешный опыт сокращения рабочей недели уже существовал, и большинство х отят работать меньше – в стране до сих пор не поднялся вопрос перехода на четыре рабочих дня в неделю? ВЦИОМ провел опрос [7] россиян на эту тему и выявил следующие показатели, почему присутствует страх такой трансформации: Если верить этим данным, большин ство (57%) россиян боится снижения зарплат и уровня жизни, а также процветания алкоголизма и наркомании из за большего количества свободного времени. Это стоит учитывать, поскольку важным является момент сохранения зарплаты при таком переходе. В остальных вопросах успешный и позитивный опыт показывает, что сокращение количества рабочих дней позитивно влияет на уровень жизни и настроение работников. Рис. 1 – Что пугает россиян в четырехдневной рабочей неделе Для рассуждения о том, как правильно внедрить с окращенный рабочий режим, нужно определить основные потери в рабочих процессах. По данным опроса Vouchercloud [8], множество сотрудников призналось, что тратят большую часть времени в офисе зря: Рис. 2 – На что уходит время в офисе Итого – 262 минуты (4 часа 22 минуты) времени тратится не на работу. Это составляет половину рабочего дня. Очевидно, что люди неспособны работать интенсивно и эффективно 40 часов в неделю; в процессе работы неизбежно возникают прокрастинация и отвлечение внимания. При этом прое кты, задачи и процессы делаются вовремя и не опаздывают, потому что сотрудники либо успевают сделать все за часы, когда они эффективно работают, либо мобилизуются ближе к дедлайнам. Отсюда можно сделать предположение: за 4 рабочих дня люди будут успевать д елать все те же задачи, что и за 5, при условии более эффективной работы. Что поможет сделать работу интенсивной? 1. Борьба с выгоранием По данным сайта hh . ru [9], 80% сотрудников считают, что так или иначе сталкивались с профессиональным выгоранием. 38% из них связывают выгорание с ухудшением свой продуктивности, а 47% считают, что работают как обычно, но через силу. 20% опрошенных согласны с тем, что причина выгорания – переработки. Эта статистика наглядно иллюстрируют то, что эмоциональное состояние людей , работающих пятидневную рабочую неделю, в большинстве своем скорее негативное. Также выгорание влияет на работоспособность трети из сотрудников. Соответственно, увеличение выходных дней может привести к повышению КПД сотрудников и лучшим показателям. Рис. 3 – Вы лично сталкивались с проявлением профессионального выгорания? Рис. 4 – Что могло быть предпринять руководство, чтобы помочь вам справиться с выгоранием? Рис. 5 – Влияние профессионального выгорания на эффективности труда 2. Оптимизация бизнес процессов Таблица 1 – Оптимизация бизнес процессов Бизнес процесс Текущее состояние Потери Целевое состояние Обработка документации  Прием писем и распечатка на бумаге  Обязательная физическая подпись на бумаге  Создание физического архива и его содержание  Бумага  Время  Деньги  Пространство  Вести переписку в электронном формате  Ввести использование электронных подписей  Электронный архив Выполнение проекта  Проект задается одним днем и имеет один дедлайн  Проект требует необязательных согласований  Обы чно делается неравномерно, большая часть работы приходится на дедлайн  Время  Эмоциональный ресурс  Создание чек поинтов в процессе проекта для равномерной работы  Исключение ненужных согласований и запросов Продолжение таблицы 1 Прием сотрудника на работу  Два очных этапа собеседования  Заполнение всех документов вручную  Обучение стажера сотрудником куратором без дополнительных материалов  Время  Бумага  Эмоциональный ресурс  Первый этап собеседования – дистанционный, чтобы отсеять неподходящих кандидатов сразу  Э лектронное заполнение анкеты и документов для приема  Разработка инструкций для стажеров Еще одним ключом к безопасному переходу на четырехдневку может служить оптимизация бизнес процессов компании. Ниже в таблице 1 представлен сравнительный анализ некоторых бизнес процессов, которые можно оптимизировать почти в любой компании. Эти варианты можно разобрать на конкретном примере: для оформления сертификата соответствия в компании по сертификации сотрудник получает пакет документов и сверяет их. На опр еделенном этапе он понимает, что не знает, оплачена ли услуга клиентом и каждый раз делает запрос в бухгалтерию, что замедляет процесс оформления сертификата. Решение: внести информацию об оплате услуги во входящий пакет документов, чтобы сотрудник сразу м ог отсеять неоплаченные заказы. 3. Цифровизация Этот путь оптимизации частично был затронут ранее. Его суть заключается в максимальной цифровизации работы офиса, прежде всего для экономии времени. Если сравнить время протекания передачи распечатанного письма , подписанного вручную с добавлением на письмо электронной подписи и пересылку по почте – становится очевидно, что второй способ занимает гораздо меньше времени. Эти и другие способы оптимизации помогут компаниям вводить сокращенную рабочую неделю без риск ов потери продуктивности, ухудшения показателей и замедления всей цепочки бизнес процессов. Также сохранятся заработные платы сотрудников, поскольку объем выполняемых работ не снизится – и это отвечает на главный страх россиян при мысли о четырехдневке. Та ким образом можно не только максимально оптимизировать работу предприятий, но и улучшить эмоциональный фон и индекс счастья сотрудников путем борьбы с выгоранием и сохранения work life balance . 

: упаковочные материалы, качество, цепочка поставок, дефицит, производство Проблема дефицита упаковочных материалов в России возникла в середине 2022 года и будет длиться ещё несколько лет. Многие новые поставщики не могут об еспечить стабильное высокое качество упаковочных материалов, которое было ранее, а многое новое сырьё, из которого делаются материалы, не приспособлено под текущее состояние производственных линий. Рассмотрим динамику эффективности производственных линий в период возникновения проблем в поставках. Общая эффективность каждой линии Unilever рассчитывается каждую смену и считается исходя из времени бесперебойной работы линии, то есть работы без остановок. Все остановки классифицируются в зависимости от причины и вносят свой вклад в снжение или повышение эффективности линии. На рисунке 1 предс тавлена эффективность одной из линий Unilever в январе 2022 года, то есть до возникновения дефицита. Рисунок 1 – Эффективность линии за январь 2022 Из данного рисунка видно, что общее время эффективной работы линии за смену составило 78.95%, что является высоким показателем. Существуют обязательные остановки, такие как перерывы на продуктовый или форматный переход, переоснастку, ТО, запуск и остановку линии, из за которых эффективность линии не может быть равна 100%. В рамках данной работы нас интересует показатель QDTL , отмеченный жёлтым цветом. Данный показатель показывает влияние качества упаковочных материалов на эффективность линии. В данном случа е остановки по качеству упаковки составили менее 1% от общего времени работы линии. Теперь посмотрим на отчёт по эффективности той же линии в августе 2022 (Рисунок 2). Рисунок 2 – Эффективность линии за август 2022 Общая эффективность линии снизилась практически на 20%, а количество остановок, связанных с качеством упаковочных материалов, увеличилось в несколько раз. Годами на производстве существовал принцип работы набазовых настройках, которые зафиксированы на каждом участке производственной линии. Э ти настройки гарантировали стабильную и бесперебойную работу на любых упаковочных материалах. Новые упаковочные материалы отличаются друг от друга и требуют дополнительных мер для успешной работы на них. В связи с возникшими сложностями компания столкнулас ь с необходимостью пересмотра формата свой работы. Для уменьшения времени простоев предлагается стандартизировать настройки для каждого вида упаковочных материалов, а именно подбирать их на линии, после чего фиксировать в отдельный трекер. В качестве приме ра рассмотрим самоклеющуюся этикетку, которая используется на 8 линиях. Ранее эта этикетка делалась на материалах из Европы, но после возникновения дефицита в качестве поставщиков остались только Китай и Турция. Два этих поставщика делают этикетку и подлож ку для неё из разного материала, Туриция использует полиэтилен, Китай – полипропилен. Полипропилен имеет более гибкую и тягучую структуру, что позволяет ему растягиваться и ровно приклеиваться на флаконы разной неровной формы, полиэтилен же рвётся и на так их флаконах клеится с морщиной. При этом, если флакон ровный или округлый, этикетка из полипропилена ведёт себя нестабильно и также выдаёт морщины при сходе с подложки. Для устранения проблемы был разработан трекер продуктов, для которых может использовать ся та или иная этикетка, однако всё ещё оставался риск невозможности использовать нужный материал для конкретного продукта. В связи с этим были подобраны не только настройки этикетировщика (скорость протяжки, угол ножа), но и введена модернизация – установ ка прижимных валов каскадом, благодаря чему этикетка из полиэтилена может быть нанесена на неровный флакон без морщин. Данные изменения записаны и внесены в новый стандарт настройки линии для данной упаковки в комбинации с данным продуктом. На поиск решени я на линии потребовалось 6 часов простоя, в следующий раз стандарт позволит выполнить настройку за 15 минут. Такие изменения и стандарты внедряются на разных участках линий для разных видов упаковки с целью снижения времени остановок. Рисунок 3 – Эффекти вность линии за декабрь 2022 На рисунке 3 представлены последние отчёты по эффективности линии за декабрь 2022 года. Работа по внедрению стандартизации новых настроек ещё не закончена, но уже вида положительная динамика по снижению количества остановок из за качества упаковочных материалов, а также возврат к прежней эффективности линии. Таким образом, логистические сбои в цепочках поставок оказали огромное влияние на работу производства и привели к необходимости пересмотра работы оборудования и стандартн ых настроек для обеспечения стабильной работы и высокой эффективности производства. 

: дзета функция Римана , линейная алгебра , вычислительный эксперимент , теория чисел. Введение Гипотеза Римана является одной из задач тысячелетия [1] . Ее важность обусловлена фундаментальной связью дзета функции и простых чисел. В 2 013 году Ю. В. Матиясевич изучал конечные ряды Дирихле, обращающиеся в 0 в некоторых нетривиальных нулях дзета функции [2] . Он фиксировал первый коэффициент этих рядов равным 1, и обнаружил, что вычисленные ряды Дирихле совпадают с коэффициентами знакочере дующейся дзета функции 휁 ( 푠 ) ( 1 − 2 ⋅ 2 − 푠 ) . Мы расширили это исследование, фиксируя несколько коэффициентов, и продолжили исследовать связь дзета функции и простых чисел через проведение компьютерных экспериментов по построению коэффициентов рядов. Построение конечных рядов Дирихле Идея аппроксимации дзета функции конечным рядом Дирихле описана в [ 3 ] : нужно получить ряд 푅 ( 푠 ) = ∑ 푎 푘 푘 − 푠 푛 푐 푘 = 1 , 푛 푐 — количество коэффициентов, который равен нулю в первых 푛 нетривиальных нулях дзета функции. Для получ ения ряда необходимо решить систему уравнений. Каждое уравнение в системе, обеспечивающее равенство нулю в некотором нуле дзета функции, содержит все коэффициенты ряда: 푅 ( 푠 푗 ) = ∑ 푎 푗 푘 − 푠 푗 푛 푐 푘 = 1 = 0 . Чтобы получить ненулевое решение, фиксируем один из коэфф ициентов, равным, например, 1: a 1 + 푎 2 ⋅ 0 + ⋯ + 푎 푛 푐 ⋅ 0 = 1 . Таким образом, можно представить задачу в матричной форме 푆푎 = 푏 , где 푆 — матрица размера 푛 푐 × 푛 푐 , 푎 — вектор 푛 푐 × 1 , содержащий искомые коэффициенты, 푏 — вектор свободных членов. Для ряда с 푎 1 = 1 система имеет вид: Количество коэффициентов 푛 푐 определяется числом уравнений, которым должен удовлетворять ряд. Количество уравнений должно совпадать с 푛 푐 , чтобы матрица была квадратной. Например, если равенство нулю в 푛 нулях дзета функции обеспечивается с помощью 푛 уравнений и еще одно уравнение обеспечивает фиксацию первого коэффициента, то 푛 푐 = 푛 + 1 . Этот метод описан в [ 3 , 4 ]. Данное исследование посвящено изучению свойств рядов с несколькими фиксированными коэффици ентами. Для 푓 фиксированных коэффициентов количество уравнений будет составлять 푛 푐 = 푛 + 푓 : 푛 уравнений для обеспечения равенства ряда нулю в 푛 точках и 푓 уравнений для фиксации значений коэффициентов. Например, если фиксировать a 1 = 1 , 푎 2 = 0 , 푎 3 = 0 , сис тема примет вид: Используя данный метод, можно построить ряд с любым количеством фиксированных коэффициентов. В исследовании использованы численные значения нулей дзета функции [ 5 ]. Исследование свойств полученных рядов Рассмотрим коэффициенты некоторых рядов Дирихле, построенных по первым 400 нулям дзета функции с точность 600 знаков после запятой [5 ] . Интерес представляют ранние коэффициенты (в первой половине), так как после первой половины коэффициентов возникает «выброс» с очень большими значениями. Первые 80 коэффициентов рядов с разными фиксированными коэффициентами представлены на рисунке 1. а)  б) в) Ри с. 1. Первые 80 коэффициентов ряда с зафиксированными коэффициентами а) 푎 1 = 1 , 푎 2 = 0 , б) 푎 1 = 1 , 푎 2 = 푎 3 = 0 , в) 푎 1 = 1 , 푎 2 = 푎 3 = 푎 4 = 0 Судя по всему, значения коэффициентов формируют группы. Например, на рисунке 1.а) можно увидеть 4 разных класса значений коэффициентов:  푎 푖 = 1 , где 2 ∤ 푖 & 3 ∤ 푖  푎 푖 = 0 , где 2 | 푖 & 3 ∤ 푖  푎 푖 = − 1 2 , где 2 ∤ 푖 & 3 | 푖  푎 푖 = − 3 2 , где 2 | 푖 & 3 | 푖 Также, можно сравнить коэффициенты полученных рядов и коэффициенты дзета функции (конечную часть). Выдвинув гипотезу, что начальные коэффициенты ряда с 푎 1 = 1 , 푎 2 = 0 совпадают с коэффициентами ряда ( 푏 1 ∙ 1 − 푠 + 푏 2 ∙ 2 − 푠 + 푏 3 ∙ 3 − 푠 ) 휁 ( 푠 ) , можно найти 푏 1 , 푏 2 , 푏 3 исходя из первых шести коэффициентов ряда и получить интересующее соотношение. Первые 6 коэффициентов ряда с 푎 1 = 1 , 푎 2 = 0 : 1 − 푠 + 0 ∙ 2 − 푠 + ( − 1 2 ) ∙ 3 − 푠 + 0 ∙ 4 − 푠 + 1 ∙ 5 − 푠 + ( − 3 2 ) ∙ 6 − 푠 Первые 6 коэффициентов ряда ( 푏 1 ∙ 1 − 푠 + 푏 2 ∙ 2 − 푠 + 푏 3 ∙ 3 − 푠 ) 휁 ( 푠 ) : 푏 1 ∙ 1 − 푠 + ( 푏 1 + 푏 2 ) ∙ 2 − 푠 + ( 푏 1 + 푏 3 ) ∙ 3 − 푠 + ( 푏 1 + 푏 2 ) ∙ 4 − 푠 + 푏 1 ∙ 5 − 푠 + ( 푏 1 + 푏 2 + 푏 3 ) ∙ 6 − 푠 Соответствую щая система: { 1 = 푏 1 0 = 푏 1 + 푏 2 − 1 2 = 푏 1 + 푏 3 ⇒ { 푏 1 = 1 푏 2 = − 1 푏 3 = − 3 2 Таким образом, рассматриваемый ряд походит на ряд ( 푏 1 ∙ 1 − 푠 + 푏 2 ∙ 2 − 푠 + 푏 3 ∙ 3 − 푠 ) 휁 ( 푠 ) . В исследовании было рассмотрено больше ряд ов с различным количеством фиксированных коэффициентах. Было установлено, что значение коэффициента зависит от делимости его индекса на 1 , 2 , … , 푓 + 1 , где 푓 – количество фиксированных коэффициентов в ряде. Также коэффициенты с индексами, у которых делимости на эти числа совпадают, имеют одинаковые значения. Исходя из исследования, можно заключить, что начальные коэффициенты похожи на коэффициенты ряда 푅 ( 푠 ) ~ 휁 ( 푠 ) ∑ 푏 푘 푘 − 푠 푓 + 1 푘 = 1 , где 푓 — количество фиксированных коэффициентов и 푏 푘 — числа, которые находятся исходя из коэффициентов ряда. Заключение В рамках данной работы были исследованы конечные ряды Дирихле, обращающиеся в ноль в некоторых нулях дзета функции Римана. Была обнаружена связь между коэффициентами таких рядов и делимостью индексов этих коэффициентов на определенные числа. Данная связь была описана и формализована в виде распределения коэффициентов ряда в зависимости от его индекса. Найденная законо мерность может способствовать дальнейшим исследованиям, связанным с дзета функцией Римана. 

: Таблица Юнга, алгоритм RSK, путь выталкиваний, асимптотическая комбинаторика, мера Планшереля Работа выполнена при поддержке гранта РНФ № 22 21 00669. Преобразование Робинсона Шенстеда Кнута (RSK) представляет собой биекцию между набором перестановок и набором пар стандартных таблиц Юнга одинаковой формы, выровненных по левому нижнему кр аям: записывающей P и нумерующей Q [1]. Таблицы, получаемые при преобразовании равномерно распределённых случайных перестановок, имеют т.н. планшерелевское распределение [2]. При добавлении очередного значения последовательности в таблицы, используя преобразование RSK, это значение записывается в первый столбец таблицы P. Если значение максимально в столбце, то оно записывается в новую клетку сверху столбца. Иначе значение записывается на место ближайшего большего значения в столбце, которое в свою оч ередь будет “вытолкнуто” в соседний столбец справа. По тому же принципу будет произведён поиск нового положения “вытолкнутого” значения, пока очередное “вытолкнутое” значение не окажется максимальным в столбце. После этого в таблицу Q в ячейку, в которой п роизошло расширение формы таблицы, помещается порядковый номер добавленного элемента. Алгоритм завершает работу после обработки всех элементов последовательности. Для алгоритма RSK для таблицы Юнга можно выделить т.н. путь выталкиваний последовательность клеток таблицы P, перемещающихся в ходе добавления одного элемента при помощи преобразования RSK. Конец пути выталкиваний находится на фронте таблицы. В пределе с ростом размера таблиц фронт стремится к предельной форме Вершика Керова:            2 4 2 arcsin 2 ) ( u u u u  ,       | u | ≤ 2 ,     (1) где для перехода от системы координат (u,v) к (x,y) производится поворот на 45 ᴼ: 2 u v x   , 2 u v y   . Траектория пути выталкиваний для таблиц бесконечно большого размера, распределённых по мере Планшереля, зависит только от значения первого элемента пути выталкиваний. В статье Д. Ромика и П. Сняды [3] представлены формулы (2) (8) для вычисления предельных кривых путей выталкиваний бесконечных планшерелевских таблиц: ) 2 arcsin 4 4 ( 1 2 1 ) ( 2 u u u u u F      .        | u | ≤ 2         ( 2 ) ) ( ) ( 1 t F t t u      0 ≤ α ≤ t ≤ 1 ( 3 ) )) ( ( ) ( 1 t F t t v       0 ≤ α ≤ t ≤ 1 . ( 4 ) 2 ) ( ) ( ) ( t u t v t x      ,                            ( 5 ) 2 ) ( ) ( ) ( t u t v t y      .                                   ( 6 ) 2 ) ( )) ( ( ) 1 ( ) ( 1 1           F F x k .                        ( 7 ) )) ( ( ) ( 1 s x y s       , 0 ≤ s ≤ k ( α ),   ( 8 ) где  – значение первого элемента пути выталкиваний; t – промежуточное значение на пути выталкиваний; ) ( t u  , ) ( t v  , ) ( t x  , ) ( t y  – проекции координат положения элемента t на пути выталкиваний, построенном от  , на соответствующие оси в русской и французской нотациях. ) (  k – п роекция пересечения пути выталкиваний и кривой Вершика Керова на ось x (конец пути выталкиваний); ) ( s   – проекция на ось  y текущего положения в зависимости от значения первого элемента пути  и параметра s (аналога x ). На рисунке 1 представлена связь формул для вычисления предельной формы пути выталкиваний при  = 0.2 . Рис. 1. Предельная кривая пути выталкиваний для α = 0.2 ( выделена красным ) Проведена серия вычислительных экспериментов по модели рованию путей выталкиваний алгоритма RSK и их отклонений от соответствующих предельных форм. С помощью преобразования RSK генерировался набор случайных пар таблиц Юнга  P и Q размера n , распределённых по мере Планшереля. Затем, также с помощью преобразования RSK в таблицу P добавлялось значение α и вычислялись нормализованные координаты вытолкнутых клеток ( xi , yi ). Затем вычислялось среднеквадратичное отклонение координат пути выталкиван ий ( x , y ) от соответствующих предельных ( x* , y* ) . Для таблиц размера n = 10 6 для α от 0.1 до 0.9 с шагом 0.2 вычислялось среднеквадратичное отклонение и дисперсия отклонения экспериментальных значений от предельных кривых в зависимости от числа рассмотренны х таблиц. Графики отклонений изображены на рисунке 2. В результате этих вычислений было установлено, что для размера 10 6 достаточно брать 1000 таблиц, чтобы достичь приемлемый результат. В дальнейшем вычислительном эксперименте изучалась сходимость путей в ыталкиваний к теоретическим кривым с ростом размера таблиц. Рис. 2. Зависимость среднеквадратичного отклонения от числа рассмотренных таблиц юнга размера 10 6 для значений  = 0.1 ( ▬ ), 0.3 ( ▬ ), 0.5 ( ▬ ), 0.7 ( ▬ ), 0.9 ( ▬ ) Одним из результатов [4] является то, что отклонения от предельных форм при больших значениях n хорошо аппроксимируются формулой : 2 1 4 1 ) (       n b n a n f (9) Были вычислены значения параметров a , b и их точность Δ как максимальное отклонение кривых аппроксимации от экспериментальных путей выталкиваний. Для проведения эксперимента рассматривались таблицы размера  n  [105 , ..., 4 · 106] с шагом 10 5 . Для каждого размера генерировалось фиксированное число k пар табли ц P и Q : k = 10 4 для таблиц размера от 10 5 до 10 6 и k = 1000 для таблиц размера 11 · 10 5 до 4 · 10 6 . Затем, при помощи преобразования RSK , в таблицы P добавлялись значения   [0.1, ..., 0.85] с шагом 0.05. В таблицу 1 сведены параметры аппроксимирующей кр ивой. Таблица 1 Параметры кривой, аппроксимирующей отклонения путей выталкиваний от предельных форм α 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 a 0.244 0.270 0.285 0.296 0.302 0.303 0.305 0.304 b 0.191 0.184 0.213 0.236 0.264 0.325 0.319 0.331 Δ 0.000217 0.000239 0.000349 0.000301 0.000209 0.000249 0.000202 0.000298 α 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 a 0.296 0.289 0.281 0.266 0.253 0.233 0.210 0.179 b 0.475 0.597 0.622 0.826 0.914 1.136 1.457 1.925 Δ 0.000230 0.000211 0.000233 0.000294 0.000216 0.000270 0.000228 0.000167 По таблице легко заметить, что наибольшее отклонение достигается на значениях 0.4 и 0.45, минимальное – в 0.1 и 0.85. Вычислительный эксперимент хорошо сходится с результатами, полученными в [3], при этом сходимость к предельной кривой при увеличении размера таблицы достаточно медленна – главный член функции пропорционален 푛 − 1 4 .  

: бинарное отношение, однозначность, тотальность, инъективность, сюръективность Имеются два множества (X, Y) известных мощностей n и m. Требуется найти математические формулы для вычисления количества бинарных о тношений, обладающих заданными свойствами. Всего свойств четыре: 1. Однозначность ( unambiguity ) – каждому элементу из множества X сопоставляется не более одного элемента Y . 2. Тотальность ( totality ) – для каждого элемента из X существует сопоставляемый ему элеме нт из Y . 3. Инъективность ( injectivity ) – образы любых двух элементов из X различны. 4. Сюръективность ( surjectivity ) – для любого элемента из Y существует прообраз из множества X . Частные случаи комбинаций свойств представлены на рисунке 1. Для удобства обозна чения каждому конкретному набору свойств будет сопоставлена аббревиатура типа 푈푇퐼푆 , где в случае отсутствия какого либо свойства над соответствующей ему буквой будет поставлена черта. Например, 푈푇 퐼 ̅ 푆 – однозначное тотальное неинъективное сюръективно е отображение. Рисунок 1. Примеры отображений, обладающих различными свойствами В работе было использовано 3 различных подхода к получению формул. Первый заключался в явном подсчете для конкретной комбинации свойств. Второй заключался в идее, что можно рассмотреть отображения, обладающие только двумя свойствами: однозначность и тотальность, для которых легко получаются формулы. Тогда очевидно, что сумма некоторого набора отображений с четырьмя заданными свойствами должна равняться количеству отображений, обладающих двумя свойствами. Третий подход – соображения симметрии. Свойства прямого и обратного отношения переходят друг в друга следующим образом: 푈 → 퐼 , 퐼 → 푈 , 푇 → 푆 , 푆 → 푇 Это очевидно из определения данных свойств. Связь свойств прямого и обратного о тношений представлена ниже 1. 푈푇 퐼푆 ↔ 푈 푇 퐼푆 2. 푈푇퐼 푆 ̅ ↔ 푈 푇 ̅ 퐼푆 3. 푈푇 퐼 ̅ 푆 ↔ 푈 ̅ 푇 퐼푆 4. 푈푇 퐼푆 ̅ ↔ 푈푇 ̅ ̅ ̅ ̅ 퐼푆 5. 푈 푇 ̅ 퐼푆 ↔ см . 2 6. 푈 푇 ̅ 퐼 푆 ̅ ↔ 푈 푇 ̅ 퐼 푆 ̅ 7. 푈 푇 퐼 ̅ ̅ ̅ 푆 ↔ 푈 ̅ 푇 퐼 푆 ̅ 8. 푈 푇 퐼푆 ̅ ̅ ̅ ̅ ̅ ↔ 푈푇 ̅ ̅ ̅ ̅ 퐼 푆 ̅ 9. 푈 ̅ 푇 퐼푆 ↔ см . 3 10. 푈 ̅ 푇 퐼 푆 ̅ ↔ см . 7 11. 푈 ̅ 푇 퐼 ̅ 푆 ↔ 푈 ̅ 푇 퐼 ̅ 푆 12. 푈 ̅ 푇 퐼푆 ̅ ↔ 푈푇 퐼 ̅ ̅ ̅ ̅ ̅ 푆 13. 푈푇 ̅ ̅ ̅ ̅ 퐼푆 ↔ см . 4 14. 푈푇 ̅ ̅ ̅ ̅ 퐼 푆 ̅ ↔ см . 8 15. 푈푇 퐼 ̅ ̅ ̅ ̅ ̅ 푆 ↔ см . 12 16. 푈푇 퐼푆 ̅ ̅ ̅ ̅ ̅ ̅ ̅ ↔ 푈푇 퐼푆 ̅ ̅ ̅ ̅ ̅ ̅ ̅ Таким образом из 16 различных свойств достаточно исследовать всего 10, из которых 4 – самодвойственные, а оставшиеся 6 – двойственные. Формулы для двойственных случаев отлича ются только переменой мест переменных.    Для упрощения изложения решение будет разбито на два случая: когда m = n и когда 푚 ≠ 푛 . Для случая 푛 = 푚 диаграмма, представленная на рисунке 1 будет выглядеть как показано на рисунке 2: Рисунок 2. Примеры отношений, обладающих заданными свойствами, в случае 푛 = 푚 . Формулы для отношений 푈푇퐼푆 , 푈푇 퐼푆 ̅ , 푈푇 ̅ ̅ ̅ ̅ 퐼푆 , 푈 푇퐼푆 ̅ ̅ ̅ ̅ ̅ , 푈푇 ̅ ̅ ̅ ̅ 퐼 푆 ̅ , 푈푇퐼 ̅ ̅ ̅ ̅ ̅ 푆 , 푈 ̅ 푇 퐼푆 ̅ и 푈푇퐼푆 ̅ ̅ ̅ ̅ ̅ ̅ ̅ получаются посредством применения простых подходов, описанных ранее, поэтом у не будут приведены.  Рассмотрим отношение 푈 푇 ̅ 퐼 푆 ̅ . Поскольку множества отправления и прибытия равномощны, то частичность влечет за собой отсутствие сюръективности. Поэтому для получения формулы количества таких отношений была применена следующая идея: чтобы найти 푁 푈 푇 ̅ 퐼 푆 ̅ ( 푛 , 푛 ) достаточно рассмотреть все возможные способы убрать из множества отправления хотя бы один элемент. Тогда, после такой модификации, остается однозначное, тотальное, инъективное и не сюръективное отношение, для которого формула м ожет быть получена простым подсчетом. Тогда, учитывая, что из множества X можно убрать от 1 до n 1 различных элементов, получается следующая формула: 푁 푈 푇 ̅ 퐼 푆 ̅ ( 푛 , 푛 ) = ∑ 퐶 푘 푛 ⋅ 푛 ! 푘 ! 푛 푘 = 1 + 1 . Нахождение количества отношений с набором свойств 푈 ̅ 푇 퐼 ̅ 푆 потребо вало введения вспомогательной функции, которая позволила обеспечить сюръективность       푁 ( 푛 , 푚 ) = ( 2 푚 − 1 ) 푛 − ∑ 퐶 푘 푚 푁 ( 푛 , 푘 ) − 푚 푛 푚 − 1 푘 = 1 . Сюръективность достигается за счет идеи, схожей с приведенной для предыдущего отношения, только модифицируется множество прибытия, чтобы получить сюръективное отношение. Таким образом, если из общего количества отношений убрать те, которые являются сюръе ктивными для модифицированного Y, то останется искомое отношение.                         Таким образом 푁 푈 ̅ 푇 퐼 ̅ 푆 ( 푛 , 푛 ) = 푁 ( 푛 , 푛 ) . Далее был рассмотрен случай 푛 ≠ 푚 . Возможны два случая:  푛 > 푚 и 푛 < 푚 . Для различия в формулах исп ользованы верхние индексы B, L, соответствующие случаям, когда  푛 < 푚 и 푛 > 푚 соответственно. Возможные примеры для каждого случая приведены на рисунках 3а и 3б. Рисунок 3а. Примеры возможных отношений при m>n. Рисунок 3б. Примеры возможных отношений при m<n. В данном разделе формулы для случаев 푛 > 푚 и 푛 < 푚 связаны перестановкой переменных, соответствующих мощностям множеств. Например, 푁 푈푇퐼 푆 ̅ 퐵 ( 푛 , 푚 ) = 푚 ! ( 푚 − 푛 ) ! , 푁 푈 푇 ̅ 퐼푆 퐿 ( 푛 , 푚 ) = 푛 ! ( 푛 − 푚 ) ! . Для нахождения 푁 푈 푇 ̅ 퐼 푆 ̅ 퐿 ( 푛 , 푚 ) и , как следствие , 푁 푈 푇 ̅ 퐼 푆 ̅ 퐵 ( 푛 , 푚 ) использовалась описанная ранее идея с исключением элементов из множества отправления. Вычисление 푁 푈푇 퐼푆 ̅ 퐵 , 푁 푈푇 ̅ ̅ ̅ ̅ 퐼푆 퐿 , 푁 푈 푇퐼푆 ̅ ̅ ̅ ̅ ̅ 퐵 , 푁 푈푇 ̅ ̅ ̅ ̅ 퐼 푆 ̅ 퐿 , 푁 푈푇 퐼푆 ̅ 퐿 , 푁 푈푇 ̅ ̅ ̅ ̅ 퐼푆 퐵 , 푁 푈 푇퐼푆 ̅ ̅ ̅ ̅ ̅ 퐿 , 푁 푈푇 ̅ ̅ ̅ ̅ 퐼 푆 ̅ 퐵 , 푁 푈 푇퐼 ̅ ̅ ̅ 푆 퐿 , 푁 푈 ̅ 푇퐼 푆 ̅ 퐵 , 푁 푈 ̅ 푇 퐼푆 ̅ 퐿 , 푁 푈푇퐼 ̅ ̅ ̅ ̅ ̅ 푆 퐵 , 푁 푈 ̅ 푇 퐼푆 ̅ 퐵 , 푁 푈푇퐼푆 ̅ ̅ ̅ ̅ ̅ ̅ ̅ 퐵 не выходит за рамки описанных методов, поэтому не будет приведено. Для вычисления 푁 푈 ̅ 푇 퐼 ̅ S 퐵 и 푁 푈 ̅ 푇 퐼 ̅ S 퐿 была использована вве денная ранее вспомогательная функция:  푁 푈 ̅ 푇 퐼 ̅ S 퐵 ( 푛 , 푚 ) = 푁 ( 푛 , 푚 ) , 푁 푈 ̅ 푇 퐼 ̅ S 퐿 ( 푛 , 푚 ) = 푁 ( 푚 , 푛 ) . Для вычисления 푁 푈푇 퐼 ̅ S 퐿 и 푁 푈 ̅ 푇푈푆 퐵 была введена дополнительная функция, которая впоследствии оказалась числами Стирлинга второго рода (числами Моргана).     푆 ( 푛 , 푚 ) = 푚 푛 − ∑ 퐶 푘 푚 푆 ( 푛 , 푘 ) 푚 − 1 푘 = 1 , 푚 < 푛 . Обоснование данной формулы аналогично обоснованию вспомогательной функции 푁 ( 푛 , 푚 ) с точностью до того, что рассматриваемое отношение однозначное. 푁 푈푇 퐼 ̅ S 퐿 ( 푛 , 푚 ) = 푆 ( 푛 , 푚 ) , 푁 푈 ̅ 푇푈푆 퐵 ( 푛 , 푚 ) = 푆 ( 푚 , 푛 ) . 

: тропическая рекуррентная последовательность, тропическое предмногообразие, пак ет Gfan , последовательность Сомоса. Введение Тропическая математика является молодой областью современной математики , связанной с изучением полуколец с идемпотентным сложением . Несмотря на новизну, она уже нашла свое применение в алгебре, геометрии, математической физике, биологии [1], экономике [2], теории нейронный сетей [3], динамическом программировании, а также в других областях. Эта работа является продолжением работы [4], которая была посвящена тропическим линейным рекуррентным последовательнос тям. В рамках этой работы вычисляются тропические последовательности, ассоциированные с последовательностями Сомоса, в пакете Gfan. Цель ю данной работы, как и предыдущей, является проверка гипотезы Григорьева о стабилизации максимальных размерностей решени й систем тропических уравнений, заданных полиномами, которые зависят от длины рассматриваемой последовательности. Выполнение такой гипотезы позволяло бы вычислять размерности этих решений для систем произвольной длины. Gfan это программный пакет для вычи сления универсальных базисов Грёбнера, некоторых связанных с ним геометрических объектов (вееров Грёбнера) и тропических многообразий, разработанный в 2005 году А. Йенсеном, на основе алгоритмов, описанных и разработанных в его диссертации [5]. Пакет Gfan позволяет вычислять универсальные базисы Грёбнера, веера Грёбнера, тропические предмногообразия, многообразия, заданные системой тропических многочленов, и другие объекты тропической геометрии и теории базисов Грёбнера. В настоящий момент является самым мо щным программным средством для таких вычислений. Gfan распространяется в качестве стандартного пакета Linux, входит в состав дистрибутива Debian. Постановка задачи Одним из основных объектов тропической математики является тропическое полукольцо ( ℝ ∪ { − ∞ } , ⊕ , ⊗ ) . Это множество состоит из вещественных чисел c дополнительным элементом – минус бесконечностью. В тропическом полукольце классические операции сложения и умножения над вещественными числами заменяются на операции взятия максимума и классическое сложение с оответственно: 푥 ⊕ 푦 ∶ = max { 푥 , 푦 } , 푥 ⊗ 푦 ∶ = 푥 + 푦 . В тропической математике есть свои аналоги полиномиальной алгебры, линейной алгебры и других разделов математики [6]. В качестве тропического сложения можно рассматривать взятие минимума, тогда дополнительны м элементом ко множеству вещественных чисел будет плюс бесконечность. Пусть 푘 ≥ 2 натуральное и 훼 = { 훼 푖 | 1 ≤ 푖 ≤ [ 푘 / 2 ] } , 푥 = { 푥 푗 | − 푘 / 2 < 푗 ≤ [ 푘 / 2 ] } два множества независимых формальных переменных в количестве [ 푘 / 2 ] в первом случае и 푘 во втором. Посл едовательность рациональных функций Сомос 푘 от переменных из 훼 и 푥 , 푆 푘 ( 푛 ) = 푆 푘 ( 푛 ; 훼 ; 푥 ) ( 푛 ∈ ℤ ) , определяется рекуррентным соотношением 푆 푘 ( 푛 + [ 푘 + 1 2 ] ) 푆 푘 ( 푛 − [ 푘 2 ] ) = ∑ 훼 푖 푆 푘 ( 푛 + [ 푘 + 1 2 ] − 푖 ) 푆 푘 ( 푛 − [ 푘 2 ] + 푖 ) 1 ≤ 푖 ≤ 푘 / 2 . Впервые эту последовательность при 푘 = 6 , 훼 1 = 훼 2 = 훼 3 = 1 , 푥 − 2 = 푥 − 1 = 푥 0 = 푥 1 = = 푥 2 = 푥 3 = 1 рассмотрел Майкл Сомос в связи с изучением свойств эллиптический тэта функций [7]. При 푘 = 2 , 훼 = { 훼 1 } , 푥 = { 푥 0 , 푥 1 } рекуррентное соотношение выглядит как 푆 2 ( 푛 + 1 ) 푆 2 ( 푛 − 1 ) = 훼 1 푆 2 2 ( 푛 ) . И ндукцией по 푛 легко показать, что 푆 2 ( 푛 ) = 훼 1 푛 ( 푛 − 1 ) / 2 푥 0 1 − 푛 푥 1 푛 . В данной работе изучаются ассоциированные с 푆 푘 ( 푛 ) тропические последовательности 푝 푘 ( 푛 ) , удовлетвор яющие рекуррентному соотношению 푝 푘 ( 푛 + [ 푘 + 1 2 ] ) + 푝 푘 ( 푛 − [ 푘 2 ] ) = = min 1 ≤ 푖 ≤ 푘 / 2 { 푝 푘 ( 푛 + [ 푘 + 1 2 ] − 푖 ) + 푝 푘 ( 푛 − [ 푘 2 ] + 푖 ) } . Интересным является факт, что тропический аналог таких последовательностей связан с классическими последовательностями Сомоса нек оторым соотношением. В работе [8 ] доказано, что 푆 푘 ( 푛 ) является полиномом Лорана от начальных переменных 푥 푗 и обычным полиномом от 훼 푖 . Поэтому его можно записать в виде 푆 푘 ( 푛 ) = ( ∏ 푥 푗 푝 푘 ( 푗 ) ( 푛 ) − 푘 / 2 < 푗 ≤ 푘 / 2 ) 푃 푘 ( 푛 ) , где 푃 푘 ( 푛 ) = 푃 푘 ( 푛 ; 훼 ; 푥 ) – полиномы с целыми коэффициентами, а 푝 푘 ( 푗 ) ( 푛 ) – целочисленные последовательности. В данной работе будем рассматривать все решения последовательности 푝 푘 ( 푛 ) для конечного 0 ≤ 푛 ≤ 푠 . Для этого преобразуем тропическую рекуррентную последовательность в систему тропических полиномов. Решение для системы тропических полиномов будем находить с п омощью пакета Gfan , вычисляя для системы тропическое предмногообразие.  Подробные вычисления для тропических линейных рекуррентных последовательностей со всеми определениями представлены в [ 9 ] . Вычисление в пакете Gfan В данной работе рассматриваются послед овательности при 푘 = 4 . Для вычисления полиномов 푝 4 ( 푛 ) рассматриваются полиномы 푞 4 ( 푛 ) = ∆ 2 푝 4 ( 푛 ) = ∆ 푝 4 ( 푛 + 1 ) − ∆ 푝 4 ( 푛 ) = 푝 4 ( 푛 + 1 ) − 2 푝 4 ( 푛 + 1 ) + 푝 4 ( 푛 ) . Тогда тропические соотношения будут иметь вид 푞 4 ( 푛 − 1 ) + 푞 4 ( 푛 ) + 푞 4 ( 푛 + 1 ) + max { 0 , 푞 4 ( 푛 ) } = 0 . Для вычисления в пакете Gfan приведём данное соотношение в тропический полином. Пусть 푦 푖 = 푞 4 ( 푖 ) . Тогда получим max { 푦 푛 − 1 + 푦 푛 + 푦 푛 + 1 , 푦 푛 − 1 + 푦 푛 2 + 푦 푛 + 1 } = 푦 푛 − 1 ⊗ 푦 푛 ⊗ 푦 푛 + 1 ⊕ 푦 푛 − 1 ⊗ 푦 푛 2 ⊗ 푦 푛 + 1 . Для нахождения решений этого соотношения найдём тропические предмногообразия. Так как тр опические предмногообразия представляют собой множество негладкости тропического полинома, то трудностью для этого является равенство этого полинома нулю. Для решение этой проблемы добавим 0 как слагаемое в тропический полином 푦 푛 − 1 ⊗ 푦 푛 ⊗ 푦 푛 + 1 ⊕ 푦 푛 − 1 ⊗ 푦 푛 2 ⊗ 푦 푛 + 1 ⊕ 0 Можем заметить, что тропический полином max { 푦 푛 − 1 + 푦 푛 + 푦 푛 + 1 , 푦 푛 − 1 + 푦 푛 2 + 푦 푛 + 1 } достигает максимума, большего нуля, только в конечном количестве случаев. Из за чего добавление слагаемого 0 не влияет на размерность тропического предмногообраз ия. Данное соображение проверено экспериментальным путём в пакете Gfan для вычисленных конечных последовательностей.  Для вычисления тропических предмногообразий составим систему тропических полиномов для всех соотношений при 1 ≤ 푛 ≤ 푠 − 1 . Тропические предм нообразия вычислим с помощью функции gfan _ tropicalintersection пакета Gfan [10] . Обозначим размерность пространства решений 푑 푠 . Полученные размерности пространства решений представлены в табл. 1. Таблица 1 Размерности пространства решений 푠 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 2 0 2 1 2 2 푑 푠 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5 6 6 6 6 7 П олученные решения соответствуют вычислениям, проведённым в [11]. Заключение По вычисленным тропическим предмногообразиям можем сделать предположение, что 푑 푠 = [ 푠 − 2 4 ] + 2 . Тогда для таких последовательностей тропическая энтропия [ 9 ] принимает значение 퐻 = 1 4 . По результатам вычислений можно предположить, что для тропических последовательностей, ассоциированных с последовательностями Сомоса 푘 , 퐻 = 1 푘 . Для систем троп ических полиномов 푦 푛 − 1 ⊗ 푦 푛 ⊗ 푦 푛 + 1 ⊕ 푦 푛 − 1 ⊗ 푦 푛 2 ⊗ 푦 푛 + 1 при 1 ≤ 푛 ≤ 푠 − 1 тропическая энтропия 퐻 = 0 , так как пространство решений не возрастает. Полученные результаты согласуются с гипотезой Григорьева о стабилизации максимальных размерностей решений систем тропических уравнений .  

: нейронные сети, тропическая математика, глубокое обучение Введение В последние годы тропическая математика стала часто применяться для построения нейронных сетей. Она предоста вляет новые методы для решения задач, связанных с оптимизацией и обработкой данных, что может привести к улучшению точности и скорости работы нейронных сетей [1]. Тропическая математика раздел математики, который изучает свойства функций, определенных на множестве, в котором заданы операции максимума (минимума) и сложения. Она имеет широкое применение в различных областях, таких как оптимизация, теория графов, динамические системы и теория управления. Одним из способов использования тропической математики в нейронных сетях является замена классической алгебры на тропическую алгебру [2]. Целью данной работы является исследование  точности нейронных сетей с тропическими слоями в сравнении с классическими нейронными сетями. Базовые определения Пусть min {}    , max {}    тогда: min алгеброй будет называться полукольцо вида   min ,,  , где  операция тропического сложения, определенная как min{ , } x y x y  , операция тропического умножения, определенная как x y x y  , а max алгеброй – полукольцо вида   max ,,  , где тропическое сложение определено как max{ , } x y x y  [3] . Нейронные сети с тропическими слоями Тропические слои – слои нейронной сети, в которых, в качестве операции сложения используется выбор максимума, а в качестве умножения – алгебраическое сложение. В качестве примера нейронной сети с тропическим слоем рассмотрим простую арх итектуру с одним входным слоем, одним скрытым слоем и одним выходным слоем. Сначала определяются входные данные, которые будут поступать на входной слой нейронной сети. Для примера выбран набор данных, состоящий из двух входных значений 푥 1 и 푥 2 , которы е представлены вектором [ 푥 1 , 푥 2 ] . Затем создается скрытый слой, состоящий из нескольких нейронов, каждый из которых имеет свой весовой коэффициент 푤 1 и 푤 2 , а также смещение b . Для каждого нейрона в скрытом слое вычисляется сумма произведений входных знач ений на соответствующие весовые коэффициенты, а затем к этой сумме применяется операция выбора максимума. Таким образом, для одного нейрона в скрытом слое можно записать выражение: ℎ = max ( 푤 1 , 1 푥 1 + 푤 1 , 2 푥 2 + 푏 1 , 푤 2 , 1 푥 1 + 푤 2 , 2 푥 2 + 푏 2 ) . Затем создается выходной слой, состоящий из одного нейрона. Также определяется весовой коэффициент 푤 и смещение 푏 для этого нейрона. Для выходного нейрона вычисляется сумма произведений значений скрытого слоя на соответствующие весовые коэффициенты и к э той сумме применяется операция выбора максимума. Таким образом, можно записать выражение для выходного нейрона: 푦 = max ( 푤 ℎ + 푏 ) В литературе известны следующие преимущества использования нейронных сетей с тропическими слоями: 1. Более быстрое обучение. Исполь зование тропических слоев может привести к более быстрому обучению нейронной сети, так как она позволяет сократить количество операций, которые необходимо выполнить для достижения определенных результатов [4] . 2. Улучшенная точность. Использование тропичес кой математики может привести к повышению точности работы нейронной сети, так как она позволяет учитывать не только значения функций, но и их производные [5 6 ] . 3. Более простая архитектура. Тропическая математика может помочь упростить архитектуру нейронн ой сети, так как она позволяет заменить сложные операции, такие как умножение и деление, на более простые операции, такие как сложение и вычитание. Архитектура использованных нейронных сетей В качестве эталона была выбрана классическая модель Linear + ReLU + Linear. Такая архитектура была выбрана исходя из предположения, что слои, использующие тропические вычисления, при некотором приближении ведут себя как функция активации ReLU [2] . Для реализации тропических вычислений были использованы тензоры фреймворка PyTorch и созданы два линейных слоя с min алгеброй ( Min ) и max алгеброй ( Max ) . Весовые функции и функции смещения были подобраны автоматически с помощью встроенного в PyTorch модуля NN [ 7 ]. Обучение нейронной сети проводилось на наборе данных «Heart Disease dataset» – использующийся в машинном обучении для диагностики болезней сердца. Для эксперимента были выбраны три различных архитектуры: Max+Max, Min+Max и смешанная модель Linear +Min +Max+ Linear . Каждая из моделей обучалась 100 эпох с одинаковым количеством входных и выходных нейронов в слое для линейных и тропических слоев. В качестве оптимизатора был выбран SGD, в качестве функции потерь – crossentropyloss. Для вычисления точности ра боты использовался метод accuracy . Результаты обучения Для сравнения точности обучения были построены графики, представленные на рис.1. У классической модели точность возрастает монотонно, а функция точности тропических моделей ведет себя как ступенчатая функция. При этом точность модели Min + Min с после 16 эпохи стабилизировалась, следовательно, модель перестала обучаться. Рис. 1. Сравнение точности классической и тропических моделей с использованием оптимизатора SGD Среди полностью тропических моделей л учшую точность показала сеть M in +Max. Но улучшения точности по сравнению с классической не было достигнуто ни у одной тропической модели. При этом смешанной модели получилась на 0,2% выше, чем у модели, не использующей в архитектуре тропические слои. Итого вые результаты полученной точности моделей после обучения представлены в табл. 1. После получения результатов было проведено сравнение этих же моделей с использованием оптимизатора Adam. Полученные графики представлены на рис. 2.  Рис.2. Сравнение точности классической и тропических моделей с использованием оптимизатора Adam Точность классической и Max + Max моделей выросла на 0,8%, а вот точность модели Min + Max снизилась на 0,4%. При этом, в классической модели стали наблюдаться скачки точности, у Ma x + Max – стабилизация, а у Min + Max – убывание со скачками после 35 эпохи. Точность смешанной модели выросла на 0,6%, а график очень похож на график классической модели. Откуда можно сделать вывод, что для данной задачи использование оптимизатора Adam снизил о способность к обучению у сетей с тропическими слоями, но повысило итоговую точность моделей с использованием слоя Linear . Результаты полученной точности моделей после обучения представлены в табл. 1. Таблица 1 Точность моделей с использованием оптимизато ра Adam Оптимизатор Архитектура сети Точность на тестовых данных SGD Linear + ReLU + Linear 77,3% Max+Max 70 , 7% Min+Max 69 , 7 % Linear+Min+Max+Linear 77,5% Adam Linear+ReLU+Linear 76, 5 % Max+Max 67,9 % Min+Max 54,2% Linear+Min+Max+Linear 7 6 , 9 % Выводы В результате проделанной работы было проведено сравнение нейронной сети с архитектурой : Linear+ReLU+Linear, с моделями, содержащими комбинации тропических слоев: Max+Max , Min+Max и Linear +Min+Max+ Linear . Сравнение показало, что архитектура сети, сос тоящая только из тропических слоев, не дает улучшения в точности обучения. При этом смешанная архитектура, которая использует линейные и тропические слои показывает себя лучше, чем нейронная сеть, в которой тропических слоев нет. Смешанная сеть показала пр ирост в 0,2% с использованием оптимизатора Adam и прирост в 0,4% с использованием оптимизатора SGD . Из такого сравнения можно сделать вывод, что итоговая точность нейронной сети зависит не только от входных параметров (размер  входного слоя, количество нейр онов в скрытом слое), но и от функции оптимизации, используемой для данной архитектуры. Кроме полносвязных нейронных сетей, тропические слои можно использовать в качестве сверточных слоев. Например, в работе [ 8 ] были использованы сверточные нейронные сети с тропическими слоями, которые показали улучшение точности модели в сравнении с обычными сверточными сетями. Дальнейшие исследования будут направлены на применение тропических слоев в более сложных архитектурах, а также на подбор параметров обучения, с помощью которых можно будет добиться значительного улучшения точности работы нейронных сетей, содержащих тропический слой. 

: Диаграмма Юнга, таблица Юнга, размерность диаграммы Юнга, формула крюков Введение Проблема нахождения диаграммы Юнга максимальной размерности была поставлена в 1968 году [ 1 ] и до сих пор является открытой. Известно, что с ростом размера диаграмм их фронт стремится к кривой Вершика Керова [ 2 ], однако в данной работе исследуются геометрические свойства диаграмм Юнга конечного размера . Для описания формы диаграммы Юнга введем понятие базовой поддиаграммы. Базовой поддиаграммой sym A диаграммы A называется максимальная симметричная поддиаграмма A . Клетки диаграммы A , не входящие в ее базовую поддиаграмму, можно разделить на два множества: клетки, лежащие ниже прямой yx  ( d A ), и клетки, лежащие выше этой прямой ( u A ). Во время исследования диаграмм больших размерностей, полученных в предыдущих работах [ 3 , 4 ] , была выдвинута гипотеза о том, что у диаграммы максимальной  размерности либо u A либо d A отсутствует. Другими словами, все клетки диаграммы максимальной размерности, не входящие в sym A , расположены с одной стороны от прямой yx  . Алгоритм преобразования диаграмм Юнга Для доказательства приведенной выше гипотезы был разработан алгоритм преобразования диаграмм Юнга. Он имеет схожую природу с ранее разработанными алгоритмами [ 4 ] : диаграмма A размера n превращается в диаграмму  C того же размера. При этом размерность диаграммы C больше или равна размерности диаграммы A . Алгоритм получает на вход диаграмму A , которая состоит из своей базовой поддиаграммы sym A , клеток d A , расположенных ниже прямой yx  , и клеток u A , расположенных выше этой прямой. На первом шаге алгоритм превращает диаграмму A в диаграмму B , состоящую только из своей базовой симметричной поддиаграммы sym B и клеток u B , расположенных выше прямой yx  . Рассмотрим строку с номером t , содержащую клетки из d A . Если число этих клеток равно 2 m или 21 m  , то мы перемещаем m клеток из этой строки в t ый столбец. Пример первого шага алгоритма показан на рис. 1. Синим цветом изображены клетки u A , красным цветом клетки d A , которые мы перемещаем, а зеленым – клетки d A , которые остаются на месте. Рис. 1. Первый шаг алгоритма преобразования диаграмм Юнга В получившейся после первого шага диаграмме B , все оставшиеся на месте клетки d A входят в базовую поддиаграмму sym B диаграммы B , т.к. они симметричны перенесенным клеткам из d A . Таким образом, диаграмма B состоит только из sym B и клеток u B , расположенных выше прямой yx  . На втором шаге алгоритм преобразует диаграмму B , в диаграмму C , состоящую только из своей базовой поддиаграммы sym C и клеток d C , лежащих ниже прямой yx  .  Более того, в каждой строке может быть только одна клетка из d C . Данный шаг полностью аналогичен первому. Только в этом случае мы перемещаем клетки из t ого столбца в t ую строку. Пример второго шага алгоритма показан на рис. 2. Красным цветом выделены перемещаемые клетки из u B , а зеленым – клетки из u B , которые остаются на месте. Рис. 2. Второй шаг алгоритма преобразования диаграмм Юнга Оставшиеся на месте клетки из u B входят в базовую поддиаграмму sym C диаграммы  C , т.к. им будут симметричны перемещенные на втором шаге клетки. Однако не у всех перемещен ных клеток есть симметричная им оставшаяся клетка. Если в t ом столбце диаграммы B было нечетное число клеток из u B , то в t ой строке диаграммы  C будет ровно одна клетка, не входящая в sym C . Следовательно, алгоритм создает диаграмму, состоящую только из своей базовой поддиаграммы, к каждой строке которой добавлено не более одной клетки, лежащей ниже прямой yx  . Размерности исходной и модифицированной диаграммы Докажем, что размерность диаграммы, получившейся в результате представленного выше алгоритма, больше размерности исходной диаграммы. Для этого необходимо ввести определени е крюка клетки. Крюк клетки ( , ) ij в диаграмме A это сама клетка ( , ) ij , все клетки, лежащие в столбце i выше ( , ) ij и лежащие в строке j правее ( , ) ij . Длина крюка – количество клеток в крюке. Доказательство основывается на формуле крюков [ 5 ]. ( , ) ! dim( ) , ( , ) A i j A n A h i j    ( 1 ) где n размер диа граммы A , ( , ) ij координаты клетки диаграммы, а ( , ) A h i j длина крюка клетки ( , ) ij . Докажем , что dim( ) dim( ) BC  . Из формулы ( 1 ) следует, что нам достаточно показать, что ( , ) ( , ) ( , ) ( , ) BC i j B i j C h i j h i j    . Для каждого t докажем, что произведение длин крюков клеток крюка ( , ) B h t t больше либо равно произведению длин крюков клеток крюка ( , ) C h t t , т.е. ( , ) ( , ) ( , ) ( , ) ( , ) ( , ) BC BC i j h t t i j h t t h i j h i j    . Для этого разделим клетки ( , ) B h t t и ( , ) C h t t на 4 множества: клетки, перемещаемые в ходе алгоритма ( m B и m C ), клетки u B , остающиеся на месте в ходе алгоритма ( R ) и клетки sym B крюка ( , ) B h t t ( S ). Тогда ( , ) ( , ) ( , ) ( , ) mm BC i j B i j C h i j h i j    ( 2 ) и ( , ) ( , ) ( , ) ( , ) ( , ) ( , ) ( , ) ( , ). B C  C B i j R i j R i j S i j S h i j h i j h i j h i j          ( 3 ) Из формул ( 2 ) и ( 3 ) следует, что ( , ) ( , ) ( , ) ( , ) ( , ) ( , ) BC BC i j h t t i j h t t h i j h i j    для каждого t , а значит dim( ) dim( ) BC  . Причем равенство достигается только в случае, когда B симметрично  C . Аналогично доказывается, что dim( ) dim( ) AB  . А именно, доказательство неравенства dim( ) dim( ) uu A A B A  полностью аналогично представленному выше доказательству. Далее мы добавляем по одной клетке из u A к обеим диаграммам. При каждом добавлении клетки размерность второй диаграммы растет сильнее размерности первой диаграммы. Поэтому получаем, что dim( ) dim( ) AB  . Выводы Был разработан алгоритм, позволяющий по исходной диаграмме Юнга получить нов ую диаграмму того же размера, но с большей размерностью , не производя никаких вычислений. Из этого алгоритма вытекает, что диаграмма A максимальной размерности состоит только из своей базовой симметричной поддиаграммы и клеток, рас положенных с одной стороны от прямой yx  . Более того, если эти клетки лежат снизу от yx  , то в каждой строке находится не более одной клетки не принадлежащей базовой поддиаграмме диаграммы A . Аналогично, если эти клетки лежат сверху от yx  , то в каждом столбце находится не более одной клетки не принадлежащей базовой поддиаграмме диаграммы A . Это свойство позволяет значительно ускорить алгор итмы нахождения диаграммы максимальной размерности. 

: система рекомендаций, машинное обучение, обработка естественного языка, граф цитирования Постановка задачи В данной работе была создана система, которая может составить список научных статей с похожими характеристиками относительно заданной. Система рекомендаций статей основана на алгоритмах машинного обучения без учителя, а и менно кластеризацию рёбер в графе цитирования. В ходе работы были применены алгоритмы, такие как k medoids и k means. Для обучения системы были использованы аннотации статей и граф цитирования. Модель была обучена на графе цитирования arXiv HEP TH теории физики высоких напряжений. Данный граф был взят из электронного архива научных статей arxiv.org и содержит 27770 статей и 352807 цитирований. В работе рассматривается датасет, содержащий около 30 000 файлов, где каждый представляет собой текстовый докумен т, содержащий авторов, дату публикации, название и аннотацию. Далее в работе такой документ будет называться статьей. Архив с данными файлами рассортирован по папкам, где каждая папка называется в соответствии году выпуска статьи. Также в архиве содержится список строк, каждая из которых состоит из двух чисел идентификаторов статей. На основе такого файла строится ориентированный граф цитирования, где первое число идентификатор указывает на статью, из который исходит ссылка, а второе число идентификатор – к уда ведет ссылка. Важно отметить, что в исходных данных нет рекомендованных статей, т.е. у нас отсутствуют “правильные” ответы . Рекомендательная система Рекомендательная система представляет комплекс алгоритмов, программ и сервисов, задача которого предс казать, что может заинтересовать того или иного пользователя. В основе работы лежит информация о профиле человека и иные данные. Термин «проблема холодного старта» относится к ситуации, когда возникает необходимость предоставления начальных оценок до того , как алгоритм сможет определить релевантные рекомендации. Такая проблема характерна для рекомендаций на основе содержания. Важно отметить, что рассматриваемый датасет содержит информацию только о статьях, что и вызывает затруднения в создании информационн ой системы. То есть, на основе только статей и связи между статьями полноценную рекомендательную систему создать невозможно, необходима дополнительная информация о пользователях. [1] Рассматриваемый датасет содержит информацию только о статьях, поэтому в р аботе рассматривалась реализация content based system. Фильтрация на основе контента в качестве входных данных содержит множество пользователей и множество ключевых слов, которыми были помечены объекты интереса. Задача систем рекомендаций, основанных на ко нтенте вычислить множество объектов, которые наиболее близки к категориям, которыми интересуется текущий пользователь . Обработка естественного языка Для того, чтобы разработать систему, которая позволяет получить перечень научных статей, схожих с заданно й по ряду признаков, нам прежде всего необходимо рассмотреть смысловое содержание каждой статьи, то есть нужно выполнить обработку естественного языка (NLP). Данная технология машинного обучения дает возможность интерпретировать человеческий язык в более п онятный для обработки компьютером. NLP позволяет классифицировать текст и извлекать из него необходимую информацию, например ключевые слова в статьях. В данной работе рассматривается предобработка данных: токенизация и лемматизация. Токенизация по словам – это процесс разделения предложений на слова компоненты. Эти фрагменты или токены очень полезны для поиска закономерностей и рассматриваются в качестве основного шага для лемматизации. При этом мы чистим текст от стоп слов бесполезных для анализа, но пр исутствующих практически в каждом тексте. Это предлоги, артикли и другие служебные части речи. [4] Лемматизация – это процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме – лемме. Важно отметит ь, что лемматизация учитывает контекст и преобразует слово в его значимую базовую форму, в отличие от стемминга, который избавляется от, например, окончания ing в английском языке. Если использовать стемминг на слове “caring”, слово будет приведено в форм у “car”, что неверно, т.к. слово образовано от “care”. Лемматизация учитывает эти аспекты и благодаря этому слова приводятся без таких ошибок, насколько это возможно. [2] С помощью методов NLP можно получить перечень научных статей, схожих с заданной по кл ючевым словам и смысловой нагрузке. Именно методы обработки естественного языка, которые описаны выше, позволили нам вычленить из каждой статьи ключевые слова. Далее, используя ориентированный граф цитирования, необходимо определить, какие статьи мы можем рекомендовать читателю. Для этого был реализован следующий алгоритм: 1. Находим все статьи, на которые ссылается текущая (выбираем все рёбра в графе, начальной вершиной которых является текущая статья); 2. В каждой найденной статье определяем ключевые слова и их частотность; 3. Выявляем пересечения такие слова, которые присутствуют и в ссылающейся статье, и в той, на которую ссылаемся. При этом учитываем частотность; 4. На основе наибольшего числа пересечений включаем статью в список рекомендации . Алгоритмы машинн ого обучения После предобработки текстовой информации статей в данной работе были реализованы такие алгоритмы кластеризации как k means и k medoids. Данные алгоритмы принимают входной параметр k и разбивают пространство данных на k кластеров таких, что меж ду объектами одного кластера сходство максимально, а между объектами разных кластеров минимально. Сходство измеряется по отношению к некоторому центру кластера как дистанция от рассматриваемого объекта до центра. Основное различие между этими методами закл ючается в способе определения центра кластера. В алгоритме k means сходство рассматривается по отношению к центру масс кластера – среднему значению координат объектов кластера в пространстве данных. Алгоритм k medoids, в отличие от k means, использует для представления центра кластера не центр масс, а представительный объект – один из объектов кластера. [3] В качестве объектов для кластеризации рассматриваются точки на плоскости. На оси абсцисс откладываем количество ребер, где есть эта вершина. На оси орди нат средний вес всех дуг вершины, который получаем как рассчитанный вес дуг между всеми соседями данных вершин и делим его на количество всех соседей. После стандартизации данной выборки точек используем алгоритмы k means и k medoids. На рис.1. представлен а точечная диаграмма результатов кластеризации k means, где разные цвета точек обозначают принадлежность точек к разным кластерам. Рис.1. Полученные результаты кластеризации k means. В работе мы столкнулись с логической ошибкой выбранных данных. Так как изначально алгоритмы k means и k medoids используют в качестве объекта точку, а оси полученных точек зависят от друг друга, то выделение кластеров получается неверным. Например, рассматриваем статью про квантовые технологии, которая ссылается на другую ста тью, где совпадает два слова из аннотации, то координата такой точки (1;2). А вторая статья про солнечные системы, которая ссылается на одну другую статью, где тоже совпадает два слова из аннотации, то и ее координата (1;2). Так, по выбранным данным обе ст атьи, не похожие по смыслу, будут находиться в одном кластере. Заключение В рамках данной работы был разработан метод, позволяющий предложить читателю текущей статьи несколько схожих с заданной по ряду признаков. Работу с методами кластеризации можно развить, использовав другие алгоритмы. Например, рассматривать не только соседей первого порядка, но и общих соседей двух статей вне зависимости от того, есть ли между ними ребро. 

: алгоритм ORB , алгоритм FAST , алгоритм BRIEF , алгоритм нахождения GLCM и текстурных признаков, алгоритм SLIC , алгоритм Efficient Graph Based I mage Segmentation Введение Задача вскрытия объектов изображения является подзадачей при решении задач компьютерного зрения, связанной с нахождением объектов на изображении. Проблемой является отделение объектов от окружающего ландшафта. Задача решается в у словиях дополнительных ограничений — на борту небольшого по размеру дрона, соответственно, в условиях ограничения на объем потенциальных вычислительных мощностей на борту.  Также процесс получения информации о вскрываемых объектах должен происходить в реаль ном времени (1 – 10 раз в секунду). В работе сделан акцент на использование математических методов вскрытия объектов на изображении при использовании малых вычислительных мощностей. Алгоритм на основе обнаружения особых точек и применения дескрипторов особ ых точек Данный алгоритм основан на поиске особых точек при помощи алгоритма ORB[1] и алгоритме Хафа[2]. При идеальных входных данных оба алгоритма должны полностью описывать искомый объект точками и линиями соответственно. Однако у алгоритма Хафа есть нед остаток: его массив определяет параметры прямых без их протяженности. Алгоритм состоит из нескольких этапов: входное растровое изображение 640×480, пиксели которого размываются по среднему значению интенсивности соседних в окрестности 5 × 5 . Далее изображение переводится в черно белый формат для применения на нем алгоритма ORB. По количеству полученных особых точек выбирается решение по использованию алгоритма Хафа: Если особых точек достаточно, применяется алгоритм Хафа. Полученные линии уточняются по длине ос обыми точками, находящимися в диапазоне разброса. Координаты концов уточненных линий Хафа разбиваются при помощи иерархической кластеризации на группы с типом связи Ward[3]. Размер кластера зависит от объема концов уточненных линий Count = ln ( p ) , где p – количество ко нцов. Если особых точек недостаточно, то проводится иерархическая кластеризация с количеством групп, равным 12, и типом связи Ward. Она сводит к минимуму максимальное расстояние между наблюдениями пар кластеров. Алгоритм на основе нахождения GLCM и текстур ных признаков В ходе выполнения алгоритма происходит определение похожих текстур в изображении, выделяются текстуры, не являющиеся фоном, по полученным областям строится бинарная маска, либо bounding box’ы. Этапы алгоритма изменение размера исходного изо бражения до необходимого; квантование уровней интенсивности пикселей на несколько уровней для уменьшения размеров матрицы GLCM; вычисление GLCM [6] для частей изображения (сегментов), полученных в результате разбиения исходного изображения сеткой размера 7 × 7 пикселей; вычисление среднего значения каждой матрицы GLCM [4], составление карты этих значений; исключение из рассмотрения сегментов, для которых значения получились меньше порогового; объединение оставшихся сегментов 7 × 7 , расположенных достаточно близко д руг к другу; исключение малых по размеру сегментов; выделение оставшихся сегментов bounding box’ами. Алгоритм на основе выделения суперпикселей Идея алгоритма — искомые объекты имеют цвета, отличающиеся от цветов фона. В ходе выполнения алгоритма происходи т выделение суперпикселей [5] алгоритмами SLIC [6] или Efficient Graph Based Image Segmentation [7], кластеризация полученных сегментов в пространстве RGB при помощи алгоритма DBSCAN [8]. Сегменты, оказавшиеся в одном кластере, объединяются. Новые сегменты отражают местонахождение потенциальных объектов. Этапы работы алгоритма изменение размера исходного изображения до необходимого; применение алгоритмов выделения суперпикслей; применение алгоритма  DBSCAN к векторам в пространстве RGB (вектора соответству ют средним цветам полученных сегментов); выделение сегментов, удовлетворяющих условию прохождения порога по размеру, bounding box’ами. Пример работы алгоритмов На рис.1 представлены примеры работы алгоритмов на некоторых фотографиях местности. В первой кол онке представлены результаты работы алгоритма на основе обнаружения особых точек, во второй — алгоритма на основе нахождения GLCM, в третьей — алгоритма на основе выделения суперпикселей. Среднее время работы программ — 0.23 сек, 1 сек и 0,95 сек соответст венно. Можно заметить, что первый алгоритм, работая за наименьшее время, дает точный, но не самый полный результат, тем не менее, с наименьшим количеством ложноположительных оценок. Второй алгоритм, работая медленнее первого, распознает большее количество правильных объектов, однако работает нестабильно на некоторых изображениях. Третий алгоритм распознает наибольшее количество объектов и работает быстрее, чем второй, но выдает наибольшее количество ложноположительных результатов. Рис. 1. Примеры работы алгоритмов на основе особых точек, GLCM и суперпикселей. Из приведенных на рис. 1 изображений видно, что разные алгоритмы находят разные паттерны в изображениях, выбор конкретного алгоритма зависит от вида решаемой задачи. В будущем планируется усовершенст вование работы алгоритмов: улучшение способности к распознаванию объектов, находящихся около края изображения и имеющих  темный оттенок для алгоритма на основе обнаружения особых точек и применения дескрипторов особых точек; повышение стабильности работы ал горитма на основе вычисления GLCM; уменьшение количества ложноположительных результатов для алгоритма на основе выделения суперпикселей. 

: обнаружения вторжений, преобразование табличных данных, изображение в градациях серого , сверточные нейронные сети Вступление Широкое применение глубоких нейронных сетей объясняется их способностью выявлять скрытые нелинейные связи между анализируемыми признаками. В настоящее время существует множество исследований, посвященных проблеме преобразования табличных данных без таких связей в изображения с целью применения глубоких нейронных моделей и использования преимуществ пре дварительно обученных моделей [ 1 , 2 , 3 ]. Входные данные в задачах обнаружения сетевых вторжений обычно представлены ве ктором числовых значений. Существует лишь несколько подходов, использующих признаки на основе изображений для обнаружения сетевых атак [ 2, 4 , 5 , 6 ], и все они используют линейное преобразование табличных данных, таких как статистика сетевых потоков, извлеченн ая из файлов PCAP ( Packet Capture ). В настоящей работе рассматриваются три различных подхода к формированию изображения на основе анализа статистик сетевого трафика: прямое преобразование, нелинейное преобразование DeepInsight [ 1 ] и линейное преобразование IGDT, в основе которого лежит оценка попарного расстояния между исследуемыми признаками , и оценивается влияние способа формирования изображения на эффективность обнаружения вторжений . Анализ методик преобразования табличных данных в изображения Изображен ия в градациях серого – это полутоновое изображение, которое имеет только один канал, который имеет только один канал яркости, и каждый пиксель кодирует информацию о яркости 8 битами, таким образом он принимает значения в диапазоне от 0 до 255. Для построе ния такого изображения для числовых данных необходимо выполнить масштабирование значений атрибутов в диапазон от 0 до 255, при этом значение 0×0 соответствует черному цвету, им кодируется минимальное значение атрибута, а значение 0×FF – белому цвету и макс имальному значению атрибута, соответственно. Однако  ключевым аспектом в этой процедуре является способ компоновки пикселей или определение пикселя на изображение, состояние которого кодируется заданным атрибутом. В настоящей работе рассматриваются три разл ичных способа построения изображения на основе вектора входных числовых данных: прямое преобразование, нелинейное преобразование и линейное преобразование на основе оценки попарного расстояния между признаками. Прямое преобразование Прямое преобразование это один из методов преобразования табличных данных в изображения, который состоит в том, что сначала данные нормализуются, после чего происходит построчное преобразование в изображения. В данном методе данные разбиваются на небольшие блоки, каждый из к оторых преобразуется в изображение. Каждый столбец из блока представляет собой пиксель в изображении. После этого изображения проходят через сверточную нейронную сеть для обнаружения вторжений. Ключевым преимуществом данного преобразования является простот а реализации, а также отсутствие дополнительных операций с данными, требующихся для настройки преобразования . Недостатком же являются возможность потери информации из за низкого разрешения изображений. Преобразование DeepInsight DeepInsight это алгорит м построения изображений , в основе которого лежит построение проекции многомерных данных в двумерное пространство. Идея DeepInsight заключается в том, чтобы сначала преобразовать входной вектор, не являющийся изображением, в картинку , а затем подать его в архитектуру CNN для предсказ ания или классификации. Иллюстрация этого процесса приведена в рис.1 , где вектор признаков x, преобразуется в матрицу признаков M с помощью преобразования T. Расположение признаков в декартовых координатах зависит от сходства пр изнаков. После определения местоположения каждого признака в матрице признаков, затем сопоставляются значения выражений или признаки. Это позволит создать уникальное изображение для каждого образца (или вектора признаков). Затем этот набор из матриц призна ков обрабатывается в архитектуре CNN для обучения модели и прогнозирования. Рис. 1. Преобразование из вектора признаков в матрицу признаков К преимуществам использования данного преобразования табличных данных в изображения является возможность выявит ь нелинейные связи между атрибутами, но за счет того, что происходит снижение размерности данных возможна потеря информации и наложение атрибутов в один пиксель. Преобразование IGTD IGTD (image generator for tabular data) генератор изображений для таблич ных данных, для преобразования табличных данных в изображения путем присвоения перестановки признак ов с последующей генерацией изображения линейным способом с учетом перестановки. Перестановка выполняется таким образом, чтобы схожие признаки располагались близко друг к другу на изображении. Алгоритм ищет оптимизированное назначение, минимизируя разницу между попарно ранжирова нными расстояни ями между признаками и попарно ранжирова нными расстояний между ассоциированными с ними пикселями на изображении. Таким образом, в данном способе каждый пиксель изображения также, как и в линейном подходе ассоциирован с некоторым атрибутом, отсутствуют «пустые» зоны изображения, с которыми не связаны ни один атрибут, как в случае применения преобразования DeepInsight . Экс перименты Для оценки влияние способа формирования изображения на эффективность обнаружения вторжений был проведен ряд экспериментов. В качестве экспериментального набора данных использовался набор CICIDS ( https://www.unb.ca/cic/datasets/ids 2017.html ) . По сле преобразования табличных данных в изображения, полученные изображения проходят через сверточную нейронную сеть для обнаружения вторжений. В данной статье для обнаружения вторжений используется четырехслойная сверточн ая нейронн ая сеть со следующей арх и т ектурой: два сверточных слоя (Conv2D), два слоя пулинга (MaxPooling2D), один слой преобразования данных (Flatten), и два полносвязных слоя (Dense). Рассмотрим подробнее каждый из слоёв:  Сверточный слой (Conv2D) с 16 фильтрами (количество выходных каналов) и ядром размером 3x3. Он принимает на вход черно белое изображение размером 9x9 пикселей и использует функцию активации ReLU для нелинейного преобразования данных. Он отвечает за изучение определенных признаков на изображении.  Слой пулинга (MaxPooling2D) с размером окна 2x2. Он выполняет операцию максимальной подвыборки и уменьшает размерность изображения в два раза. Он отвечает за уменьшение размерности данных и избавление от избыточной информации.  Сверточный слой (Conv2D) с 32 фильтрами и ядром размером 3x3. Он использует функцию активации ReLU и принимает на вход результат операции пулинга. Он отвечает за изучение более сложных признаков на изображении.  Слой пулинга (MaxPooling2D) с размером окна 1x1. Он выполняет операцию максимальной подвыборки и умень шает размерность изображения до минимально возможной. Он отвечает за дальнейшее уменьшение размерности данных и улучшение эффективности вычислений.  Слой преобразования данных (Flatten). Он преобразует данные из двумерного массива (после операции пулинга) в одномерный массив. Он отвечает за преобразование изображения в вектор признаков.  Полносвязный слой (Dense) с 64 нейронами и функцией активации ReLU. Он принимает на вход результат операции выравнивания и используется для обработки признаков и генерации но вых признаков.  Полносвязный слой (Dense) с 15 нейронами и функцией активации softmax. Он принимает на вход результат работы предыдущего полносвязного слоя и используется для классификации изображения на 15 возможных классов. Эксперименты показали, что точн ость классификации атак методов IGTD сравним с моделью, на вход которой подавались изображения, полученные линейным способом. Таким образом мы будем рассматривать только результаты прямого преобразования и преобразования методом deepinsight . Точность прямо го преобразования : precision = 1.00, recall = 1.00, f1 score = 1.00. Точность метода deepinsight: precision = 0.99, recall = 0.99, f1 score = 0.99. а) б) Рис. 2. Матрица ошибок а) для прямого преобразования и б) для метода deepinsight Заключение В данной статье мы рассмотрели 3 метода преобразования табличных данных в изображения для обнаружения вторжений и сверточную нейронную сеть для обработки полученных изображения . Прямое преобразование простой и эффективный метод, который хорошо подходит для небольших наборов данных. Метод IGTD для экспериментальных данных оказался подобен линейному способу преобразования, а с учетом необходимости выполнения дополнительных преобразования применения данного способа видится не целесообразным. DeepInsight мето д, который позволяет получить изображения , которые отражают нелинейны зависимости между данными. Однако для выбранного набора данных, который представлен статистическими величинами, такими как число сетевых пакетов, максимальная длина пакета в потоке, его применение не позволяет повысить эффективность по сравнению с линейным способом. Точность обнаружения атак при использовании линейного способа преобразования вектора статистик сетевого потока оказался высоким, что позволяет говорить о том, что применение п реобразования табличных данных в изображения является целесообразным при условии применения методов глубокого обучения, но требует дополнительных исследований. 

: лидар, камера видимого света, калибровка, взаимная калибровка камеры и лидара Введение Системы, состоящие из лидара (лазерного радара) и камеры широко применяются в различных областях, требующих точного восприятия окружающей среды 1 . Например, в автономных автомобилях для создания трехмерной карты окружения. Лидары могут точно измерять расстояния до объектов и создавать облака точек, в то время как камеры могут использоваться для распознавания дорожных знаков, определения маркировки на дороге, обнаружения и распознавания различных объектов. В робототехнике система из камеры и лидара помогает решать задачи позиционирования. В этом случае лид ар может использоваться для точного измерения расстояния до объекта, а камера для распознавания маркеров и маяков. Нередко возникают задачи, требующие сведения данных с лидара и камеры (3д реконструкция, навигация, улучшение точности и надежности распознав ания объектов, множественное объектное отслеживание). При этом возникает необходимость в определении внутренних и внешних параметров сенсоров. Разновидности лидаров Существуют как двухмерные лидары, так и трехмерные. Каждый из типов обладает своими преимуществами и недостатками. По сравнению с 3д лидаром, 2д сенсор обладает более низкой стоимостью, большей скоростью обработки данных, меньшим объемом данных, высокой точностю в одной плоскости измерения, более компактными размерами. Таким образом, в ря де случаев целесообразнее использовать именно 2д лидар. Принцип работы двухмерного сенсора следующий: лазерный свет с заданной модуляцией отправляется от источника (передатчика) и отражается от объект а на сцене. Отраженный свет обнаруживается приемником, а время пролета используется для определения расстояния до точки . Для получения большего количества точек лидар вращается вокруг своей оси и строит зависимость расстояния до точек сцены от угла поворота сенсора. Этапы решения задачи сопоставления Решение за дачи сопоставления данных лидара и камеры включает несколько этапов:  Калибровка: это процесс определения пространственного соответствия между координатными системами лидара и камеры.  Синхронизация по времени: данные с лидара и камеры могут иметь разные вре менные метки, поэтому важно синхронизировать данные по времени, чтобы иметь возможность их сопоставлять.  Извлечение признаков: для сопоставления данных с лидара и камеры необходимо извлечение признаков из обоих источников данных. Например, из изображений м огут быть извлечены такие признаки, как: углы, края, текстуры, а из лидарных данных – точки, облака точек или дескрипторы точек.  Сопоставление: на этом этапе происходит фактическое сопоставление данных с лидара и камеры. В данном исследовании описывается п ервый этап решения задачи сопоставления – калибровка. Калибровка камеры и 3д лидара Калибровка камеры – это задача получения внутренних и внешних параметров камеры по имеющимся фотографиям или видео, отснятыми ею. К внутренним параметрам камеры относятся: фокусные расстояния по осям x и у, координаты оптического центра, угол наклона пикселей изображения. Внешние параметры отвечают за расположение камеры в мировой системе координат. Существуют различные алгоритмы калибровки камеры. Один из самых распространенных – алгоритм, использующий в качестве калибровочного объекта шахматную доску. Принимая на вход фотографии доски, по разному ориентированной относительно камеры, алгоритм определяет координаты ключевых точек – углов клеток, и по ним восстанав ливает калибровочные матрицы сенсора. После вычисления внутренних параметров камеры можно приступить к калибровке 3д лидара 2 . Для этого необходимо определить плоскость доски по данным лидара и камеры, а затем подобрать такую внешнюю матрицу лидара, чтобы п лоскости, полученные по данным двух сенсоров, совпали. Калибровка камеры и 2д лидара В отличие от 3д лидара, 2д лидар восстанавливает карту глубин только для одной плоскости. По этой причине вариант с использованием в качестве калибровочного объекта шахм атной доски отпадает, т.к. различным вариантам расположения доски в пространстве может соответствовать один и тот же набор данных лидара. Возникает задача поиска такого трехмерного объекта, различным ориентациям в пространстве которого соответствуют различ ные показания лидара. Вышеуказанное ограничение на калибровочный объект позволит определять положение лидара относительно объекта без учета данных с камеры. Однако в рамках системы, состоящий из камеры и лидара, можно ослабить ограничение, учитывая тот фак т, что на основании известной геометрии объекта и данных с камеры можно восстанавливать перемещение объекта в мировой системе координат. Далее будет подробнее рассмотрен процесс выбора калибровочного объекта без учета данных с камеры. Выбор калибровочного объекта Ограничение, описанное в предыдущем разделе, может быть записано следующим образом: ∀ 푃 1 ≠ 푃 2 ⇒ 휙 ( 푟 , 푃 1 ) ≠ 휙 ( 푟 , 푃 2 ) , где 푃 1 и 푃 2 внешние матрицы лидара. Кроме того, для поиска отличий между зависимостями φ( r ) , получаемыми при различных положениях лидара относительно калибровочного объекта, удобно пользоваться ключевыми точками. Если для камеры ключевыми точками являются области с резким градиентом интенсивности, то для лидара ключевыми являются области с резким градиентом глубины. Проверим на соотв етствие вышеуказанным критериям объекты некоторых классов. 1) Плоскости: любые плоские объекты, очевидно, не удовлетворяют первому ограничению, т.к. через одну прямую, принадлежащую плоскости, может проходить бесконечное число плоскостей лидара (плоскость лид ара – плоскость, в которой перемещается его луч). Кроме того, такие объекты имеют градиенты глубины только по краям. 2) Перфорированные плоскости: добавление перфорации улучшает объект с точки зрения увеличения количества ключевых точек, однако не устраняет н есоответствие объекта первому ограничению. 3) Поверхности (разомкнутые и замкнутые), многогранники, сложные трехмерные фигуры: требуют дальнейшего разбиения на подклассы по признаку соответствия ограничениям. Можно выделить два типа алгоритмов поиска калибровочного объекта. 4) От ограничений: выбрать подкласс объектов третьего класса, представить первый критерий в удобном виде, разработать программу, синтезирующую объект заданного подкласса в соответствии с указанными ограничениями. 5) От объекта: предложить конкретный объект и проверить его на соответствие двум основным критериям. Вариант калибровочного объекта В качестве варианта калибровочного объекта может быть рассмотрен прямоугольный неравногранный тетраэдр (рис. 1 , а). При этом начало системы координат объекта привязано к вершине тетраэдра, в которой ребра сходятся под прямым углом, а оси направлены  вдоль этих ребер. Грань, лежащая напротив начала системы координат, либо отсутствует, либо (для увеличения количества ключевых точек) перфорирована определе нным образом (рис 1, б). При расположении лидара в области положительных значений координат x , y , z в системе координат калибровочного объекта график зависимости φ( r ) на выходе сенсора будет состоять из набора участков парабол (от одной до трёх), соответствующих пересечениям плоскости лидара с гранями тетраэдра. В точках «стыковки» парабол будет наблюдаться резкий градиент. Один из возможных вариантов расположения лида ра относительно калибровочного объекта представлен на рис. 2. При этом пересечения плоскости лидара с гранями тетраэдра изображены пунктиром, в то время как сами грани выделены жирной линией. На правом нижнем изображении представлены соответствующие показа ния лидара. Можно заметить резкое изменение знака производной в точке стыковки участков парабол. В случае наличия перфорированной грани, рисунок перфорации будет «проецироваться» на плоскости граней, увеличивая при этом количество точек с резким градиенто м на графике φ( r ) . Наличие перфорации увеличивает количество ключевых точек не только для лидара, но и для камеры. В алгоритмах компьютерного зрения часто используют текстуры с большим количеством углов, положение которых определяется с помощью детектора у глов Харриса 3 . Однако при больших углах поворота плоскости с рисунком относительно камеры углы искажаются, и их детекция затрудняется. В качестве альтернативы рисунок перфорации может быть составлен из набора кругов. При этом алгоритм Хафа 4 , определяющий п оложение кругов, более устойчив к вращению перфорированной плоскости. Рис. 1. a ) Прямоугольный тетраэдр, б) вариант перфорации грани Рис. 2 . Частный случай взаимного расположения лидара и калибровочного объекта. Грани тетраэдра (левый верхний, правый в ерхний, левый нижний рисунки) показаны жирной линией, пунктиром показаны линии пересечения плоскости лидара с гранями тетраэдра. Правый нижний рисунок отражает соответствующие показания лидара (зависимость φ(r) ). Заключение В ходе исследования была сформул ирована проблема калибровки системы, состоящей из 2д лидара и камеры, и предложены некоторые пути ее решения. В частности, был рассмотрен случай независимого определения положений лидара и камеры в координатах калибровочного объекта. Были сформулированы кр итерии, которым должен соответствовать объект, а также предложены варианты самих объектов. Дальнейшая работа в этой области предполагает поиск калибровочных объектов, увеличивающих точность и надежность работы алгоритмов вычисления относительного положения сенсоров. 

: «протокол придачи информации», «технические системы», «открытый исход ный код», «интерфейс передачи данных». Цель исследования. Протокол обмена информацией — это набор правил и инструкций, которые определяют, как устройства взаимодействуют между собой и обмениваются данными. Промышленные протоколы используются для управления и автоматизации различных систем, таких как производственное оборудование, здания, транспортные системы и многое другое. Для эффективной работы таких технических систем необходимо обеспечить быструю и надежную передачу информации между их компонентами. В условиях быстрого технологического развития и растущей зависимости от информационных технологий, существующие протоколы все меньше и меньше способны удовлетворять увеличивающиеся запросы по скорости и безопасности передачи. В данной статье приводятся новые тенденции в сфере обмена информаци ей и рассматриваются преимущества и недостатки существующих решений , а также проблемы, с которыми они могут столкнуться в контексте применения для  управления современными техническими системами. Также, одна из задач данно й статьи определить наиболее эффективные и надежные протоколы передачи информации для управления техническими системами в условиях быстрого развития технологий и увеличивающихся требований к скорости, безопасности и надежности передачи данных. Существующ ие протоколы передачи информации: преимущества и недостатки. Существует множество промышленных протоколов, которые могут различаться по своим характеристикам и способностям. Одними из наиболее популярных промышленных протоколов являются: 1. Протокол Modbus яв ляется одним из наиболее популярных промышленных  протоколов, который используется для обмена данными с целью управления различными типами оборудования и систем. К его преимуществам можно отнести:  Легкость в использовании и настройке, что делает его идеа льным для использования в простых системах с ограниченными требованиями по обмену информацией.  Распространённость, которая позволяет легко его интегрировать с другими системами и устройствами.  Не требует больших затрат на лицензирование и обеспечение подд ержки.  Возможность передачи данных через различные типы интерфейсов. Однако у него имеются и недостатки, такие как:  Неэффективность передачи больших объемов данных.  Необходимость дополнительной настройки (низкий функционал).  Низкая защита от ошибок. 2. Протокол Profibus является одним из наиболее популярных промышленных протоколов, который используется для обмена данными между электронными устройствами. Он был разработан в Германии в 1989 году и используется для управления различными типами оборудования и систем. Преимущества протокола Profibus включают:  Высокая скорость передачи данных.  Дальность передачи.  Протокол Profibus может быть использован для передачи данных через различные типы интерфейсов (RS 485 и Ethernet).  Надежность. Недостатки протокола Pr ofibus включают:  Сложность настройки.  Затраты на лицензирование и обеспечение поддержки.  Необходимость использования специального оборудования. 3. Ethernet/IP — это протокол, используемый для обмена данными в промышленных сетях. Он основан на стандарте Ethern et и TCP/IP протоколах, что делает его совместимым с широким спектром оборудования и программного обеспечения, работающего в среде сети. Преимущества протокола Ethernet/IP включают:  Высокая скорость передачи данных.  Гибкость: Ethernet/IP поддерживает различные протоколы, такие как TCP/IP и др.  Простота настройки.  Масштабируемость. Недостатки протокола Ethernet/IP включают:  Надежность.  Конфигурация сети: Ethernet/IP требует настройки с Таблица 1 Сравнительные характеристики промышленных протоколов передачи данных Характеристики Modbus Profibus Ethernet /IP Скорость передачи данных От 300 до 115 200 бит/с. От 9,6 кбит/с до 12 Мбит/с. До 1 Гбит/с. Режимы передачи данных RTU, UDP, TCP , ASCII DP, FMS, PA TCP/IP, UDP Режимы Одноуровневый Многоуровневый Многоуровневый Формат кадра Фиксированный Фиксированный Различный Методы передачи данных Пакетный обмен. Циклический обмен. Обмен с использованием сервисов. Поддержка топологии Линейная Линейная, звезд Линейная, звездообразная, шина. Поддержка безопасности Низкая Высокая Высокая После сведения данных протоколов к виду таблицы 1 и анализа других решений на рынке, можно заметить, что главными недостатками существующих решений являются :  Ненадежность: многие протоколы по прежнему используют UDP дейтаграммы для передачи данных, что при передачах «по воздуху» приводит к большим потерям пакетов.  Ограниченность: Многие протоколы сильно ограничены по возможности передавать большие объёмы данных.  Доступность: протоколы, в которых решены вышеописанные проблемы имеют закрытый исходный код, что приводит к необходимости покупки ПО и «железа» разработчика протокола. Это в свою очередь не позволяет интегрировать эти протоколы в существующие систе мы.  Сложность: некоторые протоколы могут быть сложными для понимания и настройки, что может приводить к трудностям в интеграции и сопровождении системы.  Ограничения по расстоянию и скорости передачи данных: это сужает возможный спектр их применениия в неко торых технических системах. Инновации и новые тенденции в протоколах передачи информации технических систем Сейчас основными инструментами для обмена данными в промышленных сетях являются доработанные и усовершенствованные готовые решения, переводимые под передач у данных по Ethernet . При этом передачу переориентируют под использование более надежного TCP пакета, представленного на рисунке 1. Примерами являются Modbus TCP,  Profinet, EtherCAT и многие другие. Распространение Ethernet промышленных средах позв оляет использовать существующую инфраструктуру сетей для передачи данных между устройствами и системами, но протоколы передачи данных по Ethernet обладают высокой скоростью передачи данных и могут использоваться для передачи больших объемов данных, включая видео и аудио. Другим инновационным решением является использование протоколов передачи данных с открытым исходным кодом, таких как Open Platform Communications Unified Architecture (OPC UA) и Message Queuing Telemetry Transport (MQTT). OPC UA обеспечивае т безопасную и надежную передачу данных в различных промышленных средах, включая Интернет вещей (IoT) и облака данных (cloud computing). MQTT позволяет передавать данные в режиме реального времени с низкой задержкой и высокой точностью. Этот протокол имеет широкий спектр применения, начиная от автоматизации производства до автоматизации транспорта и управления энергосистемами. Рис . 1 . 32 битный TCP пакет. Также внедрение концепции «Edge Computing» позволяет обрабатывать данные на месте их производства, что снижает задержки и уменьшает нагрузку на сеть. Вместо того, чтобы отправлять все данные на удаленный сервер, данные обрабатываются непосредственно на устройствах, что позволяет ускорить обработку и уменьшить нагрузку на сеть. Выводы В данной статье мы определили основные проблемы существующих протоколов передачи информации: ком м ерциализированность продвинутых решений, их ориентированность на использование внутри компании разработчика, а также проблемы с надежностью в работе, в особенности с большими об ъёмами данных. Наиболее перспективными разработками, являющимися решением данных проблем, являются протоколы OPC UA , MQTT , имеющие открытый исходный код. Безусловно, второй веткой развития будет являться применение концепции «Edge Computing» , позволяющий п родлить жизнь, доработанным под более надежный формат TCP, существующим решениям. 

: приборная панель, электромобиль, Figma, ЖК дисплей, интерфейс, прототип, векторные изображения. Введение В докладе под электромобилем будем понимать автомобиль, приводимый в движение одним или нескольк ими электродвигателями, питаемыми от независимого источника электроэнергии. Электромобили отличаются от автомобилей с двигателями внутреннего сгорания (ДВС) тем, что не имеют двигателя, работающего на топливной смеси, и как следствие отсутствием выхлопов г азовых отходов. Очевидно, что рынок электромобилей сейчас является актуальной мировой задачей и для возможности конкуренции РФ предполагается разработка и полное производство электромобилей в нашей стране. Поскольку данная задача является большой, то ц елью работы в рамках данного доклада является разработка прототипа интерфейса приборной панели для электромобиля. Приборная панель электромобиля была разработана на основе жидко кристаллического дисплея (ЖК дисплея), который позволяет отображать более подробну ю информацию о состоянии автомобиля, чем аналоговая панель. Благодаря чему появилась возможность воспроизвести такие данные как уровень заряда батареи, расход электроэнергии, дальность поездки и т.д. Кроме того, ЖК дисплей дает возможность предоставлять ее в удобном для водителя (пользователя) виде, например, с помощью графиков и диаграмм. Программные средства для разработки прототипа Разработка прототипа интерфейса приборной панели не представляется без применения специальных инструментальных средств – гра фических редакторов, дающих разработчику набор инструментов необходимых для создания и настройки прототипа. В качестве программного обеспечения (ПО) был выбран Figma – это онлайн сервис для проектирования  интерфейсов и прототипирования с возможностью орган изации совместной работы в режиме реального времени. Основные плюсы данного сервиса: ▪ большое количество инструментов и функций – инструменты для рисования, шаблоны и библиотеки; ▪ отсутствие обязательной платной подписки; ▪ работа в облаке. Figma [1] является векторным редактором, который базируется на сплайновых кривых [2 3], а также в веб д изайне при создании сайтов [4]. Описание разработанного прототипа интерфейса приборной панели Разработанный прототип приборной панели (рис. 1) состоит из нескольких частей. В центральной части располагается спидометр, состоящий из двух сегментов: левый сегмент содержит информации о скорости электромобиля, в то время как в правом сегменте отображаются сведения о заряде аккумуляторных батарей. Для простоты восприятия информаци и о скорости электромобиля на приборной панели используется как стрелочный спидометр, так и дублирующее его значение цифровой индикации. Так же используется цветовая индикация скорости, которая реализована изменением цвета стрелки спидометра при разных зна чениях скорости электромобиля, например, от 0 км/ч до 90 км/ч стрелка окрашена в синий цвет, от 90 км/ч до 120 км/ч – в желтый цвет, выше 120 км/ч – красный цвет. В правом секторе расположена стрелка запаса энергии, который измеряется в кВт. Его значение, как и значения скорости, дублируются на ЖК дисплее в числовом виде. В центральной части спидометра размещены данные о запасе хода, измеряемые в км, и индикатор оставшегося заряда аккумуляторной батареи находится под цифровым показателем скорости. Рис. 1. Вид прототипа интерфейса приборной панели электромобиля. Слева и справа от спидометра находятся две зоны, куда может выводиться различная текстовая и графическая информация. Например, в этих зонах могут располагаться следующие элементы: текстовые сообщени я об ошибках и неисправностях, график потребления энергии, информация о входящих/исходящих звонках, экран навигатора или экран музыкального проигрывателя. Кроме того, можно вывести на ЖК дисплей модель электромобиля, где отображено положение дверей (открыт о/закрыто), значение давления в шинах и режим работы фар. Эти зоны имеют гибкую настройку, но перманентно в этих зонах сверху  показывается строка состояний: информация о качестве сигнала мобильной сети, наличие уведомлений – справа и расстояние до пункта н азначения, если включен навигатор – слева. Сверху и снизу в ряд расположены основные пиктограммы, отвечающие за быстрое и понятное предоставление информации водителю, например: обозначение режима работы фар и поворотников, режим стояночного тормоза и т.п. Разработка их дизайна основывалась на общеизвестных обозначениях, появившихся еще на автомобилях с ДВС, для простоты понимания и использования водителями. В случае особых или сложных элементов были разработаны специальные обозначения, например отображение температуры окружающей среды и реального местного времени. Следует отметить, что использование ЖК дисплея дало дополнительные преимущества перед аналоговой панелью, такие как возможность персонализации приборной панели, например, выбор отображаемых элемент ов (график расхода энергии, входящие звонки, экран навигатор и т.д.), появилась возможность дополнительной цветовой индикации как изменением цвета элементов, так и изменение цвета фона (дневной/ночной режим) для привлечения внимания к критически важным соо бщениям. Сравнение с аналогами Рассмотрим основные аналоги: Tesla Model 3 и Nissan Leaf. По основным функциональным возможностям таким как отображение и управление, наличие дополнительных функций, различным режимам работы предлагаемый прототип выступает на равне с Tesla Model 3 и значительно превосходит Nissan Leaf, за счет наличия дополнительных функций, например, навигатор, входящие звонки. С другой стороны можно сравнить качество формируемого изображения на экране приборной панели. Прототип имеет разрешен ие изображения 1920х2854 пикселей, в то время как последняя версия Tesla Model 3 не имеет приборной панели вовсе (от части из за наличия автопилота) и все данные передаются через центральный дисплей. Если сравнивать с прошлыми версиями, то разрешение прибо рной панели составляло 1280х480 пикселей, что значительно меньше, чем у разработанного прототипа. Третьим критерием сравнения может выступать эргономика приборной панели [5], которая за счет возможности настройки внешнего вида приборной панели и использова ния известных обозначений элементов интерфейса, прототип интуитивно понятен водителю и прост в использовании. Последним важным элементом сравнения является язык интерфейса приборной панели. В данном прототипе используется русский язык, в отличие от Nissan Leaf, где используется японский и английский языки (без возможности смены на русский), а в последних версиях Tesla Model 3 появилась поддержка русского языка, но смена языка требует значительных временных и трудовых затрат. В итоге можно сказать, что разра ботанный прототип может конкурировать с аналогом от Tesla и значительно превосходит аналог от Nissan приборной панели электромобиля. Выводы Разработан интерфейс и создан дизайн для прототипа интерфейса приборной панели электромобиля и ее элементов в вектор ном редакторе Figma. Главным достоинством представленного прототипа является то, что он является отечественным аналогом, т.е. решена важнейшая на сегодня задача импортозамещения. В дальнейшем планируется разработать документацию пользователя, а также рассм отреть вопрос внедрения в других предметных областях, например в электробусах и троллейбусах с возможностью автономного хода. 

: системы поддержки принятия решений, распределение преподавательской нагрузки, требования к системе распределения нагрузки. Введение Процесс принятия решения о распределении учебной нагрузки на преподавателей в учебном заведении является трудозатратным и требует от специалиста и руководителя структурного подразделения знаний законов и нормативно правовых актов, регламентирующих норму часов нагрузки на полную ставку, ограничения по допуску к ведению разного вида учебных занятий (лекции, семинары, практики), а также возможности руководства практической подготовкой. Эти условия зависят от должности, занимаемой преподавателем. Помимо регламентов при распределении нагрузки необходимо принимать во внимание компетентность и предпочтения каждого преподавателя к ведению дисциплин. Для преподавателей, работающих в учебном заведении больше года, можно смотре ть исторические данные и распределять им нагрузку на те дисциплины, опыт преподавания которых у них имеется. Однако с постоянно меняющимися запросами на рынке труда, меняются учебные дисциплины, подходы и требования, что добавляет неопределённости в  процес с принятия решения о распределении нагрузки и требует от руководителя дополнительных мер по обеспечению реализации учебного плана. Зачастую распределение нагрузки происходит неравномерно между преподавателями структурного подразделения, в силу отсутствия а втоматизированных средств распределения, предлагающих возможные оптимальные варианты и учитывающие все правила и ограничения. Целью работы является формализация требований к автоматизированной системе поддержки принятия решений о распределении нагрузки на преподавателей. Для достижения поставленной цели необходимо проанализировать системы поддержки принятия решений с точки зрения инструмента повышения эффективности управления ресурсами, выделить ключевые моменты и требования к системе для распределения учеб ной нагрузки в учебных заведениях. Системы поддержки принятия решений как инструмент повышения эффективности управления ресурсами Существует мнение, что об эффективности принятия решений начали задумываться в первой половине XVIII века, когда в 1738 году Д . Бернулли вывел формулу нелинейной логарифмической функции полезности денег, которая показывает способность удовлетворять потребности индивида, учитывая его предпочтения и ценность блага [1]. Далее стоит отметить вклад в теорию принятия решений Г. Саймона , который в 50 х годах XX века описал человеческое поведение с точки зрения ограниченной рациональности в виду ограниченности памяти и способности к обработке большого количества информации. Альтернативы выбора не даны по умолчанию, а их необходимо найти и з исходных данный, а также оценить возможные последствия [2]. Помимо теории принятия решений активно развиваются информационные системы для принятия решений, начиная с 1960 х годов. К концу 1970 х разработанные интерактивные информационные системы, использ ующие различные модели с разными входными данными, во многих компаниях получили название систем поддержки принятия решений. Далее начали появляться информационные системы управления (MIS), руководителя (EIS), финансового планирования, на основе технологий реляционных баз данных, бизнес интеллекта (BI), OLAP кубов, объектно ориентированных технологий и другие [3]. Системами поддержки принятия решений (СППР) принято считать такие информационные системы, которые обеспечивают управляющему звену (человеку, руков одителю) в процессе управления организацией принимать обоснованные, верные управленческие решения, даже в условиях неопределённости и быстро меняющейся предметной области. При этом сама система рассматривается, как вычислительное звено процесса управления и содержит в себе модели, правила и ограничения, которые нужно учитывать при принятии решения. Входные данные и выбор финального решения из возможных вариантов задаёт управляющее звено, а все вычисления и нахождение вариантов решений выполняет компьютер, ч то повышает скорость обработки информации – один из критериев повышения эффективности принятия решения. Выделяют следующую классификацию систем поддержки принятия решений [4]. СППР принято делить по способу взаимодействия с пользователем, по источникам пол учения информации, по области применения. Виды и описание каждого типа представлены в таблице 1. Системы поддержки принятия решений позволяют принимать более эффективные управленческие решения, чем без использования таких систем [5]. Повышение эффективност и складывается из многих критериев, среди которых выделяют уменьшение времени обработки информации, более быстрая обратная связь при возникновении нестандартной ситуации, не требует дополнительных затрат времени и ресурсов при изменении состояния предметно й области. СППР помогают находить наиболее оптимальные варианты решений проблем, не требуя от лиц, принимающих решение (ЛПР), детальной проработки текущей ситуации, ЛПР достаточно сравнить предлагаемые системой варианты, и выбрать один из них, либо скоррек тировать промежуточные данные и посмотреть результаты их обработки. Таблица 1 Описание классификации систем поддержки принятия решений Тип СППР Описание Взаимодействие с пользователем Пассивная Визуализирует результаты вычислений, но не определяет лучшее решение. Пользователь системы самостоятельно анализирует и принимает решения по представленной программой информации. Активная Предлагает варианты решений, ранжируя найденные альтернативы по приоритетности. Критерии приоритетов выставляет пользоват ель в момент ввода исходных данных и может как согласиться с предлагаемыми вариантами результатов работы системы, так и выбрать свой вариант, т.е. результаты вычислений являются рекомендательными. Кооперативная Пользователь и система находятся в постоянно м диалоге: пользователь может корректировать промежуточные вычисления системы, а система «принимает во внимание» изменения и выполняет перерасчёты. Процесс работы пользователя с системой завершается, когда результаты системы и ожидания пользователя будут с огласованными. Источники получения информации Модельная Обработка исходных данных на основе статистических, финансовых, оптимизационных и имитационных моделях. Коммуникационная Обработка сообщений различных групп пользователей, работающих над одной задачей. Сообщения синхронизируются в многопоточной распределённой системе, сервер которой управляется событиями от клиента. Данные Доступ и манипуляция с данными, происходит статистическая и/или имитационное моделирование, анализ временных рядов. Докуме нтальные Обработка документов в различных форматах. Выполняется поиск и обработка неструктурированной информации. Знания Система решает задачи по фактам, правилам, процедурам. Появляется акцент на способность системы «понимать» проблемы, по правилам, изве стным пользователю. Полезность системы выражается в способности принимать решения с большим количеством зависимостей, которые сложно просчитать человеку. Область применения Настольная Система, работающая на локальном компьютере одного пользователя, данные и результаты не предоставляются другим пользователем. Корпоративная Используются большие хранилища информации, выполняется анализ данных. Система обслуживает нескольких пользователей при решении одной задачи или нескольких связанных задач. Выявлен ие требований к системе распределения преподавательской нагрузки в учебных заведениях Несмотря на стремительное развитие информационных технологий, распределение преподавательской нагрузки до сих пор выполняется без использования автоматизируемых средств, контролирующих соответствие законам, правилам и ограничениям. Специалистам, занимающимся распределением часов по учебным дисциплинам на учебный год, приходится контролировать все ограничения и нормы по часам на каждого преподавателя, занимающего определённ ую должность, имеющих различный статус трудоустройства (штат, гражданско правовой договор (ГПД), совместительство) вручную, что неэффективно с точки зрения временных затрат, а также с точки зрения частоты возможных ошибок и неоптимальности варианта распред еления нагрузки по всему профессорско преподавательскому составу (ППС) подразделения. Стоит отметить, что специалисту помимо формальных правил, также приходится ориентироваться в квалификации и предпочтениях ППС подразделения, чтобы обеспечить выполнение о бразовательных услуг, оказываемых подразделением, на высоком уровне. Каждый преподаватель имеет опыт работы с определённым набором дисциплин, ориентируется в определённых предметных областях и имеет свои предпочтения к ведению той или иной дисциплины, а та кже может тяготеть к обучению студентов на определённых курсах, не обязательно на тех, что предлагается учебным планом. Соответственно, специалисту нужно знать не только правила, но и субъективные аспекты назначения ППС на дисциплины. В случае, если специа лист подразделения меняется и не знает первое время специфики работы подразделения и особенностей ППС, будет трудно распределить ППС по дисциплинам так, чтобы обеспечить равномерность распределения часов нагрузки подразделения между ППС, выполнение нормати вов нагрузки по ставке ППС и удовлетворение ППС распределением. Для новых специалистов время выполнения распределения может значительно увеличится относительно того специалиста, который уже проработал в подразделении хотя бы один учебный год. В статье [6] представлено описание процесса распределения нагрузки в вузе на примере «Высшей Школы Экономики». По собранной ранее информации, имеющемуся опыту работы в подразделении и обсуждению с текущим специалистом необходимой функциональности для автоматизации расп ределения нагрузки ППС на дисциплины учебного плана, была построена диаграмма требований (вариантов использования), которая представлена на рисунке 1. На диаграмме серым цветом выделена функциональность, доступная только руководителю подразделения (на утве рждение или отмену утверждения распределения нагрузки), т.е. только руководитель в праве решать, какой вариант нагрузки будет принят на учебный год. Функции, имеющие ограничения доступа или поясняющие состав документов для выполнения действия отмечены зали вкой прецедентов серыми зигзагами. Основной функцией системы, предлагающей варианты распределения по имеющейся информации о ППС (сотрудниках), учебном плане, истории и общей нагрузки, выделенной на подразделение, является «Сформировать новый вариант распре деления нагрузки», отмеченной в диаграмме заливкой с серой р ешёткой. Рис. 1. Требования к системе распределения преподавательской нагрузки На данный момент основа системы поддержки принятия решения о распределении нагрузки на ППС подразделения – формирование варианта распределения нагрузки, находится в стадии разработки, о результатах, которой планируются новые публикации в ближайшее время. Заключение Системы поддержки принятия решений позволяют руководителям принимать взвешенные и оптимальные реш ения, скорость принятия которых значительно выше традиционных методов. В статье рассмотрены особенности и применение СППР для решения реальных задач. В задаче о распределении преподавательской нагрузки предполагается реализация корпоративной кооперативной СППР, управляемой данными, документами и знаниями, в силу специфичности и многокритериальности предметной области. Построена диаграмма требований для системы распределения нагрузки ППС, которая в дальнейшем планируется к разработке. 

 : беспилотные летательные аппараты, патрулирование территориальных вод, геоинформационные сист емы, м ашина Дубинса. Введение Актуальной сферой применения беспилотных летательных аппаратов (БПЛА) является плановое патрулировани е границы государства и, в частности, его территориальных вод. Беспилотники позволяют пограничным службам более оперативно об наруживать факты нарушения границы и осуществлять контроль над прилегающим к границе территориями в режиме реального времени. Выполнение полетного задания предполагает предварительное планирование траектории полета, которое выполняется в два этапа. На перв ом задаются опорные точки траектории. На втором этапе формируется допустимая гладкая траектория полета с учетом маневренности ЛА. Применительно к горизонтальному полету можно использовать решение задачи машины Дубинса [1], согласно которой траектория форми руется из сегментов трех типов – движения по прямой линии, левого и правого поворотов, осуществляемых по дуге окружности. Результаты, полученные Дубинсом [1], оказались весьма полезными для построения траекторий движения БПЛА [2 3]. Задача прокладки маршру та полета БПЛА Для определения местоположения путевых точек в районе патрулирования необходимо располагать цифровой картой (ЦК) контролируемой территории, создание которой осуществляется средствами геоинформационных технологий [ 5 ]. Для прикладных  исследова ний в области геоинформатики подходит свободная географическая информационная система с открытым кодом QGIS [ 6 ]. В качестве примера рассмотрим задачу облета группы островов патрульным беспилотником. Географическое расположение островов и зоны патрулировани я иллюстрируется рис. 1, на котором представлена упрощенная карта местности, построенная с помощью программы QGIS 3.20.3. Маршрут полета БПЛА задан 10 точками. Место его базирования обозначено точкой 0. Протяженность маршрута равна 79 км. Маршрут проходит по границе 12 мильной зоны территориальных вод. Рис. 1: Географическое расположение островов и зоны патрулирования Алгоритм синтеза траекторий Дубинса Определим маршрут полета БПЛА как заданную последовательность путевых точек 01 { , , , } N M P P P  . (1) Каждая точка PM  задана декартовыми координатами: ( ) ( , ) P x y  r . Если траектория замкнута, то 0 N PP  . Рис. 2 : Ф рагмент траектории поле та БПЛА Проанализируем фрагмент траектории полета БПЛА, представленный на рис. 2: беспилотник вначале движется по прямолинейному отрезку пути 1 ( , ) ii PP   , затем двигается по дуге окружности ( , ) ii PP   , и далее по прямолинейно му отрезку 1 ( , ) ii PP   . Таким образом, точки i P  и i P  являются точками гладкого сопряжения отдельных участков траектории. Далее считаем, что радиус каждой дуги задан и равен R . Траектория предполагается гладкой, так что дуга ( , ) ii PP   должна касаться отрезков 1 ( , ) ii PP   и 1 ( , ) ii PP   . Введем обозначения: i O центр дуги ( , ) ii PP   , () i O r ее радиус вектор Построение траектории Дубинса сводится к решению задачи построения точек сопряжения i P  и i P  , определения координат центра соединяющих их дуги i O и ее углового размера i  . Дальнейшие построения иллюстрирует рис. 3. Рис. 3 Геометрия Зададим единичные векторы, направленные вдоль отрезков 1 ( , ) ii PP  и 1 ( , ) ii PP  : 1 1, 1 ( ) ( ) || ( ) ( )|| ii ii ii PP PP       rr n rr ,  1 ,1 1 ( ) ( ) || ( ) ( )|| ii ii ii PP PP       rr n rr .  (2) Здесь двойными прямыми скобками обозначается евклидова длина вектора. Величина угла между отрезками 1 ( , ) ii PP  и 1 ( , ) ii PP  определяется соо тношением:   1, , 1 arccos ( , ) i i i i i    nn (3) Здесь 1, , 1 ( , ) i i i i  nn скалярное произведение векторов 1, ii  n и ,1 ii  n . Центр дуги ( , ) ii PP   расположен на биссектрисе угла, образованном двумя лучами, исходящими из точки i P и проходящими через точки 1 i P  и 1 i P  . Окружность с центром i O и радиусом R вписана в этот угол, так что радиус вектор окружности, проведенный из этого центра в точку 1 i P  , перпендикулярен к отрезку 1 ( , ) ii PP  . Таким образом, расстояние от точки i P д о точки i O равно φ sin 2 i i R d  (4) Расстояния от точки i P до точек i P  и i P  определяются формулами: φ 2 ii i R dd tg    (5) Найдем единичный направляющий вектор биссектрисы рассматриваемого угла , 1 1, , 1 1, || || i i i i i i i i i      nn n nn (6) Из (4) и (5) получаем выражение для положения центра дуги   , ii PP   ( ) ( ) i i i i O P d    r r n .             (7) Аналогичные построения дают положения концевых точек дуги ( , ) ii PP   : 1 1, ( ) ( ) i i i i i P P d      r r n ,  ,1 ( ) ( ) i i i i i P P d       r r n .    (8) Формулы (2) – (8) представляют алгоритм построения траекторий Дубинса по заданной последовательности путевых точек (1). Решение модельной задачи патрулирования Расчет траектории выполнялся в среде программирования MATLAB, причем входные данные импортированы из QGIS. Полученный результат представлен на рис. 4 Рис 4. Результат модеьной задачи патрулирования. Заключение Одно из важнейших направлений применения БПЛА является патрулирование протяженных территорий. Управление беспилотником в режиме патрулирования предполагает планирование его траектории полета. Один из подходов к решению данной задачи заключается в применении траекторий движения машины Дубинса. В работе рассмотрен вопрос алгоритмизации этого подхода. Приведен модельный пример построения траектории патрулирования территориальных вод, окружающих группу островов Вьетнама. 

: Автоматизация управления, ERP , 1С, АСУП, Производственная компания. Введение В настоящее время автоматизация и совершенствование управления предприятием является ключевыми задачами развития крупного бизне са. Без современных информационных систем эти задачи становятся трудно достижимыми, либо вовсе невозможными. Практическая реализация концепции автоматизации управления имеет мало альтернативных решений, и все они связаны с внедрением современных ERP систем , которые с одной стороны предоставляют всю необходимую информацию для принятия решений, с другой минимизируют влияние человеческого фактора [1] . В 2020г. руководством компании ООО ЮНИКОСМЕТИК было принято решение о необходимости внедрения новой современной информационной системы, способной автоматизировать управление компанией и консолидировать все бизнес процессы в единой среде. Целью настоящей работы являлось автоматизация процесса по разработке новой продукции. Для достижения цели выполнялись следующие задачи:  Построение функциональной модели процесса;  Разработка автоматизированного рабочего места (АРМ) в информационной системе 1 C : ERP ;  Тестовая эксплуатация и настройка модели;  Внедрение модуля в производственный процесс. Материалы и методы Еще несколько лет назад, при упоминании аббревиатуры ERP (Enterprise Resource Planning Планирование Ресурсов Предприятия) в основном подразумевали два мировых гиганта SAP и Axapta ( Microsoft Dynamics AX ), которые стали де факто стандартом АСУ Предприят и я . Тяжелые неповоротливые программы, очень дорогие в обслуживании, но  для выхода на мировые рынки требовалась отчетность, которую предоставляли только они [ 2] . Необходимо отметить еще один сегмент ERP систем это так называемая собственная разработка. 1 0 15 лет назад довольно популярный тип систем, способный учитывать все нюансы предприятия. В настоящее время встречается довольно редко. C выходом второй версии 1С:ERP все изменилось. Все больше российских компаний стали выбирать отечественное решение [3] . Из очевидных плюсов это более низкая стоимость внедрения и последующего сопровождения, моментальная реакция на изменения в законодательстве и относительно большое число IT специалистов, работающих с 1С . Впервые в отечественной системе появилось МСФО (Международный Стандарт Финансовой Отчетности), который соответств ует всем требованиям международного бизнеса. Д ополнительно, на выбор информационной системы может повлиять международная санкционная политика по отношению к России и, как следствие, курс на импортозамещение в т.ч. и программного обеспечения [4] . Первый, основной, самый сложный , дорогой и длительный этап внедрения – это Функциональное моделирование. Этап состоит в описании всех бизнес про цессов, происходящих в компании, их формализация, поиск функциональных разрывов и определение необходимых доработок. Всего было выделено 14 отдельных функциональных моделей и одна связывающая их вместе. (табл.1) У каждой модели был функциональный заказчик ключевой сотрудник подразделения и куратор от IT отдел а. Таблица 1 

: РСДБ, корреляционная обработка сигналов, ГПУ, GPU, MPI, CUDA. Введение В Российской Федерации существует комплекс РСДБ (радиоинтерферометрия со сверхдлинной базой) наблюдений космических объектов «Квазар », включающий в себя три обсерватории, оснащенные 32 метровыми и 13 метровыми радиотелескопами. Обсерватории расположены неправильным треугольником на территории России: в Ленинградской области, в Карачаево Черкесии и в Республике Бурятия. Комплекс предназ начен для наблюдения внегалактических объектов — квазаров и определения по ним координатно временных параметров [1,2]. Данные, полученные ими, передаются на коррелятор [3,4] – устройство, который объединяет данные от всех радиотелескопов, полученные за нек оторый промежуток времени вплоть до нескольких минут и осуществляет корреляцию данных с получением взаимно корреляционных спектров. Далее происходит постпроцессорная обработка, во время которой в амплитудной составляющей массива проводится поиск корреляцио нного отклика – пика на фоне шумовой подложки, и определяется задержка прихода радиосигнала на разные радиотелескопы; по полученным задержкам определяются параметры вращения Земли, строятся системы координат на Земле и на небесной сфере, формируются шкалы времени. Коррелятор RASFX РСДБ комплекса «Квазар КВО» создан в 2012 2016 гг. в виде специального программного обеспечения функционирующего на гибридном блейд серверном процессорном кластере, включающем в себя как классические 8 ядерные процессоры Intel, та к и графические процессорные ускорители (ГПУ) NVIDIA. Коррелятор (и РСДБ комплекс в целом) предназначены для обработки шумоподобных сигналов квазаров. Интерес представляют наблюдения космических аппаратов (КА), в том числе наблюдения одиночной антенной, вы деление доплеровского смещения несущей частоты излучаемого сигнала, по которой определяется радиальная (относительно антенны) составляющая скорости КА. По этим данным, накопленным на длительных интервалах времени, можно уточнять параметры движения КА. Задача создания программного обеспечения (ПО) определения доплеровских смещений фазомодулированного сигнала КА была поставлена перед авторами. ПО должно работать на процессорном кластере коррелятора RASFX, распределяя вычисления по нескольким вычислительны м узлам и ГПУ таким образом чтобы скорость обработки была не ниже скорости регистрации данных (32 миллиона тактов в секунду). От сотрудников Института прикладной астрономии РАН, разработавшими коррелятор RASFX, была получена модель системы обработки; она п редставляла собой ПО, работавшее на одном ядре процессора (единственным потоком) без использования ГПУ, и обрабатывающая одну секунду наблюдения за 20 секунд. В статье представлена структура и основные технические решения соответствующего разработанного ПО . Обзор архитектуры выбранного решения Одно из самых перспективных направлений по повышению производительности вычислений – это использование многопроцессорного коррелятора с использованием графических процессоров. GPU обладают такими особенностями, как: в ысокий параллелизм, многопоточность, многоядерность, огромная пропускная способность и сотни вычислительных ячеек. Параллельный подход в перспективе позволяет достичь эффекта ускорения во много раз выше раз по сравнению с последовательной версией, а базова я параллельность GPU может ускорить последовательный алгоритм в 10 раз. Подобные корреляторы существуют в мире, однако метод ускорения алгоритма обработки РСДБ наблюдений с помощью параллелизации и ГПУ изучен не так детально. Первый в мире РСДБ коррелятор на ГПУ был разработан в ИПА РАН. На основе существующих решений была создана программа коррелятора для обработки данных с одного радиотелескопа. Отличительной особенностью одностанционного коррелятора является отсутствие так называемых станционных модулей – узлов, в реальном времени собирающих информацию с обсерваторий. Для достижения потенциально наилучшего результата по производительности в инфраструктурной части проекта был выбран Message Passing Interface (MPI) – программный интерфейс для передачи инфо рмации, который позволяет обмениваться данными между процессами, выполняющими одну задачу; здесь – между процессорами в вычислительном кластере, объединяя общей шиной сообщений управляющий модуль со всеми корреляционными модулями. Для математической части использован CUDA – интерфейс работы с ГПУ Nvidia. Весь коррелятор состоит из: • Одного управляющего модуля (УМ), который отвечает за организацию инфраструктуры в системе. Он постепенно считывает блоки данных, распределяя по всем свободным от расчётов К М, получая обратно от каждого из них некоторую фазу, которую использует для юстировки следующего (а в итоге и финального опорного) значения фазы; • Нескольких корреляционных модулей (КМ), которые отвечают за непосредственную обработку данных. В нашем с лучае число КМ равно трём. Архитектура программного комплекса представлена на рисунке 2. Рис. 2. Устройство программного комплекса Работа коррелятора При запуске программы инициализируется подсистема MPI, разделяя все доступные процессоры на управляющий модуль и модули корреляционные. Следует учитывать, что для УМ выделяется процессор без связанного ГПУ. В управляющем модуле происходит вся основная инициализация программы: чтение файла конфигурации, выделение первого варианта опорной фазы и об щее определение базовых значений переменных, синхронизация всех КМ, связывание CPU с видеокартами, а также все одноразовые проверки и валидационные части кода. Инициализация корреляционных модулей заключается в основном в ожидании синхронизационного запрос а для УМ. Основной цикл для УМ состоит из следующих шагов: 1. Если не превышено количество буферных блоков данных для передачи – то управляющим модулем считывается следующий из файла; 2. Если есть и свободные корреляционные модули, и ещё не отправленные буферные блоки данных – то следующий блок вместе с текущей фазой отправляется следующему КМ. При этом КМ помечается как «занятый» и буферный блок удаляется из памяти. 3. Если от какого то корреляционного модуля был получен ответ в виде новой выделенной фазы – то при меняем её через П регулятор, а сам КМ помечаем «свободным». 4. Если во входном файле что то осталось (или если уже всё считали, но еще не все корреляторы прислали фазу) – переходим к п. 1. Основной цикл для КМ состоит из следующих шагов: 1. Получение на вход дек одированного сигнала и актуальной частоты от УМ. 2. Вычисляется фаза из полученной частоты по формуле 휑 = 2 휋푓푡 . Затем каждая точка сигнала 퐼 푖 умножается на cos( 휑 ) и на sin( 휑 ). Получены промежуточные значения комплексной 푆 푖 = 퐼 푖 ∗ 푠푖푛 ( 푎 ) и действительной  퐶 푖 = 퐼 푖 ∗ 푐표푠 ( 푎 ) части сигнала. 3. Далее сигналы  С 푖 и 푆 푖 проходят учетверение по формулам двойного угла: 푐표푠 ( 2 푎 ) = 푐표 푠 2 ( 푎 ) − 푠푖 푛 2 ( 푎 ) , 푠푖푛 ( 2 푎 ) = 2 ∗ 푐표푠 ( 푎 ) ∗ 푠푖푛 ( 푎 ) .  Получим сигналы с учетверенной частотой  퐶 4 , 푖 и 푆 4 , 푖 . 4. Затем происходит суммирование сигнала и поиск среднего значения по следующим формулам:  С 푆 = 1 푁 ∑ 퐶 4 , 푖 푁 푖 = 1 ,  푆 푆 = 1 푁 ∑ 푆 4 , 푖 푁 푖 = 1 . 5. После этого происходит вычисление новой фазы по формуле: 휑 = 푎푟푐푡푔 ( 푆 푆 퐶 푆 ) . 6. Полученный результат возвращается в УМ, пр оцесс переходит к шагу 1. По окончании работы всем КМ пересылается флаг завершения. Модули штатно выполняют все действия, нужные для завершения – в частности, освобождение памяти. Заключение В данной статье была описана разработка программного комплекса об работки радиоинтерферометрических наблюдений, перечислены технологии, использованные при разработке, описана архитектура программного комплекса, а также принцип его работы. В настоящее время время обработки улучшилось незначительно, менее чем в 1.2 раза. Отсутствие более заметного результата однозначно связано с тем, что система в некоторых критических секциях пока что не оптимизирована на достаточном уровне. В перспективе, после доработки программного комплекса, программный коррелятор будет показывать про изводительность, которая должна позволить обрабатывать данные, приходящие с радиотелескопов от действующей РСДБ сети, в режиме, близком к реальному времени. 

: умный дом , Z Wave, контроллер , система мониторинга. 1. Введение В предыдущих работах был проведен анализ протоколов реализации систем умного дома, в результате которого протокол Z Wave был выбран в качестве реализуемого на устройства серии NTU RG 54XX WZ [1] . Впослед ствии была разработана архитектура контроллера умного дома, которая была реализована. Затем была произведена интеграция данной системы на устройства серии NTU RG 54XX WZ. Оптические терминалы компании ООО «Предприятие «Элтекс» NTU RG 54XX WZ представляют с обой домашние роутеры, но имеющие вместо Ethernet WAN – PON WAN. Устройства предназначены для преобразования оптического сигнала, полученного от станционного оборудования провайдера по пассивным оптическим сетям, в удобный конечному пользователю вид – для беспроводной передачи или по витой паре. На данный момент на устройствах NTU RG 54XX WZ поддержаны VoIP, IPTV и другие необходимые абоненту сервисы [2]. Целью данной работы является разработка системы мониторинга контроллера умного дома по протоколу Z Wave для устройств серии NTU RG 54XX WZ, которая заменит существующую систему. Задачами данной работы являются: 1 ) Выдвинуть требования, которым должна удовлетворять новая система мониторинга умного дома. 2 ) Реализовать новую систему мониторинга умного дома. 3 ) Протестировать новую систему мониторинга . 2. Требования к системе мониторинга Главной проблемой предыдущей системы мониторинга умного дома являлось то, что возникновение любых ошибок в умном доме приводило к перезагрузке всего устройства . Это было неприем лемо для эксплуатации устройства. В связи с этим был выдвинут ряд требований: 1 ) При возникновении ошибок в умном доме не должно происходить перезагрузок всего устройства. 2 ) Система должна быть надежна и не иметь уязвимостей. 3 ) Система должна упростить запуск приложений умного дома . 4) Система должна быть переносима на другие устройства компании ООО «Предприятие «Элтекс» . 5) Система должна иметь механизм уведомлений. 3. Реализация системы Одним из главных требований, установленны х при реализации новой системы, является отсутствие изменений в форме конфигурации контроллера умного дом, котор ая представлен а на рисунке 1. В данной форме можно включить/отключить контроллер Z Wave , ввести адрес, порт и выбрать защищенное или не защищенн ое соединение с облачной платформой, а также произвести сброс контроллера к заводским настройкам (удаление всех датчиков и сценариев). При сбросе контроллера перед пользователем предстанет чистая форма . Рис. 1. Форма конфигурации контроллера умного дома В новой системе мониторинга умного дома была изменена концепция. Теперь при возникновении ошибок в умном доме новая система, в отличие от старой, пытается перезапустить приложения умного дома, когда старая система перезапускала все устройство . Среди поста вленных требований к системе мониторинга были устойчивость и надежность – для выполнения данных требований использовались утилита Valgrind (для проверки на утечки памяти), а сам код был проверен статическим анализатором cppcheck . Кроме того, ранее каждое приложение умного дома запускалось отдельно, что приводило к дублированию кода, теперь же новая система отвечает как за запуск приложений умного дома, так и за передачу на вход параметров из энергонезависимой памяти устройства. Разработанная система имеет Makefile, аналогичный тому, что используется в других приложениях умного дома и располагается в той же директории, что другие приложения. Новая система мониторинга умного дома обладает функционалом, который позволяет выводить оповещения о критических ошибк ах в консоль устройства . Кроме того, информация о произошедших ошибках также записывается в системный лог устройства, что обеспечивает более глубокое анализирование возможных проблем в системе и помогает устранять их. 4. Тестирование системы После разработки системы мониторинга умного дома было проведено тестирование, в результате которого было установлено, что переход на новую систему мониторинга является оправданным. В сравнении со старой системой мониторинга, в случаях, когда ранее требовалась полная перез агрузка устройства, новая система обеспечивает перезагрузку только приложения умного дома.  В процессе тестирования было принято решение о включении резервного механизма мониторинга в виде старой системы, которая продолжает функционировать для других крити чески важных приложений системы. В результате новая система мониторинга умного дома под постоянным контролем старой системы, что обеспечивает дополнительный уровень надежности и безопасности. Такой подход позволяет снизить риски возможных сбоев и обеспечив ает бесперебойную работу всей системы в целом . 5. Заключение В ходе работы была разработана новая системы мониторинга умного дома для устройств серии NTU RG 54XX WZ взамен существующей . Новая система мониторинга умного дома соответствует всем поставленным тре бованиям. Во время тестирования новой системы мониторинга умного дома, было решено сохранить старую систему мониторинга в качестве резервной. Разработанная система готова к переносу на другие устройства компании ООО «Предприятие «Элтекс» . 

: Интеллектуальные системы , И нтерактивные игровые системы, Игро фикация, И зучение иностранных языков, А нглийский язык, И гровая форма обучения Ввиду широкой цифровизации и введению гаджетов в о бучающий процесс в школах и ВУЗах все большую актуальность приобретает использование гаджетов не в развлекательных целях, а в целях самообучения. Слияние игровых механик с обучающими элементами позволяют сделать изучение чего либо, в том числе иностранных языков, более интересным и увлекательным. По степени влияния на потребителей и их вовлеченности в интерактивную среду, предлагаемую видеоиграми, этот сегмент уже давно выделяется среди других видов развлечений. Само по себе создание игр является лишь часть ю сложной "экосистемы", которая обеспечивает полный жизненный цикл производства, распространения и потребления таких сложных продуктов, как компьютерные игры. В структуре современной игровой индустрии можно выделить следующие уровни: платформы, игровые дви жки, разработка видеоигр, публикация и эксплуатация, популяризация и потребление. Успешные игровые проекты также могут быть реализованы  небольшими командами энтузиастов. Этому способствует наличие на рынке большого количества открытых и широко распростране нных платформ, качественных и практически бесплатных движков, платформ для привлечения "популярных" инвестиций (краудфандинг) и доступных каналов распространения. Любая игра представляет собой перечень характеристик и правил, объединенных командой разработ ки в единый игровой продукт. Можно сказать, что игровой баланс это, по сути, основополагающий фактор, ведь от него зависит как интерес геймера к продукту, так и итоговое впечатление пользователя об игре. При этом важно понимать, что баланс имеет прямую и неразрывную связь с игровой механикой, то есть можно говорить о необходимости полной отладки всех внутренних процессов. Процесс раскрытия комплексности игры побуждает игрока и дальше исследовать её, открывая новые и спрятанные игровые элементы. Один их к лючевых особенностей игр — нелинейный рост как цены, так и пользы от улучшения, но рост цены значительно выше относительно роста прибыли. В перспективе такой рост имеет смысл: если бы соотношение цены и пользы не увеличивалось, например, за цену 1 всегда б ы покупалось 0,2 скорости роста, то не было бы никакой вариативности дохода, и скорость росла бы стабильно и предсказуемо относительно цены. Это бы очень быстро наскучило. Экспоненциальный рост стоимости имеет плюс при балансировке несколько путей улучшени й: он обеспечивает убывающую доходность на любом из них. Такой подход закладывает механику тактической балансировки доходности в саму формулу, а не в элементы, добавляемые геймдизайнером «сверху». Даже если ускорение получения того или иного ресурса кажетс я более выгодным в конкретный момент, экспоненциальный рост на даёт получать выгоду вечно. Подобная формула используются во множестве инкрементальных игр: Price = BaseCost * Multiplier owned Где Price – Итоговая цена последующего улучшения, BaseCost – Базовая стоимость предмета, Multiplier – Множитель, from 1.07 to 1.15 Owned – Уровень улучшения. Главная цель разработчиков игр — создать по настоящему хорошую игру с оптимальным механизмом монетизации для максимизации прибыли, есть несколько аспектов план ирования и реализации игровой экономики. С юда могут входить планирование стратегии монетизации и структуры внутриигровой экономики, предложение покупки привлекательных ценных вещей и доступность разных схем монетизации внутри игры, каждое направление ценн о само по себе. В случае экономики, нацеленной на доходность проекта, ключевые ограничения диктует рынок. Расчёты не начинаются с предположений гейм дизайнеров и выведенных формул, которые затем корректируются для подгонки под нужный результат. Если игрова я экономика должна приносить проекту доход, нужно понять, при каких показателях он будет окупаться. Именно из этого простого тезиса вытекают все дальнейшие вычисления. Окупаемость продукта (как и любой инвестиции в принципе) описывается таким показателем, как ROI (Return on Investment). Идея проекта заключается в обучении английскому языку посредством простых интересных действий. Обучающая игра "City Language" – это игра приложение, где игрок строит город исследуя слова и открывая реальные объекты города. Н ачиная с 1 домика и  27 первого жителя, игрок расширяет городскую инфраструктуру открывая лавочки, дороги, деревья, мост, магазин, ферму и другие объекты города. Открыв городскую школу появляется возможность изучать грамматику языка, а разведав Ферму для игрок а станут доступны веселые игры с животными. Каждый новый объект позволяет выучить связанное с ним слово, задействовав предыдущие знания урока. Продвигаясь от уровня к уровню, город преобразуется вместе с этим расширяя знания языка. Продукт призван решить п роблему мотивации и создать привлекательные образовательные условия. Игра приложение «City Language» ориентирована на любителей мобильных игр жанра Idle и стратегий. В обучающей игре будет создано 15 игровых тренажеров для развития всех основных языковых н авыков, более 5 000 позиций аудиоконтента и трехсот обучающих видео. В игру приложение будет встроена функция распознавания речи для качественной отработки устной формы языка. Также в проект будут добавлены интеллектуальные системы, которые на основе интер есов и увлечений игрока подберут соответствующий контент. Основная производственная работа делится на итерации. За определенное количество итераций планируется реализовать прототип продукта, затем создать полноценную бета версию продукта. Каждая последующа я итерация предполагает сверку планируемых и осуществленных задач. Предлагается инновационное решение на основе игровой ИКТ технологии ELT (English Learning and Teaching) . Новым в разработке является синтез всех технологий. Разработка проекта делится на р еализацию значимых механик взаимодействия. 1. Интерактивный интерфейс приложения. 2. Многоуровневая игровая карта с наличием всех интерактивных объектов. 3. Игровые системы взаимодействия игрока с виртуальным миром. 4. Распознавание голоса игрока для отработки произношения речи. Потребитель так или иначе сталкивался с изучением английского языка и понимает, что нередко процесс обучения сопряжен с зубрежкой и слепым запоминанием материалов. Приложение позволяет получить такой опыт изучения, в котором упражнения и запоминание лексики обернуто в игру, очень увлекательную и разностороннюю игру. В игре существует 3 режима игры. Первый основной режим, в котором игрок наблюдает всю карту города целиком. Изометрическое пространство позволяет передвигаться по городу с по мощью свайпов и приближать/ отдалять карту. Доступно наблюдать текущие открытые объекты города, а также видеть объекты, которая можно открыть уже сейчас. Для этого на карте располагается школа , нажав на которую игроку предлагается выучить набор слов, а на ферме он может зарабатывать валюту и решать простые задания, чтобы подтвердить, что игрок выучил материал. Выучив материал, игрок может перейти в другой режим и открыть объект. Второй режим также определяется видом камеры, в котором можно масштабировать и взаимодействовать с объектами города. Представлены знаки вопроса, которые обозначают, что можно открыть новый объект, обновить старый или помочь персонажу. Третий режим: режим в котором игрок изучает лексику, грамматику, решает блоки задач (см. Рис. 1) . Рис. 1. Режимы обучающей игры По данным компании DFC Intelligence, к середине 2022 года количество людей, играющих в видеоигры, выросло до 3,1 миллиарда. Учитывая, что в июле общее население Земли превысило 7,8 миллиарда, с играми знакомо чуть меньше 40%. Аналитики отмечают, что почти половину учтённых трёх миллиардов составляют те, кто играет только на смартфонах или мобильных устройствах. Этот сегмент также опережает все остальные по темпам роста. Объем российского рынка видеоигр по итогам 2022 года дости г 177 млрд рублей по данным аналитики игр NewZoo. Согласно исследованию, самый быстрорастущий сегмент рынка — мобильные игры. На его долю приходится 43% от общего объема игровой индустрии (см. Рис. 2) . Рис. 2. Объем рынка игр Индустрия видео игр – одна из самых быстро развивающихся отраслей информационных технологий и одновременно глобального сектора развлечений. В предыдущие пять лет игровая индустрия во всем мире переживает бурный рост. Рост наблюдался во всех сегментах, но основными драйвер ами в этот период стали мобильные игры на двух основных платформах iOS и Android. 

: ПАНО, дерево решений, классификация, регрессия , биохимия, лактатный порог. 1. Введение Порог анаэробного обмена (ПАНО) — момент перехода энергетического метаболизма в мышечной ткани на преимущественно анаэробный гликолитический путь ресинтеза АТФ (уровень интенсивности нагрузки, при котором концентрация лактата в крови начинает резк о повышаться, поскольку скорость его образования становится выше, чем скорость утилизации). Уровень ПАНО спортсмена – показатель его уровня выносливости. Например,  чем выше ПАНО, тем выше скорость, которую спортсмен может развивать без накопления молочной кислоты при занятии циклическими видами спорта. При разном уровне физической подготовки ПАНО значительно отличается: у начинающих он находится на уровне 65 75% от максимальной частоты сердечных сокращений (ЧСС), у подготовленного спортсмена лактатный порог составляет около 85 95% от максимальной ЧСС. Так же уровень ПАНО у людей с различными заболеваниями может быть показателем готовности к операции [1]. Привычные методы определение ПАНО проводятся в лаборатории, под наблюдением специалиста, который отслежив ает время и уровень лактата и требуют от спортсмена выполнения большой физической нагрузки. Такие л абораторные исследования достаточно точные , однако у них есть ряд недостатков. Во первых, они дорогие, во вторых, требуют многократного отбора проб . Поэтому возникает задача прогнозирования и оценка ПАНО без сложных тестов. В статье [2] предлагается альтернативный тест для оценки адаптации организма к физическим нагрузкам. Так же в [3] рассматриваются вопросы предсказания ПАНО на основе методов машинного обуче ния. Задача данного исследования – построение и анализ модели оценки порога анаэробного обмена у спортсменов на основе клинико лабораторных исследований . 2. Описание данных Для построения моделей были использованы результаты клинико лабораторных исследований спортсменов (MCV, MCHC, КФК , к реатинин, АСТ, АЛТ, мочевина и другие) и показатель уровня ПАНО (время достижения), определенного на основе ступенчат ого тест а на беговой дорожке. Всего было проведено 47 тестов. На первом этапе построена корреляционная матри ца для оценки линейной зависимости между временем наступления ПАНО и другими параметрами. Наибольшее положительное значение корреляции Пирсона имеют такие параметры как: средний объем эритроцитов (MCV) 0.27; показатель насыщения эритроцита гемоглобином (MC HC) 0.22 и фермент ответственный за биоэнергетику мышечных сокращений (КФК) 0.16. Наибольшая обратная корреляция с ПАНО имеют: к реатинин 0.34, аланинаминотрансфераза (АЛТ) 0.33, м очевина 0.29 и АСТ 0.24. Для оценки нелинейной зависимости между параметр ами был выбран максимальный информационный коэффициент (англ, MIC – m aximal information coefficient), который способен улавливать нелинейные взаимосвязи. Коэффициент MIC оценивает зависимость между двумя переменными, разбивая множество различными способами и выбирая из этих разбиений «наилучшее», путем вычисления взаимной информации [4]. Наибольшее значение коэффициента MIC : к реатинин 0.37, м очевина 0.33, АСТ 0.31, т реонин 0.31. 3. П остроение моделей предсказания ПАНО a) Построение регрессионной модели предсказания ПАНО На данном этапе исследований была разработана регрессионная модель предсказания ПАНО на основе дерева решений. Выбор алгоритма обусловлен тем, что в данной задаче важна интерпретируемость модели. Так как число выборки мало, тестирование модели осуществлялось с помощью перекрестной проверки (англ. cross validation). Была рассчитана средняя абсолютная ошибка MAPE (англ. mean absolute percentage error). Значение средней абсо лютной ошибки на перекрестной проверке составило 14%. Построенное дерево решений представлено на рисунке 1. Рис. 1 Модель предсказания ПАНО b) Построение классификационной модели предсказания ПАНО На втором этапе исследований задача регрессии Χ → ℝ была сведена к задаче классификации Χ → { 1 , 2 , 3 } . Для этого была введена нов ая переменная, соответствующая классу значения «время достижения ПАНО»:  Класс 1 (время достижения ПАНО <15,76 мин) – низкая работоспособность.  Класс 2 (время ПАНО от 15,76 до 17,15 мин) – средняя работоспособность.  Класс 3 (время ПАНО >17,15 мин) – высокая работоспособность. Далее данные были представлены в трехмерном пространстве с помощью алгоритма равномерной аппроксимации и проекции многообразия ( англ. u niform m anifold a pproximation and p rojection , UMAP). Результ аты представлены на Рисунке 2. Рис.  2 Визуализация UMAP по всем параметрам Удаление избыточных признаков позволяет сократить время настройки модели, повысить её точность и облегчить интерпретируемость. При использовании древовидных методов эта задача и вовсе может быть самой значимой, так как большое число признаков может приводить к переобучению модели. С целью выбора наиболее значимых признаков была построена более сложная модель дерева с применением градиентного бустин га над решающими деревьями и выбраны наиболее значимые параметры в данной модели. После этого была построена модель на основе дерева решений. Точность работы модели классификации  на перекрестной проверке составила 50 %. Дерево решений для задачи классификац ии представлено на рисунке 3. Рис. 3 Модель предсказания класса ПАНО 4. Заключение В результате работы были построены классификационная и регрессионная модели классификации на основе данных 47 спортсмен ов . Ошибка регрессионной мод ели составила 14 %. Точность классификационной модели составила 50%. Низкая точность модели классификации объясняется недостаточным для построения полноценной модели объёмом данных. Однако при случайном назначении класса результат составил бы 100/3~33%, поэ тому предлагаемая модель имеет смысл для определения ПАНО. 

: цифровые технологии, web сервис, база данных, клиент серверная архитектура приложения, прикладной интерфейс, а втоматизация процессов, обслуживание клиентов в сфере сервиса.  Введение В статье будет рассмотрен частный случай web сервиса для самостоятельной записи клиентов автосервиса. Потребность возникновения web сервиса с расширенным функционалом, формировалась уже давно. Автомобили стали более сложными и доступными одновременно, простому пользователю автомобиля уже нет нужды разбираться во всех его тонкостях. Поэтому, когда приходит время очередного ТО, владельцу современного автомобиля приходится нелегко, и в д анном случаем владельцу придёт на помощь web сервис, который уже знает всё про его автомобиль. Пользователю остаётся только ввести актуальный пробег, а вэб приложение проведёт индивидуальный расчет с учетом уникальной комплектации, стоимости норма часа и с кидки по возрасту автомобиля. После чего, клиенту, будет предоставлен заказ наряд с подробным описанием всех необходимых работ и запасных частей. Анализ предметной области На данный момент, даже типовые заявки от клиентов автосервиса, обрабатываются с помо щью персонала. По данным, предоставленными компанией Sigma Motors GmbH количество записей клиентов на автосервис с целью проведения планового технического обслуживания составляет около 30% от общего числа заявок. Запись в свою очередь состоит из следующих этапов:  регистрация клиента в базе компании  получение от клиента данных, касающихся конфигурации автомобиля (марка, модель, vin номер, срок эксплуатации и пробег)  составление сотрудником предварительного заказ наряда  отправка предварительного заказ наряда на электронную почту клиента Разработка веб приложения для самостоятельной записи клиентов на плановое ТО с функцией автоматического формирования заказ наряда и его (заказ наряда) последующей отправкой на электронную почту клиента позволит автоматизировать процедуру записи клиентов на плановое ТО и высвободит ресурсы, затрачиваемые персоналом на обработку таких заявок. постоянно искать баланс между пропущенными звонками (упущенная прибыль) в часы пик и количеством штатных сотрудников. Функциональность web сервиса Для создания приложения с клиент серверной архитектурой был выбран язык Java. Это кроссплатформенный язык, который позволяет создать переносимый код и исполнять его в разных операционных системах. Java обладает хорошей организацией кода, гибкос тью и простотой поддержки. С точки зрения функциональности web сервис можно рассмотреть с двух сторон: 1. Со стороны клиента компании:  самостоятельный, наглядный выбор удобного времени записи;  расчет точной стоимости регламентных работ или первичной диагности ки;  ведение личной базы посещений сервиса, с историей работ и фиксацией пробега, на котором проводились те или иные работы;  возможность регистрации нескольких автомобилей открывает дополнительные возможности сотрудничества с корпоративными автопарками. 2. Со стороны сотрудников компании:  регистрация в сервисе клиентов компании;  просмотр и редактирование доски записи;  просмотр и последующая работа с уже сформированными  заказ нарядами Для получения полного доступа к возможностям web сервиса, клиенту необходимо пройти регистрацию в салоне. Клиент может выполнить регистрацию в системе либо при покупке автомобиля, либо в любое другое удобное время. Всех клиентов подтверждают сотрудники сервиса по документам, удостоверяющим личность. Данная реализация позволяет избе жать недобросовестных действий от фирм конкурентов и случайных гостей интернет портала. Также сотрудники сервиса сверяют VIN номер автомобиля и вносят точные данные по комплектации в программу, на основании которых, в дальнейшем будут происходить расчеты. При совершении записи клиент выбирает тип планируемых работ (плановое обслуживание либо первичная диагностика), автомобиль, который записывает на данные работы и вводит текущий пробег автомобиля. Приложение, основываясь на данных автомобиля составляет спи сок необходимых работ исходя из возраста и пробега. По факту записи клиенту отобразится предварительный заказ наряд, который он сможет распечатать или отправить себе на почту. Заказ наряд в любом случаем сохранится в личном кабинете, там же рядом с автомоб илем появится информация о записи. Также предполагается дальнейшая реализация отправки смс сообщения с напоминаем о времени записи. Сотрудники сервиса имеют более расширенный функционал. У них есть возможность добавления и редактирования информации автомоб иля клиента (в случае смены владельца и/или гос. номера), редактирование и отмена записей клиентов. Подразумевается интеграция предварительно сформированного заказ наряда в систему, используемую на предприятии («1С» или аналогичную), для дальнейшей работы с ним. Структурная схема базы данных Рис. 1 . Общая структурная схема базы данных База данных web сервиса реализована исходя из потребностей конкретной станции технического обслуживания. Основной состав базы данных:  клиенты (контрагенты) сервиса;  заказ наряды клиентов;  сотрудники сервиса с матрицей рабочего времени;  модели автомобилей, состоящие из уникальных комбинаций двигателей, типов трансмиссий и нормо часа, на основании которых формируется предварительный заказ наряд;  список работ и запчастей , которые подбираются исходя из типа запрашиваемых работ и конкретного автомобиля. Для создания базы данных использовался HyperSQL, который хорошо интегрируется с приложением на Java. Взаимодействие между клиентом и промежуточным уровнем реализовано по про токолу HTTP. А прикладной интерфейс JDBC будет служить для управления взаимодействием между промежуточным уровнем и сервером базы данных: Рис. 2. Схема клиент серверного вза имодействия Web интерфейс Рис. 3. Доска записи доступная для авторизированных клиентов Web интерфейс создан с помощью технологий HTML и CSS, а на стороне сервера обработаны с помощью JavaServer Pages (JSP). Полный интерфейс доступен только для подтверждённых клиентов сервиса. Доска записи ф ормируется исходя из даты и конкретных мастеров и механиков, работающих в этот день. Клиент сервиса видит свободные (с временем) и занятые (с автомобилями) ячейки записи. Для записи на определённое время пользователю (клиенту) необходимо добавить свой авт омобиль в личный кабинет, где он укажет данные автомобиля. Доска записи для сотрудников сервиса имеет более подробный вид и расширенные функции. Клиентам доступны не все возможные ячейки записи, сотрудники сервиса исходя из текущей загрузки и могут записы вать и других клиентов без авторизации. Работникам сервиса доступен шаблонный вариант записи без внесения данных (соответственно и без предварительного расчета). Заказ наряд формируется в формате PDF (рис.4), хранится на сервере и может быть отправлен на э лектронную почту клиента. Интерфейс личного кабинета Рис. 5. Окно личного кабинета пользователя Рис. 4. Предварительный заказ наряд В личном кабинете у пользователя есть возможность добавлять свои автомобили, которые он сможет в дальнейшем записывать на обслуживание. Также будет добавлена история посещений сервиса и просмотр сформированных ранее заказ нарядов. Заказ наряды, по которым уже проведено обслуживание, будут доступны только для просмотра и сохранения. Клиент может записать один автомобиль один раз в интерактивной доске записи. При этом у клиента может быть несколько автомобилей, и дальнейшая реализация вэб приложения предусм атривает ведение истории записей автомобилей клиента, с отображением текущей записи, если таковая имеется. Данная функция будет удобна, как физическим лицам, так и юридическим, которые ведут собственные автопарки. Заключение Разработан полноценный прототип web сервиса, содержащий бизнес логику и предоставляющий дополнительные возможности по автоматизации процесса записи клиентов для фирмы. С точки зрения клиента, есть удобная возможность произвести запись своего транспортного средства в любое время (а не то лько в часы работы сервиса) и сразу получить точный расчет по всем позициям в заказе. 

: естественные языки, машинное обучение, обработка текстовой информации, анализ текстовой информации Одна из задач, стоящих перед специалистами в области машинного обучения – научить компьютер работать с естественными языками. Уточним, что естественный язык – это любой человеческий язык, например, английский или русский. Общение на таком языке присуще и привычно для людей. А вот общение с компьютерами зачастую сводится к тому, что человеку нужно знать «я зык машины», для того, чтобы передавать ему запрос или информацию, по которому хочется получить какие то данные. Поэтому специалисты работают над тем, чтобы научить компьютеры понимать, обрабатывать и пользоваться естественными языками. Благодаря таким воз можностям технология может извлекать информацию и аналитические данные, содержащиеся в документах, а также позволяет классифицировать и упорядочивать сами документы. Но вообще, нельзя забывать, что есть аспекты, которые могут помешать нормальному восприяти ю информации, переданной человеком компьютеру. Например, достаточно трудно учесть все факторы для того, чтобы компьютер понимал такой язык, а в особенности – отличал между собой диалекты, акценты и прочие особенности. Также нельзя забы вать, что люди тоже с пособны ошибаться в написании слов или использовании тех или иных речевых конструкций. Д ля того, чтобы компьютер понимал предложения, их делят на синтаксические единицы, составляя таким образом дерево синтаксического анализа. После этого происходят некотор ые изменения в исходном тексте, чтобы компьютер мог выделить важные для исследуемой области слова и словосочетания, по которым будет произведён анализ. Так как в рамках NLP решается достаточно широкий круг задач – от машинного перевода до краткого пересказ а текста, предобработка данных сводится к разным этапам, однако классически это: • токенизация по предложениям и /или по словам ; • лемматизация текста ; • удаление стоп слов ; • нормализация; • векторизация. Здесь, при необходимости, могут появляться дополнительные этапы: например, очистка текста, аннотирование и т.п. Прохождение данных этапов необходимо для исключения неверных трактовок со стороны алгоритма при дальнейшей обработке текста. Так, без нормализации текста его векторизация может пойти не п о плану. Слова, используемые в тексте с разным склонением, распознаются как разные, хотя для большинства задач их понимание должно основываться на их одинаковости. Поэтому необходим этап нормализации, который приведет все формы слова, встречающиеся в текст е, к начальной, и векторизатор будет воспринимать их как одно слово. В рамках создания модели, определяющей категории текстов, поступающих ей на вход, схема работы с данными была немного подкорректирована под основную задачу (рис 1.) . Сама задача звучала т ак: необходимо распределить тексты из входных данных на категории, отвечающие определенным требованиям. Рис. 1. Схема процесса решения поставленной задачи Здесь очистка данных предполагает дополнительный анализ на предмет наличия несодержательной информа ции для самого анализа. Такие данные просто выделялись по тем или иным признакам (ключевым словам или меткам) и удалялись из исследуемого набора. Предобработка данных состояла в лемматизаци и текста , удалении стоп слов и дальнейшей нормализации. Для этих ц елей использовалась предварительно обученная модель на русском языке ru_core_news_sm. По своей сути – это NLP конвейер, включающий несколько компонентов: токенизатор, синтаксический анализатор, лемматизатор и пр. Ее использование позволяет нормализовать те кст для дальнейшего анализа. Для проведения векторизации изучались некоторые аспекты. Существует два распространенных метода векторизации текстов: Bag of words и TF IDF vectorizer [1] . Однако использование первого метода сопряжено с некоторыми трудностями, в том числе ограниченным набором входных данных. Это стало причиной изучить еще один метод векторизации, похожий по принципу работы на Tf Idf – Count V ectorizer – и сравнивать уже эти два метода между собой. Count V ectorizer – это метод преобразования текс та в разреженную матрицу, которая содержит частоту вхождения каждого слова в набор входных данных. В таком представлении каждый столбец – это уникальное слово (или n грамма) из входных текстовых данных, а каждая строка – количество вхождений этого слова в текст. По умолчанию в этот векторизатор встроены даже преобразование текста в нижний регистр и токенизатор по словам. Это позволяет в некоторых случаях упростить процесс предобработки. Count Vectorizer полезен для определения частоты встречаемости в тексте слов, с помощью чего, например, можно определить тематику текста. Но его главные недостатки [ 2 ] : • на основе матрицы нельзя определить важность слова для анализа; • метод определяет часто встречающиеся в тексте слова как наиболее статистически значимые; • отсутствует разделение отношений между словами (лингвистическое сходство и т.п.) В свою очередь TF IDF vectorizer преобразует каждый текст в его векторное представление. Основная идея заключается в том, чтобы пренебрегать весом слов, которые встречаются ч аще во входных данных, потому что такие слова будут иметь меньшее влияние при дальнейшей классификации [ 2 ]. Для расчета матрицы используются два показателя: 푇퐹 = 푓 ( 푞 , 퐷 ) 푓 ( 푡 , 퐷 ) 퐼퐷퐹 = log 푁 푁 ( 푞 ) Исходя из этих соотношений, общий показат ель рассчитывается как их произведение: 푇푓퐼푑푓 = 푇퐹 ∗ 퐼퐷퐹 Здесь TF – частота конкретного токена в данном документе, а IDF показывает насколько часто конкретный токен встречается во всех входных документах. Сам анализ входных данных сначала был основан на использовании методов кластеризации. Казалось, учитывая широкую распространенность в сфере категоризации новостей и подобных текстов, это мог быть лучший выбор для решения. Были использованы вариационный алгоритм декомпозиции Байеса и K Means , однако н и один из алгоритмов не дал практически значимого в рамках решаемой задачи результата. 

, по которым определялись топики для текстов, не определялись должным образом из за наличия разброса в тематиках внутри одной категории. Таблица 1 Сравните льный анализ скорости и точности обработки данных разными методами Примененный алгоритм Кол во обработанных предложений Количество категорий Скорость всех стадий алгоритма (сек) Скорость обучения модели (сек) Точность модели Классификатор Байеса (CV) 10000 3 99 2,1 <0,1 K Means (CV) 18375 3 105,25 6,21 0,404 K Means (TfIdf) 18375 3 106,38 7,34 0,229 Random Forest (CV) 18375 3 176,56 5,93 0,935 Random Forest (TfIdf) 18375 3 191,13 8,78 0,936 Таким образом, был сделан выбор в сторону классификации текста с помощью алгоритма Random Forest , но с учетом предварительного аннотирования. Несмотря на достаточно наивное ручное аннотирование входных данных, точность работы самого алгоритма в разы отлича лась от кластеризации, причем в лучшую сторону. Сама разметка данных – дорогостоящий процесс, который требует больших временных затрат. Использованная в качестве пробной в ходе разработки разметка не может использоваться для корректного обучения модели, та к как нет формализации входных данных. Они написаны людьми в разном стиле и один и тот же тип может основываться на разных ключевых словах. Несмотря на это, использование классификации в рамках поставленной задачи позволило достичь хорошей точности предска зания, и может использоваться в дальнейшем при модернизации разработанной модели для системы. В ходе подготовки данных к анализу была проведена исследовательская работа методов предобработки текста, понимание которых может в дальнейшем помочь оптимизироват ь разработанную модель и улучшить точность получаемых данных. 

: машинное обучение, компьютерное зрение, гистологические микропрепараты, рак молочной железы Введение Компьютерное зрение, представляющее собой современную технологию, позволяющую обнаруживать и классифицировать объекты, находит свое применение при анализе биомедицинских изображений, таких как рентгеновские снимки и микрофотографии, включая цитологические и гистологические изображения [1 3 ]. Одной из наиболее изученных и социально значимых областей, где машинное обучение пользуется повышенным спросом, является морфологическое исследование микропрепаратов рака молочной железы [1 3 ]. Первый этап работы Первым этапом нашей работы была оценка возможностей машинного обучения в онкоморфологии путем проведения информационного пои ска. Из 8000 статей, опубликованных в период с 2018 по 2023 год, мы отобрали 45 статей для детального анализа по указанной теме работы. Согласно данным из этих статей, машинное обучение позволяет подсчитывать и выделять определенные клетки и тканевые струк туры, ядра, митозы, а также оценивать и прогнозировать экспрессию иммуногистохимических маркеров. Кроме того, модели на его основе могут рассчитывать комплексные показатели выживаемости, прогноза и клинического течения заболевания [ 2 ]. Второй этап работы В торой этап нашей работы заключался в создании собственной базы изображений гистологических микрофотографий молочной железы. Эти препараты были окрашены гематоксилином и эозином и включали как нормальные состояния, так и различные патологические процессы, т акие как неопухолевую патологию, доброкачественные и злокачественные новообразования. Мы накопили более 4,5 тысяч изображений размером 1920х1440 пикселей, которые были разбиты на фотографии размером 300х300 пикселей – оптимального формата для разметки и об учения моделей. В результате было получено более 135 тысяч микрофотографий (Рис. 1) . Рис. 1. Примеры итоговых изображений базы данных. а – Карцинома in situ ; б – Воспаление; в – Инфильтрирующая карцинома. Третий этап работы Третий этап нашей работы сост оял в выборе признаков для аннотации и тестовой разметки. Мы отобрали их на основе анализа и обобщения результатов опубликованных и проанализированных исследований. Большинство авторов используют бинарную либо  многоклассовую классификацию на основе гистоло гического типа патологического процесса, однако имеются и расширения данной парадигмы. Перечень признаков, выбранный нами, состоит из информации о наличии/отсутствии эпителия, стромы, жировой ткани, края препарата, лейкоцитов, а также карциномы in situ и и нфильтрирующего рака. Далее они будут использованы для аннотирования изображений в ходе пробной и последующей разметок. Заключение В заключение отметим, что начальные этапы исследований по теме машинного обучения являются наиболее ресурсоемкими и трудоемки ми, но играют решающую роль в определении результатов последующей работы. Хорошо подготовленные данные — важнейший аспект успешной работы всей системы, основанной на компьютерном зрении, особенно в биологии и медицине. Возможность подсчета и выделения спец ифических клеток и тканевых структур, ядер, митозов, оценки и прогнозирования экспрессии иммуногистохимических маркеров особенно полезна при морфологическом изучении микропрепаратов рака молочной железы, что является социально значимой областью исследовани й. Наша работа заключалась в создании собственной базы данных изображений гистологических микрофотографий молочной железы, которая поможет в будущих исследованиях в этой области. 

: обработка естественного языка, геокодирование, расстояние Левенштейна Введение Одним из важных аспектов планирования ремонтных работ на дорогах является учет жалоб граждан на состояние дорожных покрытий. Учет позволяет оценить реальную ситуацию на дорогах и принять правильные решения по распределению бюджетных  средств на ремонт. Анализ жалоб граждан на состояние дорожных покрытий и плановых работ позволяет определить наиболее проблемные участки и оценить эффективность запланированных мероприятий. В результате можно разработать рекомендации по улучшению планирования ремонтных работ, что позволит снизить количество точечных ремонтов и достичь экономических и качественных выгод. Такой подход обеспечивает безо пасность дорожного движения и комфортность передвижения людей. Для анализа могут быть использованы данные находящиеся в открытом доступе: данные о реализованном плане ремонтных работ предоставляются Государственной административно технической инспекцией (Г АТИ), данные о жалобах на дорожное покрытие предоставляются порталом «Наш Санкт Петербург». Проблемой учета жалоб граждан в план е ремонтных работ является сложность сопоставления жалоб и плана. Под сопоставлением данных предполагается определение жалоб, к оторые были решены в результате того или иного ремонта. Для сопоставления необходимо учитывать различия в формате представления информации: план содержит адреса в слабо формализованном виде, а жалобы граждан содержат координаты . Целью работы является реали зация алгоритма сопоставления плана ремонтных работ и жалоб граждан . Предобработка данных Портал «Наш Санкт Петербург» это сервис, с помощью которого жители Петербурга могут сообщить о проблемах, связанных с ЖКХ и благоустройством, состоянием дорог, неза конными объектами строительства и торговли. Жалобы с портала «Наш Санкт Петербург» можно выгрузить с помощью API. Для выгрузки были выбраны обращения граждан по причин е неудовлетворительного состояния асфальтового покрытия. Среди имеющихся полей данных у каждой жалобы, используются следующие: id обращения, id автора, id причины обращения, широта, долгота, дата создания обращения, дата обновления состояния обращения, причины закрытия проблемы (пользователь удовлетворен решением проблемы, автоматически, нар одный контролер подтвердил решение проблемы), является ли обращение закрытым и статус (модерация, отклонена, рассмотрение, получен ответ, промежуточный ответ). Данные имеют большую долю дубликатов, а также жалоб не прошедших модерацию. Очистку от дубликат ов можно осуществить с помощью удаления жалоб имеющих одинаковые координаты и автора. Данные не прошедшие модерацию отбрасываются фильтрацией по статусу обращения, остаются жалобы с полученным ответом или с полученным промежуточным ответом. Государственная административно техническая инспекция (ГАТИ) проводит государственную политику в сфере государственного контроля за соблюдением правил благоустройства и организацией производства земляных и строительных работ. Данные о производстве ремонтных работ распрос траняются в виде файла с табличными данными. Каждая ремонтная работа имеет следующие поля данных: код заявки, адрес производства работ, вид работ, фактические начало работ и фактический конец работ. Поле вида работ представляет собой слабо формализованны й текст, что затрудняет извлечение работ связанных с ремонтом дорожных покрытий из всего массива данных. Для поиска нужного вида работы можно использовать регулярные выражения формальный язык, используемый в компьютерных программах, работающих с текстом, для поиска и осуществления манипуляций с подстроками в тексте, основанный на использовании  метасимволов [1] . Для поиска используется строка образец, состоящая из символов и метасимволов и задающая правило поиска. В данном случае, в качестве строк образцов выступают: “покрыт”, “а/б” и “асфальт”, что позволяет выделить работы по ремонту асфальтобетонного покрытия. Адрес ремонтных работ также представляет собой слабо структурированный текст. В поле адреса могут находится адреса отдельных домов (“кронштадтская ул., д.4, лит.а”), участки улиц (“ул.латышских стрелков от ул.ворошилова до ул.кржижановского”), несколько домов (“лиственная ул., д.14 д.20.”), а также отдельные улицы. Для извлечения адресов можно воспользоваться библиотекой для извлечения именованны х сущностей Natasha. В результате работы библиотеки мы получаем отдельно названия улиц и номера домов с литерой. Для адресов записанных в формате: “ул.латышских стрелков от ул.ворошилова до ул.кржижановского” созданы регулярные выражения, которые извлек ают каждую улицу отдельно. Геокодирование адресов ремонтных работ Адреса ремонтных работ и жалобы граждан можно сопоставить по географическим координатам. Обращения граждан уже имеют координаты, адреса работ же необходимо привести к виду вектора географич еских координат. Адреса ремонтов могут представлять собой: целые улицы или отдельные дома. Координаты улиц предоставляются библиотекой osmnx, которая берет данные из OpenStreetMap некоммерческого веб картографического проекта по созданию подробной свобо дной и бесплатной географической карты мира. Osmnx представляет улицу в виде ломанной линии, а город в виде графа, где ребра это улицы. Сопоставить полученные адреса улиц с координатами улиц можно по названиям. Извлеченные адреса могут быть представлены в разных формах слова, что необходимо учитывать. Для сопоставления улиц можно использовать алгоритм нечеткого сравнения [ 2 ], данный алгоритм предоставляется библиотекой FuzzyWuzzy. Библиотека используется для расчета расстояние Левенштейна метрики, измер яющей по модулю разность между двумя последовательностями символов. Она определяется как минимальное количество односимвольных операций (а именно вставки, удаления, замены), необходимых для превращения одной последовательности символов в другую. Извлеченн ые названия улиц ГАТИ сравниваем с названиями улиц из OpenStreetMap. Улица OpenStreetMap имеющая наименьшее расстояние Левенштейна до извлеченного адреса ГАТИ выбирается как адрес ремонтных работ. Сопоставив адреса ремонтных работ с улицами из OpenStreetMa p можно получить необходимые координаты. В случае, когда адрес ремонта представляет собой адрес дома или совокупность домов, для определения координаты можно воспользоваться геокодером. Геокодирование позволяет определять координаты и получать сведения об объекте на карте по его адресу. В качестве геокодера можно использовать API сервис портала “Цифровой Петербург”. В результате обработки данных ГАТИ, мы получили адреса ремонтных работ дорожного покрытия в виде координат. Сопоставление ремонтных работ с жалобами граждан на качество дорожного покрытия Принадлежность жалобы ремонтной работе можно определить по расстоянию между этими двумя объектами, а также по соответствию временных промежутков производства ремонтной работы и существования жалобы. Если адр ес ремонта представлен улицей, то данный географический объект является  ломаной линией. Жалоба представляет собой точку в двумерном пространстве. Для определения принадлежности жалобы улице, необходимо рассчитать евклидово расстояние от каждого отрезка ло маной улицы до точки жалобы. Если расстояние от точки до ломаной не превышает заданное значение, то считаем, что данные объекты географически соотносятся. Для повышения эффективности расчета евклидова расстояния, расчет можно производить только для жалоб н аходящиеся на достаточном расстоянии до вершин ломаной, то есть сначала производится расчет расстояния точки до вершин, затем , в случае достаточной близости, до отрезков. Если адрес ремонта представлен в виде названия улицы с номерами домов, то принадлежно сть ремонта определяется расстоянием до координаты адреса или совокупности координат в случае, когда в адрес входят несколько зданий. Когда расстояние не превышает установленно е значение , то считаем, что данные объекты географически соотносятся. Для соот несения ремонтных работ по временным промежуткам, необходимо учитывать дату начала и дату конца ремонтных работ, а также дату создания жалобы на дорожное покрытие и дату удовлетворения жалобы, в случае, если она удовлетворена. По отношению дат работ и жа лоб, можно выделить следующие случаи:  Жалоба подана до начала или во время ремонтных работ и удовлетворена в процессе ремонта;  Жалоба подана до начала ремонтных работ и удовлетворена до ремонта;  Жалоба подана до начала ремонтных работ и удовлетворена после ремонта;  Жалоба подана до начала или во время ремонтных работ и не удовлетворена на момент выгрузки данных;  Жалоба подана после ремонтных работ. Ремонтные работы удовлетворили жалобу гражданина, если жалоба удовлетворена во время ремонта. Если жалоба соз дана до окончания работ и не удовлетворена во время ремонтных работ, считаем. что данный ремонт не удовлетворил жалобу гражданина. Анализ соответствия плана ремонтных работ потребностям граждан Результаты сопоставления данных, полученных с портала «Наш Санкт Петербург», по жалобам граждан на состояние дорожных покрытий и данных по плановому ремонту дорожных покрытий позволяют оценить оптимальность запланированных работ и разработать рекомендации по внесению изменений в них.  Рис. 1. Граф дорог Санкт Петербурга с нанесенными соотнесенными жалобами (черные точки) Заключение Произведена работа по реализации механизма предобработки слабо формализованных данных. Реализовано геокодирование адресов ремонтных работ. Создан ал горитм сопоставления дорожных работ и жалоб граждан на состояние дорожного полотна. Полученные результаты могут помочь оценить эффективность запланированных мероприятий, разработать рекомендации по улучшению планирования ремонтных работ, что позволит дости чь экономической выгоды и повысить безопасность на дороге. 

: киберфизические системы, временные ряды, аномалии, оценка эффективности, метрики Одним из следствий глобальной автоматизации и цифровизации стало повсеместное использование киберфизических систем. Одной из главных характеристик таких систем является тесная связь между физическими и вычислительными процессами: система получает данные от датчиков в реальном мире, анализирует и использует их для дальнейшего управления физическими элементами. Атаки на систему могут привести к критическим последствиям: от ошибок в работе и неправильного управления до полного отказа системы. В общем случае атаки вызывают аномалии отклонения от ожидаемого поведени я системы. Важной задачей является обнаружение этих атак на ранней стадии. Для многих киберфизических систем показатели датчиков можно представить в виде временного ряда, в котором каждый показатель привязан ко времени его возникновения. Он позволяет предс казать поведение системы в последующих периодах работы, исходя из значений в предыдущих. Аномалии на временном ряду принято делить на несколько видов: 1) Точечные аномалии – отклонение в поведении наблюдается в отдельных временных точках; 2) Групповые аномалии – наблюдается аномальное поведение группы последовательных точек, каждая из них не считается отдельной точечной аномалией; 3) Контекстные аномалии – наблюдается, если поведение экземпляра аномально только при определенном внешнем контексте (условии). Даже пр и наличии хорошей визуализации данных вручную легко обнаружить в основном только точечные аномалии (выбросы), поэтому в последнее время широкое распространение получили подходы, основанные на методах машинного обучения. В настоящее время предложены различн ые методы обнаружения аномалий. Наравне с классическими методами выявления аномалий широко применяются методики, основанные на использовании глубоких нейронных сетей. Так в [1] предлагается использование двух моделей Isolation Forest, авторы [2] сравнивают применение one class SVM (Support Vector Machine) и модель глубокой нейронной сети с использованием архитектуры LTSM, в работе [4] предлагают использование автоэнкодеров, в [5] и [6] рассматриваются методы с применением GAN (Generative adversarial network ). Важным моментом при использовании методов машинного обучения является выбор метрик, которые позволяют оценить эффективность обнаружения аномалий. Существует  множество методов оценки работы модели, и очевидно, что для точного сравнения алгоритмов выявлен ия аномалий необходимо выбрать метрику, которая оценивала бы не только обнаруженные точки выбросы на временной оси, но и могла оценить точность и полноту предсказания групповых аномалий.  Можно выделить следующие классы метрик для оценки эффективности алг оритмов обнаружения аномалий: 1) Метрики бинарной классификации – каждой точки присваивается один из двух классов – нормальный или аномальный 2) Обнаружение на основе окна – сопоставление прогнозируемой аномальной точки с окном вокруг истинной аномальной точки 3) В ремя точки обнаружения – вычисление расстояния между истинной и предсказанной аномальной точкой (а) Обнаружение на основе окна (б) Время точки обнаружения Рис. 1. Классы метрик для оценки эффективности алгоритмов обнаружения аномалий Следует отметить, что во всех ранее рассмотренных исследованиях [ 1 , 2 ,5 7] используются традиционные методы оценки эффективности, основанные на матрице ошибок , т.е. методы, которые выполняют поточечную оценку выявления аномалий . Таблица 1 Матрица ошибок Реальные значения Предсказанные значения норма аномалия норма T N FN аномалия FP TP Матрица ошибок сообщает число истинно положительных, истинно отрицательных, ложноположительных и ложноотрицательных экземпляров, определенных алгоритмом обнаружения аномалий. С помощью этих значений возможно вычислить классические метрики бинарной классифи кации: отношение верно классифицированных точек к их общему количеству 푎푐푐푢푟푎푐푦 = 푇푝 + 푇푛 / 푇푝 + 푇푛 + 퐹푝 + 퐹푛 , отношение верно классифицированных аномальных точек к количеству обнаруженных аномалий 푝푟푒푐푖푠푖표푛 = 푇푝 / 푇푝 + 퐹푝 ( 1 ) , отношение верно классифицированных аномальных точек к общему количеству аномальных точек 푟푒푐푎푙푙 = 푇푝 / 푇푝 + 퐹푛 ( 2 ) . На основе классических (1) и (2) можно вычислить агрегированный критерий качества, называемый F мерой: 퐹 − 푚푒푎푠푢푟푒 = 2 ∗ 푝푟 푒 푐푖푠푖표푛 ∗ 푟푒푐푎푙푙 푝푟푒푐푖푠푖표푛 + 푟푒푐푎푙푙 Все эти метрики хорошо подходят для данных, не имеющих временного измерения: они поощряют алгоритмы за точное попадание в аномалию, но не учитывают обнаружения, близкие к истинным точкам. Также они рассматривают каждую аномалию как точечную, что плохо подходит для остальных видов аномалий. Использование метрик, учитывающих временное расстояние позволяет сравнивать алгоритмы, учитывая, насколько точно они определяют время возникновение аномалии, насколько полно они определяют коллективные аномалии. Рассмотрим следующие новые метрики , предложенные и описанные в работах [ 8 ] , и [ 9 ]: ADC Average Detection Count, TD Temporal distance method, TDIR Total Detected In Range, DAIR Detection Accurac y In Range , WDD Weighted method , range based recall , range based precision , TaPR . Для сравнения метрик введем требования, которым метрика должна удовлетворять: 1) Обнаружение – метод, обнаруживший аномалию, оценивается выше пропустившего ее 2) Близкое обнаружение – метод, обнаруживший аномалию немного позже времени ее появления, оценивается выше не обнаружившего ее ; 3) Ложное обнаружение – метод, определивший нормальную точку как аномалию оценивается ниже метода, не сделавшего это ; 4) Глобальная точность – ме тод, глобально определивший большее число аномалий оценивается выше метода, который более полно определил конкретную коллективную аномалию ; 5) Количество параметров – большее количество параметров позволяет точнее оценить метод, но лишает метрику универсально сти для сравнения. Учет метриками этих требований занесем в таблицу, где “+” – метрика удовлетворяет требованию, “ ” – метрика не удовлетворяет требованию, “/” – метрика не может быть рассчитана для проверки требования (например, в данных нет аномалий) Таб лица 2 Учет метриками требований Обнаружение Близкое обнаружение Ложное обнаружение Глобальная точность Количество параметров precision + / 0 recall / / 0 F measure + / 0 ADC + + + 0 TD / + / + 0 TDIR + + / + 0 DAIR / + / + 0 WDD + + + + 1 range based recall + / + 3 range based precision + / + 3 TaPR + / + 3 Используемые в работах для оценки эффективности методов классические метрики не учитывают особенности аномалий на временных рядах. Исследователями предложено множество метрик, лучше подходящих для оценки обнаружения не только точечных, но и групповых аномалий, возникающих в кибефизических системах. Так каждая из рассмотренных метрик поощряет метод за обнаружение большего количества аномалий, в не за точность обнаружения конкретной. Необходимо подбирать метрику оценки работы алгоритма исходя из требуемых точности и полноты обнаружения аномалий, не ограничиваясь классическими метриками бинарной классификации. 

: компьютерное зрение, нейроморфный процессор, пороговый фильтр Собеля.  Описание проблемы. Процесс дискретного производства (далее производственный процесс) – это сложная организационно техническая система, предназначенная для серийного выпуска штучной продукции и состоящая из производств енного комплекса (оборудования, объединенного в технологич еские линии), набора синхронизированных и взаимозависимых технологических операций, а также нетехнологических (вспомогательных) производственных операций (транспортировка полуфабрикатов, проверка ка чества, обслуживание, упаковка и др.) и средств автоматиче ского и автоматизированного управления. [1]. В данной статье в качестве объекта исследования выбраны процессы контроля качества продукции автомобильного производства, а предметом исследования являет ся изучение возможностей использования нейроморфных процессоров в перспективных системах технического зрения для автоматизации отдельных операций (визуального осмотра) контроля качества лакокрасочного покрытия продукции с использованием современных подход ов и средств вычислительно й техники (искусственных нейрон ных сетей [2] и нейроморфных процессоров [3]). Визуальный осмотр используется при следующих видах контрольных операций: поиск дефекта (несоответствия), например, у неокрашенной з аготовки или окрашенн ого кузова; распознавание символов, например, проверка идентификационного номера автомобиля (VIN – vehicle identification num ber); идентификация наличия элемента, например, проверка наличия наклейки со штрих кодом на компоненте автомобиля. Расчёт вычислит ельной сложности алгоритма Собеля. В системах компьютерно го зрение используются алгоритмы выделения контуров изображений, например, фильтр Собеля. Пороговый фильтр Собеля это метод выделения границ на изображении. Он основывается на вычислении градиента яркости в каждой точке изображения [5 ]. Фильтры Собеля являются небольшими матрицами (как правило, 3*3), которые применяются к изображению с целью получения приближенного значения градиента яркости в каждой точке. Обычно используются две матрицы, одна для вычисления градиента в направлении горизонтали, а другая в направлении вертикали. После применения фильтров Собеля, получается два изображения, которые показывают градиент яркости по горизонтали и вертикали, который является вектором градиента G [ 4 ]. З атем с помощью формулы расчета модуля вектора [ 5 ]: ⌊ 퐺 ⌋ = √ ( 퐺 푥 2 + 퐺 푦 ) 2 находится окончательное изображение градиента яркости, которое позволяет выделить границы контура на изображении. Алгоритм Собеля широко используется в обработке изображений для задач детектирования краев, выделения контуров и других операций, связанных с выделением структур на изображении. Теперь оценим вычислительные затраты реализации данного алгоритма с помощью единицы измерения FLOPs. FLOPS – это количество вычислительных операций или инструкций, выполняемых над операндами с плавающей точкой (FP – Floating Points) в секунду.  Для оценки количества X FP для обработки одного пикселя в K канальном формате  подсчитаем вычислительную стоимость вычисления модуля градиента яркости в этой т очке. Пусть Q вычислительная стоимость модуля градиента яркости пикселя (1) для одного канала. Тогда Q=4. В случае линейной пространственной фильтрации объем необходимых вычислительных операций задается суммой произведения коэффициентов фильтра на соответс твующие значения пикселей в области, покрытой маской фильтра. Пусть необходимо P операций для обработки пикселя ядром матрицей 3*3 для вычисления составляющей 퐺 푥 . 퐺 푥 = ( 푧 7 + 2 푧 8 + 푧 9 ) − ( 푧 1 + 2 푧 2 + 푧 3 ) Аналогично , необходимо P операций для 퐺 푦 . 퐺 푦 = ( 푧 3 + 2 푧 6 + 푧 9 ) − ( 푧 1 + 2 푧 4 + 푧 7 ) Здесь мы видим, что проводится 9 операций умножения и 8 операций сложения, следовательно P=9+8=17 FP. Следовательно, X=K*M*N*(2P+Q), где M*N разрешение изображения, а K количество каналов изображения. Е сли k=3, а M*N=1920 * 1080, то X =3*1920 * 1080*(2*17+4). X=236 390 400 FP . Таким образом, получается в нашем случае 236 390 400 FP необходимо операций для  обработки одного изображения. Сравним производительность программно аппаратных комплексов (ПАК) на базе нейроморфных процессоров с ПАК на базе промышленных компьютеров на архитектуре x86 (табл.1). Таблица 1 Данные по нейроморфным процессорам в сравнении с промышленным компьютером на архитектуре x86 Параметр для сравнения Нейроморфные процессоры x86 Модуль NM Stick [ 6 ] NVIDIA Jetson TX2 [ 7 ] Intel ® Movidius ™ Myriad ™ X Vision Processing Unit (VPU) [ 8 ,1 0 ] NVIDIA Jetson Nano [ 9 ] NVIDIA Jetson TX2 NX [ 9 ] IntelCore2 Q8300 Программные библиотеки NMDL (NeuroM atrix® DeepLea rning) Пакет драйверов NVIDIA Linux для Tegra® SDK с библиотеками для глубокого обучения JetPack SDK JetPack SDK н/д Рекомендуемая стоимость, $ н/д н/д (нет данных) н/д 99 $ н/д н/д Автономность Подключ. к ПК (x86) Независимый компьютер с встроенным модулем для использования искусственного интеллекта Продолжение таблицы 1 Потр . м ощ ть модуля , Вт 2 10 20 н/д 5 10 7.5 15 95 П роиз водительность, GFLOPs н/д 126 0 1000 472 1330 40 Особенности интерфейса человеко машинного взаимодействия доп. о пер . прогр ния не требует работа с JetPack SDK Платформа FLIC [17] JetPack SDK JetPack SDK Объем необходимых вычислений, FLOPs 236 390 400 Время обработки одного изображения, с н/д 1,88*10 4 2,36*10 4 5,01*10 4 1,78*10 4 59,10*10 4 В реальных условиях на производстве сталкиваются с необходимостью обработки видеопотока.  На сегодняшний день частота кадров видеопотока в среднем составляет 30 кадров в секунду . В результате, объем данных видеопотока (в байтах), полученных с цифровой камеры в целях распознава ния изображения в одну секунду, составляет: 1920*1080*3 * 30 = 186 624 000 байт. Подсчитаем какое количество времени понадобится для обработки одного изображения и видеопотока нейроморфным процессорам и процессорам на базе x86. Полученные данные представле ны в таблице 2. Таб лица 2 К оличество времени , которое понадобится для обработки одного изображения и видеопотока Архитектура Нейроморфные процессоры x86 Процессор Модуль NM Stick NVIDIA Jetson TX2 Intel® Movidius ™ Myriad™ X Vision Processing Unit (VPU) NVIDIA Jetson Nano NVIDIA Jetson TX2 NX IntelCore2 Q8300 П роиз водительность GFLOPs н/д 126 0 1000 472 1330 40 Расчет для 1 кадр а Объем изображения, байт (1920*1080) 6 220 800 Объем необходимых вычислений, FLOPs 236 390 400 Время обработки одного изображения, с н/д 1,88*10 4 2,36*10 4 5,01*10 4 1,78*10 4 59,10*10 4 Продолжение таблицы 2 Расчет для видеопотока Объем изображения, байт (1920*1080) 186 624 000 Объем необходимых вычислений, FLOPs 7 091 712 000 Время обработки одного изображения, с н/д 5,63*10 3 7,09*10 3 1,50*10 2 5,33*10 3 17,72*10 3 Вывод Таким образом, была продемонстрирована практическая значимость быстроты работы нейроморфных процессоров над процессорами на базе архитектуры x86. Выполнен расчет вычислительной сложности алгоритма Собеля для задачи обработки изображения на примере контрольной операции распознавание символов. Использованный метод может быть использован при расчете вычислительной сложности других контрольных операций на дискретном производстве маши ностроительной продукции, таких как п оиск дефекта (несоответствия), например, у неокрашенной заготовки или окрашенного кузова и идентификация наличия элемента, например, проверка наличия наклейки со штрих кодом на компоненте автомобиля. Во всех этих задача х целесообразно использовать архитектуру на базе нейроморфных процессоров, так как программно аппаратные комплексы на этой архитектуре отличаются более высоким быстродействием (на 1 2 порядка) и более низким энергопотреблением (на 1 порядок) по сравнению с программно аппаратными комплексами на основе x86. 

: языковая модель, GPT , fine tune , embeddings , Python , Telegram Bot API , Google Colab , нейронная сеть, ВЭД, клиентская поддержка, пропри етарная модель, opensource , импортозамещение. Современные компании сталкиваются с растущей нагрузкой на свои отделы клиентской поддержки, но организации, не относящиеся к крупному бизнесу, редко могут позволить себе расширение штата. Создание чат бота – технологичное решение, которое повышает эффектив ность работы таких отделов без дополнительного найма сотрудников. Кроме того, качественный чат бот может стать дополнительным инструментом маркетинга, укрепляя имидж компании и повышая удовлетворенность клиентов. Адаптивные системы искусственного интеллект а являются одной из важных технологических тенденций, которые будут развиваться в 2023 году [1]. Таким образом, создание чат бота является актуальной темой для исследования. Цель исследования – разработка прототипа чат бота для клиентской поддержки, оценка его эффективности в решении задач бизнеса и потенциала развития проекта. Chat GPT – это модификация нейронной сети GPT [2], предназначенной для создания чат ботов. Она обучена на беспрецедентно большом объеме текстовых данных на различных языках с использ ованием весьма значительных вычислительных ресурсов и способна учитывать контекст предыдущих сообщений в ограниченном объеме. Для тонкой подстройки подобной сети используются различные техники, такие как fine tuning, transfer learning [3] и embeddings [4]. Таким образом, использование нейронных сетей как инструмента позволяет создавать, в частности, качественных чат ботов, способных использовать базу знаний предметной области, предоставляя более достоверную информацию по сравнению с необученной моделью. П рименение техники embeddings к модели GPT позволяет дообучать уже готовую модель на конкретной задаче с использованием относительно небольшого набора данных, что значительно экономит ресурсы и время компании. При этом модель сохраняет большую часть получен ных знаний, что позволяет достичь более высокой точности и эффективности на конкретной задаче, чем при обучении модели с нуля на большом наборе данных. Для бизнеса использование этой техники представляет особенный интерес, так как позволяет создавать персо нализированные модели, настроенные на специфические задачи и потребности компании. По сравнению с fine tuning технология embeddings больше подходит для использования с фактическими данными, базами знаний, лучше проходит фактологическую проверку и экономичн ее в реализации при использовании для создания ботов типа «вопрос ответ» (Q&A). [5] Для создания прототипа чат бота авторы исследования основывались на ресурсах, находящихся в открытом доступе, литературе, статьях, готовый кейсах. В процессе работы были за действованы следующие инструменты: локальный стенд под управлением Windows для запуска сервера чат бота, Google Colab для написания и запуска Python кода на мощностях Google, OpenAI для обучения и развертывания нейросетевой модели, а также GitHub как храни лище исходных кодов примеров, модулей и т.п. Это позволило значительно упростить процесс разработки. Однако для полноценного развертывания бота  в дальнейшем можно использовать собственные либо арендованные ресурсы компании, не прибегая к публичным сервисам . Для дообучения модели предполагается использование базы данных таможенного форума TKS.RU, существующего в открытом доступе с 2001 года и содержащего более 10 миллионов тематических сообщений, относящихся к сфере внешнеэкономической деятельности (ВЭД) [6] . Имеется первичная каталогизация (тематические разделы). В разделах присутствует как официальная документация, литература, технические сведения, так и сообщения от пользователей. Кроме того, имеется метрика «количество поблагодаривших», которая может испо льзоваться для оценки полезности ответов по мнению сообщества. В качестве источника дополнительной фактологической информации будут использованы собственные учебные материалы компании (учебный курс «Специалист по таможенным операциям») [7]. В связи с тем, что дообучение модели на мощностях OpenAI сказывается на стоимости, целесообразно проводить дообучение на небольшой выборке из базы данных, а затем расширять ее уже на мощностях «ТКС.РУ». Для интеграции дообученной модели в телеграм бота предполагается исп ользовать python фреймворк aiogram в локальной среде Windows. Таким образом, у обученной модели можно выделить две «killer feature» – во первых, модель будет обладать перечнем специальных знаний в отрасли, во вторых, сможет оперировать сведениями и фактами , актуальными на текущий 2023 год, тогда как базовая модель обучена на информации до 2021 года [8].  Для подтверждения состоятельности первоначальной гипотезы был проведен эксперимент: подготовлен корпус из ста статей, для которых были рассчитаны embeddin g векторы, использованные в дальнейшем для получения списка релевантных вопросу пользователя документов с дальнейшей их загрузкой в контекст запроса к языковой модели (поход Search Ask). Гипотеза заключалась в том, что обученная на базе данных таможенного форума и учебных материалов модель способна давать более точные ответы на специализированные вопросы. Для реализации интерфейса написан простейший чат бот на Python с использованием библиотеки aiogram. На втором этапе эксперимента было проведено сравнение ответов необученной и обученной моделей GPT. 

: искусственный интеллект, машинное обучение, нейронные сети, глубокое обучение, оценка плани ровок квартир, привлекательность планировок, недвижимость. Введение Последние пять лет спрос на жилую недвижимость стремительно увеличивается, количество предложений растёт, застройщики стараются выделиться на фоне конкурентов, предложить именно то, что хо тят клиенты. Планировка имеет большое значение при выборе квартиры, поэтому застройщикам и риелторам необходим инструмент, который позволил бы оценить привлекательность планировок квартир для различных возрастных групп потенциальных покупателей. Актуальнос ть данной темы подкрепляется интересом застройщиков жилой недвижимости, крупных риелторов, а также новизной темы в России. В рамках данной статьи рассматривается метод оценки привлекательности планировок квартир для различных возрастных групп. Описание мет ода Метод подразумевает глубокое обучение нейросети с учителем, поэтому необходимо собрать набор данных для обучения, который разбивается на тренировочные, тестовые и валидационные данные. 70% тренировочные, 15% тестовые и 15% валидационные. Трениров очные данные – это данные, на которых происходит обучение нейросети. Тестовые данные служат для проверки того, как нейросеть смогла обучиться и какие результаты она демонстрирует. Они позволяют оценить разницу между фактическим и ожидаемым результатом. Вал идационные данные нужны для оптимального подбора гиперпараметров нейронной сети, таких как число нейронов и скрытых слоёв, число итераций обучения и коэффициент скорости обучения. В состав набора данных входят изображения планировок квартир, их площадь и к оличество комнат, результаты опроса людей разных возрастов, интересующихся недвижимостью. В опросе обязательно указывается возраст, в нём предлагается оценить планировки квартир, в одном вопросе – одна планировка, на выбор два варианта ответа: «Нравится» и «Не нравится». За каждый ответ присваивается значение 1 или 0 соответственно. Для каждой планировки, основываясь на результатах опроса, составляется 5 параметров привлекательности в зависимости от возрастных групп. Возрастные группы: 1. От 18 до 24 лет 2. От 25 до 34 лет 3. От 35 до 44 лет 4. От 45 до 54 лет 5. Старше 55 лет Параметр привлекательности вычисляется как отношение числа оценок «Нравится» и числом всех оценок. Это можно обозначить как вероятность того, что в рамках опроса планировка имеет оценку «Нравится» (з начение 1). Таблица 1 Пример расчёта параметра привлекательности № Количество оценок планировки N , оставленных возрастной группой M Параметр привлекательности планировки N для возрастной группы M (округление в меньшую сторону) 1 «Нравится» «Не нравится» Всего оценок 2 117 19 136 0,86 Таблица 2 Пример значений параметров для некоторой планировки № Параметры Значения 1 Возрастная группа От 18 до 24 лет От 25 до 34 л ет От 3 5 до 4 4 л ет От 4 5 до 5 4 л ет Старше 55 лет 2 Привлекательность 0 ,8 6 0,75 0,68 0,33 0,21 Обработка и сбор данных Данные были собраны с применением открытых источников. Это информационные ресурсы в сети Интернет, на которых застройщики и риелторы публикуют объявления о квартирах, находящихся в продаже в городе Санкт Петербурге и Ленинградской области. Собраны изображения планировок квартир, их площади и количество комнат. Изображения были переведены в чёрно белый формат для упрощения работы и увеличения скорости обучения. Составляется матрица на основе изображения, в каждой ячейке записан цвет соответствующего пикселя изображения. Ячейка хранит значение от 0 до 255, где 0 – чёрный цвет, 255 – белый цвет. Рис. 1. Значения пикселей в чёрно белом изображении. Чёрно белые изображения планировок проходят операции свёртки для уменьшения количества параметров. Для этого используются свёрточ ные нейросети. Это позволяет ускорить процесс обучения за счёт того, что требуется гораздо меньше вычислительных мощностей для обучения нейросети. К исходной матрице применяется фильтр или ядро, например, размером 3 на 3 ячейки с шагом 1. Умножаются значен ия ячеек фильтра и значения той части матрицы, в котором фильтр находится сейчас. Далее происходит сдвиг фильтра на заданный шаг. Результат записывается в другую матрицу, которая является результатом работы свёрточной нейросети. Свёртка может применяться н есколько раз, существуют разные виды свёртки с разным фильтром, шагом и способом применения фильтра к исходной матрице. Рис.2. Иллюстрация процесса свёртки. Структура нейросети В результате свёртки получается набор параметров, на которых можно обучать нейросеть. Данные параметры являются входными значениями, как и данные о площади квартиры и количестве её комнат. Выходными значениями являются пять оценок о привлекательности планировки квартиры для разных возрастных групп. Рис.3. Структура нейросети. З аключение Описан метод оценки привлекательности планировок квартир с помощью глубокого обучения. Описан и собран набор данных, необходимых для обучения. Дополнительно к этому, создан пользовательский интерфейс, чтобы рассмотреть применение метода на практи ке. Пользователю достаточно загрузить изображение планировки квартиры, указать площадь и количество комнат. Программа вычисляет пять оценок для разных возрастных групп.  Рис.4. Интерфейс программы. 

: трансформеры, самовнимани е, метод независимых компонент Актуальность. В последнее время для целей глубокого обучения были широко востребованы и преобладали сверточные и рекуррентные сети. Но, к сожалению, они показывали ряд недостатков, т аких как медленное выполнение вычислений, сложность получения информации с предыдущих шагов дальнего порядка, взрыв и затухание градиента [ 1 ] . В настоящее время внимание исследователей сместилось на сети с вниманием и трансформеры, которые построены на принципиально новом подходе и являются перспективным направлением для развития распознавания и генерации образов. Основная особенность сетей с вниманием заключается в том, что на каждом временном шаге декодера используется отдельный контекстный вектор, так им образом, контекстный вектор смотрит (обращает внимание) на разные части последовательности. Следующим витком развития являются сети с авто вниманием, контекстный вектор которых смотрит на входную последовательность. Этот концепт послужил развитию сетей Трасформер. В энкодере и декодере трансф о рмеров присутствуют блоки self attention . Таким образом, контекст учитывается не только на этапе декодирования, но и на этапе кодирования. Трансформеры изначально были введены для задач обработки естественного языка (NLP), но быстро были приняты большинством областей глубокого обучения, включая распознавание образов и компьютерное зрение. Особенно интересны исследования требующие сохранения информации дальнего порядка, например, речи с использованием мимики [2] , расп ознавание походки [3] . Повышенный интерес к разработкам в этом направлении подтверждается большим количеством работ по данной теме за текущий год. Решаются проблемы сохранения контекста и «памяти» предыдущих шагов при обучении моделей, но, тем не менее ост ается актуальной проблема повышения качества распознавания, кластеризации изображений и видеообъектов. Цель. В данной работе рассматривается возможность улучшения качества распознавания и кластеризации за счет использования анализа независимых компонент в совокупности с ис пользованием методики self attention путем установки внимания на локальные окна. Предполагается, что такой подход позволит избежать обработки избыточной информации в процессе самонаблюдения и повысить производительность. Эксперимент. Для обучения моделей использовались надежные датасеты CIFAR 10 и CIFAR 100 . Обучение проводилось на языке Python c использованием библиотеки keras . Для сравнения были выбраны модели: сверточная и трансформер, с добавлением анализа независимых компонент с испол ьзованием алгоритма Fast ICA библиотеки scikit learn . Обучение проводилось на оригинальном датасете в течение 50 эпох, а также на датасете после аугментации также в течение 50 эпох. В процессе обучения контролировались метрики accuracy , logloss и величина обратная topic diversity , особенно интересная при сравнении на датасетов с различным количеством классов изображений. Выводы. Таким образом в работе показано, что использование алгоритма Fast ICA в сочетании с моделью Transformer повышает accur acy и уменьшает время тренировки модели по сравнению с использованием рекуррентных сетей. 

: сжатие изображений, алгоритм, фрактал, фрактальное сжатие, изображение. Введение В наше время изображения являю тся неотъемлемой частью представления информации. С каждым годом потребность в экономии памяти становится актуальнее. Ид ея методов сжатия изоб ражения способствует уменьшению затрачиваемой памяти. Это необходимо для повышения скорости передачи файлов по сет и и экономии пространства хранилища за счет уменьшения размера файлов. Существует множество методов сжатия изображений,  которые имеют как различные преимущества друг перед другом, так и недостатки. Так, на данный момент каждый метод используется для конкре тных целей. Самыми распространенными методами сжатия изображения являются: JPEG ; Deflate , применяемый в формате PNG ; Алгоритм Лемпеля Зива Уэлча , применяемый в формате GIF . Алгоритм фрактального сжатия изображений Фрактальное сжатие изображений это метод сжатия данных, который основан на принципе самоподобия. Он использует математическую теорию фракталов для описания изображения, позволяя сохранять детали и структуру изображения при сжатии. По сравнению с другими методами сжатия, такими как JPEG и PN G, фрактальное сжатие имеет несколько преимуществ. Оно позволяет достичь более высокой степени сжатия без потери качества изображения. Фрактальное сжатие также может использоваться для сжатия изображений с высокой степенью детализации, т аких как фотографии природы или архитектуры. Алгоритм фрактального сжатия изображений включает в себя следующие шаги: 1. Разбивка изображения на блоки. Каждый бл ок имеет размер N x N пикселей. 2. Выбор блока доминанты. Блок доминанта выбирается на основе наилучшего соответствия с другими блоками в изображении. Это делается с помощью функции сходства, которая определяет, насколько похожи два блока. 3. Подгонка блоков гостей. Оставшиеся блоки называются блоками гостями. Они подгоняются к блоку доминанте путем преобразования, масштабирования и поворота. Эти преобразования определяются с помощью аффинных преобразований, которые сохраняют форму блока. 4. Кодирование блоков. Каждый блок кодируется с помощью матрицы аффинных преобразований, а также с помощью индекса блока доминанты и параметров преобразования блока гостя. 5. Повторение процесса для каждого блока гостя. Этот процесс повторяется для каждогоблока гостя, пока не будут закодированы все блоки. 6. Агрегация блоков. Закодированные блоки объединяются в один файл для хранения или передачи. Результаты программной реализации Алгоритм фрактального сжатия изображений, реализованный в данной программе, позволяет сжимать изображения без значительной потери качества. Для этого используется поиск наилучшего соответствия блока изображе ния в других блоках. Когда разница между блоком и наилучшим соответствующим блоком меньше заданного порога, блок заменяется на наилучший соответствующий блок. В противном случае блок рекурсивно сжимается до тех пор, пока разница между блоком и наилучшим со ответствующим блоком не будет меньше порога. Это позволяет достичь высокой степени сжатия без значительной потери визуального качества изображения. Однако, этот алгоритм может быть довольно медленным и требовательным к ресурсам, особенно при использовании больших блоков. Таблица 4 Изображение Размер исходного изображения Размер изображения после сжатия Время сжатия 12. jpg 1339 Кб 452 Кб 57 секунд 21. jpg 335 Кб 169 Кб 58 секунд Полученные результаты описаны в Таблице 1 и показаны на рис. 1 и 2. Результаты программы зависят от выбранных параметров blocksize (размер блока) и threshold (порог) . Чем меньше blocksize, тем выше детализация изображения, но меньше коэффициент сжатия. Чем меньше threshold, тем больше блоков будут сжаты без изменения, что увеличит коэффициент сжатия, но может привести к потере качества изображения. Рис . 1 . Изображение до и после сжатия Рис . 2 . Изображение до и после сжатия При работе программы с изображением размером 1616x2180 пикселей, с параметрами blocksize=64 и threshold=100, был получен коэффициент сжатия в 2,97 раз от исходного размера. Качество сжатого изображения осталось достаточно высоким, потери практически незаметны для вос приятия человеческим глазом. В целом, фрактальное сжатие является эффективным методом для сжатия изображений, особенно когда они содержат повторяющиеся узоры и текстуры. 

: алгоритмы извлечения особых RGB точек(признаков), визуальная одометрия, бенчмарк. Введение С быстрым развитием области мобил ьной робототехники, возрастает необходимость в точной локализации роботов. Одним из методов отслеживания перемещением с использованием RGB изображений является визуальная одометрия, которая использует поток изображений с камеры робота. Выявление и описание признаков в изображении является одним из первых и важнейших этапов визуальной одометрии [2]. Необходимо провести исследования влияния алгоритмов выявления признаков в изображении на точность локализации мобильного робота. Объектом исследования являются алгоритмы извлечения признаков. Предметом исследования являются влияния алгоритмов извлечения признаков на точность локализации мобильного робота. Целью данной работы является реализовать бенчмарк для исследования алгоритмов извлечения особых RGB точек(при знаков) изображений на точность локализации мобильного робота. Для достижения цели были поставлены следующие задачи: 1. Изучить существующие алгоритмы выявления признаков. 2. Определить метод сравнения алгоритмов выявления признаков. 3. Описать способ реал изации бенчмарка алгоритмов выявления признаков. 4. Провести исследование алгоритмов извл ечения особых точек бенчмарком. Обзор предметной области Для создания бенчмарка необходимо провести обзор существующих алгоритмов извлечения признаков. Для поиска алгоритмов выявления признаков использовался следующий запрос: feature detection and description algorithms. SIFT. Один из популярнейших алгоритмов извлечения и описания признаков в изображении, предложенный в 2004 году [3]. Инвариантен к аффинным преобраз ованиям и к изменениям освещённости. Считается вычислительно трудоёмким алгоритмом, но один из самых точных. SURF. Модифицированный алгоритм SIFT. Целью модификация является ускорение вычислений за счёт параллелизации вычислительных процессов. Немного усту пает SIFT в устойчивости перед изменением освещения [1 0 ]. KAZE. Метод выявления и описания признаков, работающий в нелинейном масштабном пространстве [1 1 ]. Алгоритм KAZE уменьшает влияния шума и имеет более высокую точность (чем SIFT и SURF) за счёт неболь шого увеличения вычислений. BRISK. Был предложен в 2011 году как альтернатива SURF с более низкими вычислительными затратами [1 2 ]. Описание (дескриптор) состоит из бинарной битовой строки, соответствующей расстоянию Хэмминга, что позволяет ускорить вычисле ния. ORB. Алгоритм основан на модификациях алгоритма выявления особых точек FAST и алгоритма описания признаков BRIEF и предложен в 2011 году [1 3 ]. Вычисляются особые точки с помощью алгоритма FAST, затем точки фильтруются алгоритмом обнаружения углов Харр иса [4]. Далее вычисляется ориентация ключевой точки. После используется модифицированный алгоритм BRIEF точки, предназначенные для сравнения, поворачиваются на угол ориентации ключевой точки (таким образом лишая недостатка BRIEF в неустойчивости к враще ниям). Описание метода решения Для исследования влияния алгоритмов выявления признаков на точность локализации мобильного робота, необходимо воспользоваться методом визуальной одометрии и рассчитать местоположение робота. Метод визуальной одометрии, который реализован в бенчмарке, основывается на статьях [1] и [2]. Ниже приведены подробности данного метода: 1. Выявление и описание признаков. На данном этапе работает один из алгоритмов, описанных в разделе “Обзор предметной области”. 2. Сопоставление признаков. После обнаружения признаков на первом изображении, необходимо найти эти признаки на следующем изображении, таким образом отслеживая перемещение признаков между изображениями. 3. Расчёт движения. На основе информации о том, как менялись признаки на изображении, можно рассчитать движение самого мобильного робота. Для расчёта движения используется существенная матрица, описывающая геометрическую связь между двумя изображениями [5]. На основании данной информации можно высчитать координаты перемещени я. 4. Удаление выбросов. Обычно в изображениях содержится множество выбросов, которые не учитываются алгоритмами выявления и описания признаков. С удалением выбросов хорошо справляется алгоритм RANSAC [6]. В качестве результата выполнения, приведенного вы ше метода, будут доступны график с вычисленной траекторией и настоящей, и график, показывающий накопления ошибки с течением времени. По данным графиков можно будет оценить степень влияния алгоритмов выявления признаков на точность локализации мобильного ро бота. Также отдельно будет выводиться время выполнения алгоритмов для оценки их эффективности. В качестве основного инструмента реализации бенчмарка была выбрана библиотека OpenCV [7]. В неё включены все приведенные в обзоре алгоритмы выявления и описания признаков, а также в ней есть множество функций по обработке изображений, которые будут необходимы для вычисления местоположения мобильного робота. Бенчмарк представляет из себя консольное приложение. Пользователь может использовать приложение в режиме “во прос ответ” или передать ключами аргументы для быстрого запуска. Пользователю доступен выбор из алгоритмов извлечения и описания признаков, выбор папок для ввода данных и вывода результатов и различные параметры для  настройки работы бенчмарка. Бенчмарк мож ет установить границу оценки Лоу [3], инвертировать матрицу трансформации, добавить в изображения эффект размытия или шум. Исследования алгоритмов извлечения особых точек с помощью бенчмарка В качестве датасета был выбран The KITTI Vision Benchmark Suite [9] , состоящий из коллекци и изображений снятых с камеры на автомобили, есть сегменты в городе и по скоростной дороге. Был проведён ряд тестов на различных сегментах датасета. Эксперименты проводились на относительно небольших участках сегментов (100 изоб ражений). В данных экспериментах накопление ошибки должно быть сведено к минимуму. Для всех экспериментов оценка “хороших совпадений” по Лоу (Lowe’s ratio test) [3] составляла 0.85. Усредненные результаты экспериментов находятся в таблице 1. Пример получен ных с помощью бенчмарка графиков можно увидеть на рисунке 1 и 2. Таблица 1 Усреднённые результаты работы бенчмарка для небольших участк ов . Алгоритмы Средний процент ошибок, % Средняя скорость работы, с. Среднее количество совпадений SIFT 0.154 26,51 998 SURF 0.202 16.85 974 BRISK 0.276 21.4 1535 ORB 0.446 10.34 1890 KAZE 0.14 72.53 1217 Рис. 1. Пример графика вычисленных              Рис. 2. Пример графика ошибок  местоположений.          при вычислении местоположения. Одни из самых точных алгоритмов оказались SIFT и KAZE с разницей всего в 0.01% в сторону KAZE, при этом скорость KAZE почти в 2.7 раз ниже, чем у SIFT. SURF справляется быстрее чем SIFT, но у него упала точность на 0.05% по сравнению с SIFT , хотя эта  разница и не будет сильно влиять на результаты. ORB быстрее остальных справился с извлечением и описанием особых точек, но также он имеет и самую низкую точность. По среднему количеству совпадений можно сделать вывод о том, что в данных сегмент ах нужно около 1000 точек для получения местоположения, значительно увеличения количества точек не даёт новой информации. Заключение В данной работе был предложен метод для сравнения влияния алгоритмов извлечения особых RGB точек на точность локализации мобильного робота. На основе данного метода был спроектирован бенчмарк, позволяющий сравнить алгоритмы извлечения особых точек на разны х наборах данных. Проведено исследование результатов работы бенчмарка для небольших сегментов данных. Установлено, что SIFT один из наиболее точных алгоритмов, при этом не являюсь самым вычислительно трудоёмким. В дальнейшем следует расширять возможности бенчмарка: добавить больше алгоритмов выявления признаков. Также в дальнейших работах можно расширить существующее решение, чтобы исследовать влияние алгоритмов извлечения признаков на SLAM [8]. 

: алгоритмы, графы, онлайн курс, автоматизация проверки знаний, ст руктуры данных Введение Сейчас преподаватели затрачивают большое количество времени, чтобы проверить задачи на защиту лабораторных работ студентов по курсу “Построение и анализ алгоритмов”, т.к. проверка осуществляется ручными средствами. Создание онлайн курса поможет экономить время преподавателей, т.к. Для защиты лабораторной работы студентам будет достаточно прорешать задачи данного курса за ограниченное время, после чего их лабораторная работа будет считаться защищенной, либо же наоборот незащищенной в зависимости от числа успешно решенных задач . Целью данной работы является проведение анализа существующих задач по реализации различных алгоритмов с целью составления требований к задачам на разрабатываемом онлайн курсе, а также реализация двух разделов о нлайн курса . Объектом исследования является автоматизаци я проверки знаний по курсу “Построение и анализ алгоритмов” . Предметом исследования является эффективность автоматизации проверки знаний по курсу “Построение и анализ алгоритмов” . Для формирования ус ловий задач и реализации двух разделов онлайн курса необходимо: 1) Провести сравнительный анализ задач из существующих онлайн курсов по теме “Построение и анализ алгоритмов” . 2) Выяв ить требовани я к задачам курса по автоматической проверке защит лабораторных р абот по теме “Построение и анализ алгоритмов” на базе проведенного исследования аналогов. 3) Реализовать два раздела онлайн курса с задачами, которые удовлетворяют ранее выявленным требованиям. I . Обзор предметной области 1) Принцип отбора аналогов Для форми рования требований к задачам для онлайн курса по теме “Построение и анализ алгоритмов” необходимо рассмотреть существующие онлайн курсы, которые полностью или частично посвящены данной теме 2) Краткое описание аналогов Онлайн курс "Основы теории графов" на платформе Stepik Курс "Основы теории графов” [2] разработан участниками Лаборатории Алгоритмической математики студентами СПБГЭТУ "ЛЭТИ". В курсе представлены теория в текстовом формате и система оценивания новых знаний и навыков, которая включает тестовы е вопросы и задания. Не для всех тем этого курса разработаны задания, есть модули, которые включают в себя лишь теорию и теоретические вопросы. Входные данные для этих задач не являются разнообразными, формулировки задач всегда одинаковые. Задачи в данном курсе не разделены по уровням сложности. Онлайн курс "Алгоритмы: теория и практика. Методы" на платформе Stepik Курс "Алгоритмы: теория и практика. Методы” [3] составил Computer Science Center. В курсе представлены видеолекции, теория в текстовом формате и система оценивания новых знаний и навыков, которая включает тестовые вопросы и задания. Для каждой темы рассмотренной в даном курсе существуют практические задания на написание кода. Входные данные для этих задач являются разнообразными, а формулировки за дач всегда одинаковые. Задачи в данном курсе не разделены по уровням сложности. Онлайн курс "Основы Теории Графов для спортивного программирования" на платформе Stepik Курс "Основы Теории Графов для спортивного программирования" [4] представлен от "МФТИ Ц ентр развития ИТ образования". В курсе представлены теория в текстовом формате и система оценивания новых знаний и навыков, которая включает тестовые вопросы и задания. Входные данные также генерируются для нескольких различных тестовых сценариев. Разделен ие задач на уровни сложности в данном курсе отсутствует. Онлайн курс "Введение в алгоритмы . Практикум." на платформе Stepik Курс "Введение в алгоритмы . Практикум .” [5] создан преподавателями ВШЭ . Курс содержит только задачи и не предоставляет теорию для р ешения представленных задач . Входные данные являются разнообразными и покрывают несколько тестовых сценариев . Разделение задач на уровни сложности отсутствует . Онлайн курс "Комбинаторные алгоритмы" на платформе Stepik Курс "Комбинаторные алгоритмы” [6] разработан преподавателями УрФУ. Курс содержит только задачи и не предоставляет теорию для решения представленных задач. Представлено большое количество задач на каждую отдельную тему. Входные данные являются разнообразными и покрывают несколько тестовых с ценариев. Разделение задач на уровни сложности отсутствует. 3) Критерии аналогов Разнообразие входных данных Данный критерий подразумевает наличие как минимум пяти тестовых сценариев проверки решения задачи для различных входных данных. Наличие уровней сложности в задачах  Данный критерий подразумевает наличие задач на конкретную тему с различным уровнем сложности, например: легкий, средний, тяжелый. Наличие тестовых заданий Данный критерий подразумевает наличие задач с возможностью выбора ответа. Критерий необходим т.к. задачи на защиту лабораторных работ должны содержать как задачи на написание кода, так и на знание теоретических вопросов. 4) Сравнение аналогов Таблица 1 Таблица сравнения по критериям Аналог Разнообразие входных данных Наличие уровней сложности в задачах Наличие тестовых заданий Онлайн курс "Основы теории графов" на платформе Stepik + Онлайн курс "Алгоритмы: теория и практика. Методы" на платформе Stepik + + Онлайн курс "Основы Теории Графов для спортивного программирования" на платформе Stepik + + Онлайн курс "Введение в алгоритмы. Практикум." на платформе Stepik + Онлайн курс "Комбинаторные алгоритмы" на платформе Stepik + 5) Выводы по итогам сравнения Н и один из аналогов не удовлетворяет всем представленным критериям сразу, из чего можно сделать вывод, что при разработке требований к задачам разрабатываемого онлайн курса нужно сделать упор на удовлетворение следующих критериев "Разделение зада ч по уровню сложности" и “Наличие тестовых заданий ", т.к. эти критерии являются самыми наименее выполнимыми в рассмотренных аналогах. II . Выбор метода решения На основании обзора аналогов было установлено, что задачи для онлайн курса по теме “Построение и анализ данных " должны удовлетворять следующим требованиям: 1) Задач обязательно должны генерироваться с определенным уровнем сложности, т.к. ни один из рассмотренных аналогов не удовлетворял данному критерию. Решая задачи с высоким уровнем сложности студент ы смогут претендовать на дополнительные баллы. 2) Для того, чтобы удовлетворить требование о наличии тестовых заданий, можно воспользоваться созданием вопросов типа “Множественный выбор” на платформе Moodle , данный тип вопроса п озволяет выбирать один или нес колько правильных ответов из заданного списка. 3) Для реализации разнообразия входных данных можно ориентироваться на решения используемые во всех представленных аналогах, но необходимо учитывать, что тестовые сценарии должны покрывать все краевые случаи зад ачи. При выполнении всех требований разрабатываемый курс сможет стать решением проблемы ручной проверки защит лабораторных работ студентов на платформе Moodle кафедры МОЭВМ по теме "Построение и анализ алгоритмов". Описание метода решения По результатам о бзора предметной области и сравнения аналогов были сформированы критерии, которым должны соответствовать курс по теме “ Построение и анализ алгоритмов ”. Для создания задач на написание кода можно использовать тип вопросов С odeRunner на платформе Moodle , ко торый позволяет студентам писать код на языке Python [7] и в дальнейшем запускать их код для решения задачи на сгенерированных тестовых сценариях. Использование элемента случайности в генерации тестовых данных позволит получить достаточно разнообразное чис ло различных тестов. Заключение В ходе работы были выполнены все поставленные задачи: проведен сравнительный анализ аналогов, на основе которого были составлены требования к задачам онлайн курса по теме “Построение и анализ алгоритмов”. Опираясь на полученные требования удалось выбрать к онкретный метод решения поставленной задачи, а также следуя данному методу получилось разработать 2 раздела данного курса на темы: “Поиск с возвратом.” и “Жадные алгоритмы. Поиск кратчайшего пути.”. Каждый из разделов включает в себя вопрос на теорию и две задачи на написания кода, расположенные по нарастающему уровню сложности. 

: карты Duckietown, редактор, плитки, беспилотные транспортные средства Введение В настоящее время значительное развитие получила отрасль, связанная с созданием автономных транспортных средств[10], важной частью которых является иску сственный интеллект, отвечающий за принятие решения о том, куда необходимо двигаться в процессе движения. Однако создание таких средств требует огромных затрат ресурсов и большой квалификации работников. Чтобы сделать отрасль доступнее, был создан проект D uckietown[8], который позволяет проводить исследования в области ИИ, робототехники, автономного вождения, а также служит в образовательных целях. Для обучения автопилота требуется создавать различные конфигурации местности как для симулятора, так и для реа льного полигона Duckietown. Карты представляют собой модели дорог для разработки и запуска на них решений по автономному вождению. Конфигурация карты представляет собой набор слоёв, в которых хранятся объекты карты. Карта сохраняется в формате описанном в библиотеке dt maps[9]. Создание карты необходимого формата вручную занимает большое количество времени, поэтому существует необходимость в инструменте, который бы позволил удобно и с высокой скоростью создавать необходимые конфигурации карт. Целью данной с татьи является разработка инструмента для быстрого создания карт Duckietown. Объектом исследования является создание карты для Duckietown. Предметом исследования является скорость создания карты заданной конфигурации. Для того чтобы достичь поставленной це ли, были поставлены следующие задачи: 1. Произвести анализ существующих инструментов по созданию карт из плиток. 2. Спроектировать архитектуру инструмента. 3. Реализовать необходимую функциональность. Обзор существующих решений В качестве рассматриваемых аналогов были отобраны инструменты с графическим интерфейсом, позволяющие создавать 2d карты из предварительно загруженного набора изображений. Для того чтобы найти аналоги, использовалась поисковая система Google. Ключевые запр осы : tiles editor, 2d tiles editor, tile map maker.  Редактор Tiled. Tiled[1] — редактор, который предназначен для разработки контента для 2d игры, представлен в виде настольного приложения. Основной особенностью является создание и редактирование карт ра зных форм, состоящих из плиток. Поддерживает добавление слоёв объектов, пользовательского задания параметров объектов. Основная особенность редактора общая гибкость и удобство использования.  Редактор Tilesetter. Tilesetter[2] позволяет гибко и с высокой скоростью создавать пользовательские наборы плиток, что является его основной функциональностью. Редактор представлен в виде настольного приложения. Также в Tilesetter встроен редактор, позволяющий проверить, как плитки будут выглядеть в реальности.  Редакт ор OGMO editor. OGMO Editor[3] редактор, функциональность которого нацелена на создание 2d уровней. Позволяет создавать наборы из плиток, размещать объекты, использовать пользовательские метаданные. Позволяет сохранять файлы проекта и уровней в формате J SON.  Редактор Pickle. Pickle[4] платный аналог, заточен под создание пользовательских плиток и создание анимации, представлен в виде настольного приложения.  Редактор Mappy. Mappy[5] позволяет создавать гибкие карты для 2d и 3d игр на основе плиток, пре дставлен в виде настольного приложения.  Редактор tIDE: Tilemap Integrated Development Environment. Функциональность редактора tIDE[6] позволяет создавать содержимое для игр на основе плиток, задать порядок слоёв и их видимость. Редактор поддерживает разные форматы файлов для загрузки и сохранения карт, представлен в виде настольного приложения. Изучив функциональность существующих инструментов, была сформирована таблица 1, представляющая сравнительный анализ инструментов по следующим критериям:  Критерий №1. Возможность загрузить произвольные изображения для объектов карты. Редактор должен иметь возможность отображения объектов, используемых в карте Duckietown. На изображениях будут находиться объекты карты. С помощью изображений объектов карты пользователи р едактора будут понимать, какой именно объект они добавили или отредактировали.  Критерий №2. Возможность создавать слои объектов на карте. Помимо плиток дороги необходимо отобразить объекты карты уточек, duckie ботов, дорожные знаки и др.  Критерий №3. Во зможность задать пользовательскую конфигурацию слоя. Все слои карты имеют различную конфигурацию, соответственно необходимо иметь возможность настраивать её. Настройка должна осуществляться путём добавления необходимых свойств и их значений каждому объекту карты.  Критерий №4. Возможность автоматически добавлять конфигурации слоёв объектов при считывании карты. Необходима возможность отображать пользовательские слои, автоматически считывая конфигурацию объектов из файлов.  Критерий №5. Возможность прописать з ависимость между объектами карты. Важность данной функциональности определяется тем, что в dt maps расположение объекта на карте можно задать относительно другого объекта.  Критерий №6. Возможность отображать зависимость между объектами карты. В ходе редакт ирования объекта, относительно которого задан другой объект необходимо отображать изменение положения зависимого объекта и сохранять его. Таблица 1 Сравнение аналогов по критериям Редакторы Критерии Tiled Tilesetter OGMO Editor Pickle Mappy tIDE Критерий №1 + + + + + + Критерий №2 + + + + + Критерий №3 + + + Критерий №4 Критерий №5 + + Критерий №6 Выводы по итогам сравнения Из таблицы 1 видно, что рассмотренные аналоги не позволяют полностью удовлетворить все потребности, требуемые от редактора, необходимого для создания карты Duckietown. По итогам сравнения наиболее подходящая под цель функциональность была выявлена у редакт оров Tiled и OGMO Editor. Выбор метода решения Основной проблемой при ручном создании конфигурации карты является невозможность визуализировать полученный результат и необходимость производить множество операций копирования и вставки данных. Поэтому для у добства использования разрабатываемый инструмент должен быть представлен в виде приложения с графическим интерфейсом. Пользователь должен иметь возможность создать и отредактировать карту, после чего сохранить её в файловую систему в виде набора yaml файло в. Разработка Для обеспечения успешного встраивания инструмента в существующую экосистему Duckietown`a языком реализации внутренней логики инструмента выбран Python с использованием фреймворка PyQt[7] для реализации графического интерфейса. Упрощённая схем а архитектуры инструмента представлена на рис. 1. Архитектура инструмента построена в соответствие с паттерном Model View Controller. Интерфейс инструмента позволяет пользователю ознакомиться с состоянием редактируемой карты и изменять его. Серверная часть обрабатывает произведённые пользователем действия и обновляет данные карты, а также внутреннее состояние инструмента. С помощью буфера состояний инструмент позволяет запоминать историю изменения карты и перемещаться по ней. Для хранения зависимостей объек тов друг относительно друга в инструмент встроен граф фреймов. Рис. 1. Архитектура инструмента Исходный код инструмента доступен для ознакомления на сервисе GitHub ( https://github.com/OSLL/dt gui tools/tree/ ente ) Выводы В ходе выполнения работы достигнута поставленная цель разработан инструмент для создания карт в Duckietown. Для этого на основании сформ улированных критериев произведён обзор существующих решений. Для существующих решений сформулированы следующие критерии, которыми они должны удовлетворять: иметь возможность загрузить произвольные изображения для объектов карты, иметь возможность создавать слои объектов на карте, иметь возможность задать пользовательскую конфигурацию слоя, иметь возможность автоматически добавлять конфигурации слоёв объектов при считывании карты, иметь возможность прописать зависимость между объектами карты, иметь возможнос ть отображать зависимость между объектами карты. По результатам обзора установлено, что ни один из существующих инструментов в полной мере подходит для создания карт Duckietown. Поэтому для достижения поставленной цели спроектирована архитектура инструмент а, реализована необходимая функциональность. В дальнейшем необходимо предусмотреть возможность быстрого внедрения новой функциональности, для этого необходимо провести исследование взаимодействия компонентов реализованной архитектуры и реализовать подсисте му плагинов, чтобы уменьшить зависимость компонентов друг от друга. 

: астма, активный мониторинг, пассивный мониторинг, анкетирование Введение. Астма является х роническим заболеванием, от которого страдают 339 миллионов человек во всем мире [1]. Симптомы и течение болезни могут отличаться в зависимости от дня, сезона и человека. У многих симптомы астмы контролируются большую часть времени, у остальных течение бол езни поддается слабому контролю, однако все подвержены приступам, которые в лучшем случае могут предоставить неудобства, в худшем – госпитализацию или даже смерть [2]. В настоящее время не существует лекарства от астмы, поэтому основное внимание уделяется улучшению контроля симптомов и снижению риска приступов. Астма является общим термином для целого ряда фенотипов, поэтому очень важен персональный подбор стратегии лечения. Основную проблему представляет невозможность постоянного контроля состояния пациент ов, больными бронхиальной астмой. Мониторинг течения болезни является особенно важным элементом контроля пациента, позволяющим правильно оценить свое здоровье и вовремя принять соответствующие меры. Постоянный мониторинг подразумевает формирование множеств а потоков данных, которые создаются быстрее, чем может обработать один человек, поэтому к задачам мониторинга относятся методы машинного обучения, которые позволяют получить полезную информацию и персонализированную обратную связь. Задачи контроля решаются методами машинного обучения и включают в себя мониторинг [3], персонализированное лечение [4], обучение [5], обработку моделей поведения населения для улучшения целенаправленного лечения [6], а также прогнозирование приступов астмы с использованием множес тва источников данных [7]. Мониторинг дыхания, а следовательно обнаружение каких либо отклонений от нормы потенциально может помочь выявить приступы астмы на ранней стадии. Инструменты, предложенные для личного домашнего мониторинга, включают в себя устро йство контроля сна для мониторинга за дыханием и детектор движения грудной клетки. Применение  алгоритмов глубокого обучения и алгоритма XGBoost позволило точно определить различные модели дыхания [8, 9]. Хрипы и кашель являются важными мерами при контроле астмы и включаются в утвержденный опросники по астме. Помимо опросников также существуют исследования в области портативных систем мониторинга на основе машинного обучения для активного [10] и пассивного [11] мониторинга течения астмы. Запись и анализ про извольного кашля и дыхательных шумов у людей с различными респираторными заболеваниями могут помочь в диагностике. Используя записи кашля одно из исследований предсказало астму и хроническую обструктивную болезнь легких (ХОБЛ) с точностью 93.3% [12]. Также существуют новые разработки в области цифровой обработки сигналов, которые точно обнаруживают наличие кашля и хрипа в звукозаписи. Измерение приверженности лечению широко изучается при исследованиях астмы. Машинное обучение нашло свое применение и изучени и правильности использования ингаляторов. было обнаружено, что регрессионная модель, обученная на сигналах полученных с устройства INhaler Compliance Assessment (INCA), точно оценивает профиль потока вдоха с точностью 91% [13]. Данная технология позволяет сделать прием лекарств более эффективным. Важным аспектом мониторинга бронхиальной астмы является прогнозирование приступов и обнаружение изменения симптомов. Для решения данных проблем использовались данные, включающие в себя летучие органические соединен ия [14] качество сна[15], пиковую скорость выдоха[16], приверженность к препаратам[17] и различные триггеры окружающей среды[18]. Летучие органические соединения (ЛОС), присутствующие во выдыхаемом пациентами воздухе, могут быть использованы для предсказан ия приступов астмы. Газовая хромато масс спектрометрия (ГХМС) является золотым стандартом анализа ЛОС, но электронный нос (e Nose) является портативной альтернативой. e Nose позволяет обнаруживать и распознавать отдельные химические соединения в смесях хим ических паров. Методы штрафующей логистической регрессии и случайного леса использовались для определения наиболее важных ЛОС и позволили осуществить прогноз приступов БА. Классификация использовалась для определения ЛОС, которые могут привести к приступу или к потере контроля. В исследованиях [14, 19] сообщалось о хорошей эффективности с чувствительностью и специфичностью от 70% до 90%. Падающая пиковая скорость выдоха (PEF) и разброс вариабельности являются основным показателем приступов астмы. Пикфлоумет ры иногда используются пациентами дома для проведения объективных измерений и информировании о необходимости принятия мер. Для измерения объема легких также используются спирометры, которые проводят более подробные измерения, чем измерители PEF[20]. Падени е PEF и/или изменение оценки симптомов часто используются при планировании действий по лечению астмы для улучшения личного контроля в ответ на ухудшение состояния[21]. Интеллектуальные пикфлоуметры позволяют пациентам измерять и отслеживать свой PEF и зача стую связаны с мобильным приложением. Для дополнительной классификации все решения разделены по решаемой задаче и их способам проведения замеров и сведены в таблицу 1. Таблица 1 Сравнительный анализ современных решений по мониторингу БА Метод Аппаратно программный способ Решаемая задача Мониторинг дыхания[ 8 , 9 ] Пульсоксиметр, портативный анализатор сна Регрессия, пассивный мониторинг дыхания Обнаружение кашля и храпа[ 10 ,1 1 ,1 2 ] Устройство звукозаписи Регрессия, пассивный мониторинг кашля Продолжение таблицы 1 Контроль использования ингаляторов[1 3 ] Записывающий ингалятор Регрессия, измерение правильности применения ингалятора Анализ дыхания[1 4 , 19 ] e Nose, NIOX анализатор Регрессия, активный мониторинг дыхания, предсказание приступов и конт роля. Мониторинг функций легких[ 21 ] Спирометр и пикфлоуметр Классификация, предсказание приступов Мониторинг подверженности лекарствам[ 17 ] Анкетирование Классификация, предсказание приступов Техника использования ингалятора[ 22 ] Умный ингалятор Кластеризация пациентов по приверженности к ингаляторам Разработка мобильного приложения для контроля течения БА с использованием опросных листов согласно клиническим рекомендациям министерства здравоохранения РФ [23]. Ежедневное анкетирование и регистрация триггеров приступов астмы является сложной задачей и влечет за собой отсутствующие данные. Чтоб решить эту проблему используется анкетирование. ACT (Asthma Control Test) [24]. Данный тест необходим для определения остроты приступов астмы в повс едневной жизни пациентов за последние четыре недели. Анкета отображена на таблице 2. Таблица 6 Анкета ACT Вопрос 1. Как часто за последние 4 недели астма мешала Вам выполнять обычный объем работы в учебном заведении, на работе или дома? все время очень часто иногда редко никогда 1 2 3 4 5 2. Как часто за последние 4 недели Вы отмечали у себя затрудненное дыхание? чаще, чем раз в день 1 раз в день от 3 до 6 раз в неделю 1 или два раза в неделю ни разу 1 2 3 4 5 3. Как часто за последние 4 недели Вы просыпались ночью или раньше, чем обычно, из за симптомов астмы (свистящего дыхания, кашля, затрудненного дыхания, чувства стеснения или боли в груди)? 4 ночи в неделю или чаще 2 – 3 ночи в неделю 1 раз в неделю 1 или 2 раза ни разу 1 2 3 4 5 4. Как часто за последние 4 недели Вы использовали быстродействующий ингалятор (например, Вентолин, Беродуал, Атровент, Сальбутамол) или небулайзер (аэрозольный аппарат) с лекарством (например, Беротек, Беродуал, Вентолин небулы)? 3 раза в день или чаще 1 ил и 2 раза в день 2 или 3 раза в неделю 1 раз в неделю или реже ни разу Вопрос 1 2 3 4 5 5. Как бы Вы оценили, насколько Вам удавалось контролировать астму за последние 4 недели ? совсем не удавалось контролировать плохо удавалось контролировать в некоторой степени удавалось контролировать хорошо удавалось контролировать Полностью удавалось контролировать Значения ответов на вопросы суммируются (общее значение шкалы от 5 до 25 баллов). Значение 25 означает полный контроль, 20 – 24 баллов – астма хорошо контролируется, 19 баллов – неконтролируемая астма. ACQ 5 (Asthma Control Questionnaire) [25]. Представляет собой более чувствительный тест, который рассматривает симптоматику бронхиальной астмы за неделю. Анкета отображена на таблице 3. Таблица 3 Анкета ACQ 5 Вопросы Баллы 0 1 2 3 4 5 6 1. В среднем за последнюю неделю как часто вы просыпались ночью из за приступа БА? Никогда Почти никогда Очень редко Несколько раз Много раз Очень много раз Не могу спать из за БА 2. В среднем за последнюю неделю насколько выраженными были симптомы БА при пробуждении утром? Отсутствие симптомов Очень легкие симптомы Легкие симптомы Умеренные симптомы Достаточно тяжелые симптомы Тяжелые симптомы Очень тяжелые симптомы 3. В общем за последнюю неделю насколько вы были ограничены в повседневной деятельности из за БА? Совсем не ограничен Ограничен совсем незначительно Слегка ограничен Ограничен умеренно Очень ограничен Чрезвычайно ограничен Полностью ограничен 4. В общем за последнюю неделю опишите степень одышки, связанной с БА? Отсутствует Очень небольшая Небольшая Умеренная Достаточно выраженная Значительная Очень выраженная 5. В общем за последнюю неделю сколько времени вы испытывали затруднение дыхания? Нисколько Практически не испытывал Небольшой период времени Умеренное количество времени Большое количество времени Большую часть времени Все время. Шкала оценивания от 0 до 6. Где значение ACQ 5 < 0.75 достоверно свидетельствует о хорошем контроле бронхиальной астмы, а ACQ 5 > 1.5 говорит о неконтролируемом течении заболевания. Опросник GINA (Global Initiative for Asthma) [ 26 ] . Представлена в виде наименьшей анкеты, позволяющей оценить уровень контроля над симптомами за последние четыре недели. Анкета представлена в таблице 4. Таблица 4 Опросник GINA Уровень контроля За последние 4 недели у пациента отмечались: Хорошо контролируемая Частично контролируемая Неконтролируемая Дневные симптомы чаще, чем 2 раза в неделю Да Нет Уровень контроля За последние 4 недели у пациента отмечались: Хорошо контролируемая Частично контролируемая Неконтролируемая Ночные пробуждения из за БА Да Нет Ничего из перечисленного 1 – 2 из перечисленного 3 – 4 из перечисленного Потребность в препарате для купирования симптомов чаще,чем 2 раза в неделю Да Нет Любое ограничени еактивности из за БА Да Нет Для проведения опросов, сделано android приложение на базе Jetpack Compose . Основной экран приложения представляет из себя список возможных анкет. Каждая анкета представлена в виде экрана с вопросом и вариантами ответа. По окончании анкетирования, ответы сохраняются, а вывод по результатам анкетирования выводится на экран. Пример вопроса и экрана вывода показан на рисунке 1. Рисунок 2 . Пример анкетирования в приложении. В перспективе прогнозирование состояния по анкетным данным могут оказаться полезными для прогнозирования риска приступов астмы у чувствительных к окружающей среде пациентов. Также следует отметить, что расширение метода с оценкой изменения окружающей среды позволит выявить индивидуальные триггеры приступов астмы. Несмотря на то, что такие данные могут помочь избегать мест, представляющих наибольшую опасность для пациентов с астмой, они требуют сложных и надежных источников записи данных. Заключение В дальне йшее направление исследований целесообразно осуществить внешнюю проверку разработанных моделей с использованием больших выборок и акцентом на объединении нескольких различных источников данных. 

: визуализация данных, python, автоматическая проверка , pandas I . Введение С развитием технологий в высших учебных заведениях стало появляться все больше курсов связанных с программированием. Одним из методов контроля знаний в подобных курсах являются задачи на написание кода. Такие зад ачи часто требуют творческого подхода, из за этого трудно выработать общий шаблон для их проверки. Это неизбежно ведет к повышению нагрузки на преподавателей . Им приходится внимательно изучать каждое решение и тратить на это свое время. Автоматическая пров ерка задач является одним из способов решения этой проблемы. Целью данной работы является разработка программ для автоматической проверки знаний по теме "Работа с данными в pandas и их визуализация в matplotlib и seaborn" на платформе MOODLE. Для реализац ии цели поставлены следующие задачи: 1. Исследовать возможность автоматизации проверки решений для задач на об работку и визуализацию данных. 2. Сравнить аналоги существующих курсов в доступных источниках. 3. Описать структуру курса и исследуемые области те хнологии. 4. Подготовить материалы курса и задачи с автоматической проверкой по теме "Р абота с данными в pandas и их визуализация в matplotlib и seaborn" Объектом исследования являются задачи для самостоятельного решения. Предметом исследования являются за траты времени на проверку задач на написание кода. II . Обзор аналогов 1. Курс « Big Data Analysis Deep Dive » на платформе Сoursera [1] В курсе присутствует модуль, посвященный обработке и визуализации данных с использованием библиотек Pandas , Matplotlib и Seaborn . Сам курс представляет из себя набор видеоуроков. По окончанию изучения материала предлагается пройти тест для проверки, полученных знаний. Материал курса сжатый, не уделяется достаточно времени для изучения каждой из представленных тем. 2. Курс «2022 Python Bootcamp for Data Science Numpy Pandas & Seaborn» на платформе Udemy [2] Учебные материалы курса содержат набор видеоуроков с конспектами в Jupyter Notebook на тему обработки и визуализации данных с использованием библиотек Pandas и Seaborn . В программе курса присутствуют тесты с множественным выбором ответа, а также упражнения для закрепления пройденного материала. Курс структурирован и подходит для начинающих , но при этом курс является платным и задания на написание кода не имеют автоматическо й проверки. 3. Курс « Введение в Data Science и машинное обучение » на платформе Stepik [3] В материалах курса выделены модули, которые затрагивают обработку и визуализацию данных с использованием библиотек Pandas, Matplotlib и Seaborn. Учебная программа состои т из видео уроков, а также включает в себя ссылки на источники для самостоятельного изучения. Для проверки знаний в курсе присутствуют тесты и практические задания на написание кода . Для задач, которые не требуют визуализации данных, присутствует автоматич еская проверка. Материалы курса написан ы на русском языке , но д ля работы с ними требуется уверенное знание языка программирования Python. Помимо этого, темы в курсе подаются сжато. 4. Курс « Python Packages for Data Science » на платформе Coursera [4] В програм ме курса выделены отдельные модули для изучения Pandas , Matplotlib и Seaborn , по модулю на каждую библиотеку . Учебный материал состоит из видеоуроков, к которым прилагаются конспекты, написанные в Jupyter Notebook. К каждой теме предлагается решить ряд задач на написание кода, которые проверяются сокурсниками. Курс не структурирован и материала для изучения недостаточно для освое ния технологий . 5. Видеокурс «Введение в анализ данных» на Youtube канале VK Team [5] В видеокурсе н есколько лекций выделено на изучение библиотек Pandas, Matplotlib и Seaborn. Учебная программа состоит из видео уроков и к не й не прилагается никаких задач для самостоятельного решения. Курс структурирован и в полной мере раскрывает каждую тему , а материалы курса написаны на русском языке III . С равнени е аналогов Для сравнения аналогов необходимо определить критерии сравнения наиб олее важные для составления заданий с автоматической проверкой по теме "Работа с данными в pandas и их визуализация в matplotlib и seaborn".  Автоматическая проверка Данный критерий должен быть рассмотрен, так как автоматизация проверки упрощает работу преп одавателя, экономя его время.  Доступность У студент ов не всегда есть возможность оплачивать курсы, поэтому необходимо, чтобы курс был бесплатным.  Полнота материала Важно, чтобы курс рассматривал все возможности изучаемой технологии, по необходимости заостряя внимание на конкретных примерах, включал в себя задачи и предоставлял возможность дополнительного самостоятельного изучения. Таблица 1 Сравнение аналогов Критерии Аналог Автоматическая проверка Доступность Полнота материала Русский язык Курс "Big Data Analysis Deep Dive" + / + Курс "2022 Python Bootcamp for Data Science Numpy Pandas & Seaborn" + Курс "Введение в Data Science и машинное обучение" + / + + Курс "Python Packages for Data Science" + Видеокурс "Введение в анализ данных" + + +  Русский язык Для того, чтобы материал курса был понятен студентам, недостаточно знакомым с английским языком, важно использование русского языка, как основного в описании курса. Сравним аналоги, по указанным выше критериям в таблице 1. В данной таблице п олное соответствие критерию в таблице обозначается символов "+", частичное соответствие "+/ ", не соответствие " ". Наиболее подходящим под критерии курсом по итогам сравнения является видеокурс " Введение в анализ данных " н а YouTube канале VK Team . Однако проблема данного курса заключается в том, что в нем не представлено никаких задач для самостоятельного решения, что очень важно для закрепления студентом знаний и проверки усвоения пройденного материала. I V . Выбор метода решения По результатам обзора предметной области и существующих аналогов было выявлено, что ни один из рассмотренных аналогов не удовлетворяет всем критериям полностью. Исходя из этого были определены требования к составлению заданий и уроков курса, которы е необходимо соблюсти, чтобы покрыть все критерии. 1. Задания и материалы курса должны быть доступно описаны на русском языке. Так у русскоязычного студента не будет возникать противоречий или неясности в поставленных задачах. 2. Задания курса должны иметь автом атическую проверку. Это сэкономит время, как студенту, так и преподавателю, которому не будет требоваться тратить время на ручную проверку. 3. Курс должен покрывать все возможности изучаемой технологии, при этом избегая сжатия материала. Это позволит избежать пробелов в знаниях у студента. V . Описание метода решения. Приведем описание разработанного курса «работа с данными в Pandas и их визуализация в matplotlib и seaborn » на платформе Moodle . В качестве основной среды при разработке материалов курса был выбра н Jupyter Notebook[9], так как он предоставляет возможность хранить вместе запускаемый код и изображения. Это позволяет со з давать информативные отчеты. При составлении структуры изучаемых тем, было решено разделить курс на две части: предобработка данных и визуализация данных.  Первая часть полностью посвящена работе с библиотекой Pandas . В нее вошли материалы и задачи, которые изучают основные структуры данных этой библиотеки: Series и DataFrame . Изучены методы создания, чтения, изменения и получения допо лнительной информации из этих структур. Помимо этого, рассмотрены способы импортирования данных из локального файла или сети интернет, методы сортировки, группировки и фильтрации данных. Во второй же части курса наибольшее внимание уделяется библиотеке Ma tplotlib , так как Pandas и Seaborn , в свою очередь, для визуализации также используют этот фреймворк. В эту часть материалов курса входят разделы, описывающие возможности визуализации основных видов графиков, используемых для анализа данных: линейные, контурные и точечные графики, площадные, линейчатые, сто лбчатые и круговые диаграммы. Отдельно рассматривается возможность библиотеки Seaborn изображать тепловые карты. П омимо работы с основными видами графиков, показаны отдельные возможности визуализации Matplotlib . Задачи для самостоятельного решения разделен ы на 2 типа: 1. Задачи на написание кода. Было проведено исследование возможности автоматической проверки таких задач, которое показало, что, структуры данных, изучаемых пакетов, позволяют получить, нужные для сравнения с верным решением, данные. 2. Задачи на з нание теории. Все задачи и материалы были размещены на платформе MOODLE , а также в системе контроля версий github [6] . VI . Выводы. В ходе работы была достигнута поставленная цель – разработ аны программы для автоматической проверки знаний по теме "Работа с д анными в pandas и их визуализация в matplotlib и seaborn" на платформе MOODLE . Для достижения цели был проведен сравнительный анализ аналогов, из которого были выделены наиболее важные критерии: автоматическая проверка, полнота курса. Разработана структура курса, и на основе этой структуры подготовлены материалы и задачи для самостоятельного решения. Также проведено исследование возможности автоматической проверки решений задач на обработку и визуализацию данных , которое показало положительный результат. В качестве дальнейшего развития курса рассматривается добавление вводной части, в которой будут изучаться возможности Jupyter Notebook , а также структуры данных Python пакета NumPy . 

: онлайн курсы, обработка данных, автоматизация обработки данных. Введение В каждом семестре перед преподавателями стоит задача аттестации студентов по дисциплинам. Структура дисциплин постоянно меняется, но очень часто содержит онлай н курс в качестве обязательного элемента, результаты прохождения которого необходимо обработать, чтобы аттестовать студентов. Сами онлайн курсы представлены на платформе Moodle [1] , которую активно используют университеты. О бработка статистики прохождения онлайн курсов занимает у преподавателей достаточно много времени, при этом велик шанс ошибиться, особенно если онлайн курс проходит не одна группа студентов, а целый поток. В данной статье рассматривается разработка инструм ента настраиваемой обработки статистики прохождения онлайн курсов, который должен решить вышеперечисленные проблемы. Приводится перечень используемых технологий в разработке и краткое описание причин их выбора, описывается архитектура приложения, а также п ринцип его работы. Перечень используемых технологий Перед проектируемым инструментом стоит задача обработки статистики прохождения онлайн курсов. Данная задача является задачей обработки большого массива данных. Для ее решения идеально подходит язык програ ммирования Python [2] , т.к. для него существуют библиотеки, решающие задачу обработки данных и визуализации данных, например, библиотеки Pandas [3] и NumPy [4] , которые были использованы при разработке инструмента. Помимо задачи обработки и визуализации да нных, инструмент также должен решить задачу получения данных, которые затем будет обрабатывать. Получение данных разбито на два этапа: сначала инструмент посредством аргументов командной строки получает путь к конфигурационному файлу. В процессе обработки этого файла, инструмент получает информацию о том, где находятся файлы со статистикой по онлайн курсам, а также настройки по обработке этих данных. За обработку аргументов командной строки отвечает модуль argparse [5] , а за обработку файла с настройками – модуль json [6] . Архитектура инструмента Разработанный инструмент представляет из себя программу на языке программирования Python . В процессе работы перед программой стоят 3 задачи: получить  статистику прохождения онлайн курсов, обработать статистику с уче том настроек, заданных в конфигурационном файле , и вывести результаты обработки в формате . xlsx . Задача получения статистики прохождения онлайн курсов решается при помощи модуля argparse , а также конфигурационного файла , который хранит в себе настройки обр аботки данных. Инструмент, получив конфигурационный файл, проводит его анализ при помощи модуля json , загружает данные, а также запоминает, как именно их необходимо обрабатывать. Задача обработки статистики с учетом настроек из конфигурационного файла реш ается при помощи библиотек Pandas и NumPy . Первая отвечает за представление данных, вторая – за их обработку. Т.к. сами данные представляют из себя таблицы, то библиотека Pandas , которая предоставляет возможность хранить данные в виде “ таблиц ” – DataFrame [ 7 ] , отвечает за их хранение и представление. Библиотека NumPy предоставляет возможность обработки больших массивов данных. Задача вывода результатов обработки в формате . xlsx [8] решается при помощи библиотеки Pandas . Библиотека имеет отдельный класс ExcelWriter [ 9 ] , который преобразует данные, хранящиеся в DataFrame в . xlsx документ. Для того, чтобы пользователю не приходилось настраивать окружение для работы инструмента, сам инструмент помещен в Docker контейнер [ 10 ] . Данное решение позволяет сконцен трироваться пользователю лишь на описании конфигурационного файла, который достаточно написать лишь один раз для любого онлайн курса, при условии, что последний не претерпит серьезных изменений своей структуры. В противном случае, конфигурационный файл нуж но будет изменить. Описание работы инструмента Общая схема работы инструмента представлена на рисунке 1. Рис. 1. Схема работы инструмента Инструмент получает на вход файл с настройками (конфигурационный файл) в формате JSON , после обработки которого получает данные со статистикой. Пример такого файла представлен на рисунке 2. В данном файле задается информация об онлайн курсах, которые необходимо обработать. Помимо информации об онлайн курсах, он также содержит информацию о студентах:  список студентов от кафедры и от деканата. Причин такого дублирования данных несколько: во первых, у кафедры и деканата может быть разное число студентов, а во вторых, в статистике прохождения онлайн курсов нет столбца с номером группы студентов. Информация об онлайн курс ах содержит все, что может пригодиться при их обработке. Путь к файлу с конкретным курсом, короткое название данного курса, которое инструмент будет использовать как ключ для доступа к данным, максимальная оценка за данный курс, название листа в . xlsx доку менте, в котором будут представлены обработанные данные, а также информация по задачам курса: как именно называются задачи курса, и во сколько баллов они оцениваются. Рис. 2. Пример конфигурационного файла Вся эта информация необходима для того, чтобы м ожно было обработать статистику прохождения онлайн курсов с платформы Moodle . В случае, если пользователь ошибся в каком либо из параметров, или не указал его вовсе, инструмент сообщит ему об ошибке и скажет, какой параметр задан неверно. В качестве резуль тата работы скрипта пользователь получает набор .xslx файлов по каждой студенческой группе, внутри которых находятся листы с результатами обработки каждого онлайн курса. Причина выбора именно . xlsx формата, а не . csv обусловлена тем, что один . xlsx файл им еет возможность хранить внутри себя несколько листов, а . csv [ 11 ] нет. В противном случае, пользователь, при условии, что онлайн курсов больше, чем один, получил бы кратно больше файлов, чем студенческих групп для которых он обрабатывал  статистику прохождения. Это усложняет процесс восприятия результата и вызывает неудобства при их просмотре из за того, что необходимо открывать множество файлов. Заключение В данной статье была описана разработка инструмента настраиваемой обработки статистики прохожд ения онлайн курсов на платформе Moodle : перечислены технологии, использованные при разработке, описана архитектура инструмента, а также принцип его работы. Несмотря на то, что инструмент разработан и готов к использованию, он имеет потенциал к дальнейшей доработке: возможно расширение перечня настроек, которые задаются в конфигурационном файле, а также возможность интеграции данного инструмента в бота, который мог бы раз в несколько недель запускать инструмент для обработки текущей статистики прохождения о нлайн курсов, чтобы преподаватель мог получать картину того, как студенты проходят курс, какие задания вызывают наибольшую сложность, для дальнейшего улучшения онлайн курса. 

: высокопроизводительные вычисления, параллельное программирование, онлайн курс, автоматизация проверки знаний Введение. В настоящее время онлайн курсы занимает значительную роль в образовательном процессе. С их помощью студенты могут изучать материал вне учебного время, а также проверять свои знания с помощью задач с автоматической проверкой. Это улучшает образовательный процесс, экономя время у преподавателей и позволяя студентам самостоятельно изучать материал и проверять свои знания по курсу. На данный момент на кафедре МОЭВМ есть курс по теме “Высок опроизводительные вычисления”, в курсе присутствуют как лекции, так и лабораторные работы, но отсутствует какой либо онлайн курс и какая либо автоматизированная проверка знаний как по самому курсу, так и по лабораторным работам. Для ручной проверки знаний у студентов преподавателям необходимо потратить большое количество сил и времени, а студентам приходится долго ждать для получения оценки своей работы. В связи со всем вышеперечисленным необходима разработка онлайн курса по теме “Высокопроизводительные выч исления”. Целью данной работы является разработка концепции онлайн курса по теме “Высокопроизводительные вычисления”. Объектами исследования является онлайн курсы и автоматическая проверка. Предметом исследования является длительность проверки знаний и пра ктических навыков. Для разработки концепции необходимо: 1 ) Провести обзор существующих онлайн курсов по теме «Высокопроизводительные вычисления» и ей смежных. 2 ) Провести их сравнительный анализ. 3 ) Сформировать требования для онлайн курса по теме «Высоко производительные вычисления». 4 ) Разработать концепцию онлайн курса. Обзор предметной области Для разработки концепции онлайн курса по теме “Высокопроизводительные вычисления” на платформе Moodle необходимо рассмотреть существующие онлайн курсы, которые по лностью или частично посвящены данной теме. Поиск онлайн курсов осуществлялся на платформах stepik, coursera, Яндекс.Практикум и Udemy. В качестве аналогов были выбраны следующие онлайн курсы: 1) Многопоточное программирование на C/C++ [1] Курс составлен к омпанией VK Team на платформе Stepik и распространяется бесплатно на русском языке. В курсе представлены видеоматериалы и текстовые материалы по многопоточному программированию на языке программирования C/C++. Для проверки и оценивания знаний используются тестовые задания и задания на написание кода. 2) Введение в параллельное программирование (OpenMP и MPI) [2] Курс составлен Томским Государственным университетом на платформе Stepik и распространяется бесплатно на русском языке. Курс знакомит с основными архитектурами многопроцессорных вычислительных систем, с двумя стандартами (OpenMP и MPI), позволяющими писать параллельные программы для систем с общей и распределенной памятью. В курсе представлены видеоматериалы по многопоточному программированию на язы ке программирования C/C++. Для проверки и оценивания знаний используются только тестовые задания. 3) Многопоточность в iOS (Swift) [3] Курс составлен компанией Avito на платформе Stepik и распространяется бесплатно на русском языке. Курс знакомит с многопоточностью, начиная от самых низкоуровневых  примитивов и заканчивая высокоуровневыми абстракциями. В курсе представлены материалы по многопоточному программированию на языке программирования Swift. Для проверки и оценивания знаний используются только тестовые задания. 4) Асинхронное программирование на Python [4] Курс составлен компанией Яндекс на платформе Яндекс.Практикум и распространяется платно на русском языке. В курсе представлены материалы по параллельному и асинхронному программированию на Py thon. Для проверки знаний используются тестовые задания и задания на написание кода. 5) Learn Parallel Programming with C# and .NET [5] Курс составлен Дмитрием Нестерук на платформе Udemy и распространяется платно на английском языке. В курсе представлены только видеоматериалы, посвященные параллельному программированию. Автоматическая проверка знаний отсутствует. В качестве критериев для сравнения онлайн курсов были выбраны следующие критерии: 1) Автоматическ ая проверк а заданий 2) Присутствие видеоматериал ов 3 ) Присутствие практических заданий на написание кода 4 ) Присутствие тестовых заданий Таблица 1 Таблица сравнения по критериям Аналог Автоматическая проверка Присутствие видеоматериалов Присутствие задач на написание кода Присутствие тестовых заданий Многопоточное программирование на C/C++ + + + + Введение в параллельное программирование (OpenMP и MPI) + + + Многопоточность в iOS (Swift) + + + Асинхронное программирование на Python + + + + Learn Parallel Programming with C# and .NET + В ходе анализа было обнаружено, что во всех онлайн курсах присутствуют видеоматериалы. Почти во всех курсах есть тестовые задания, а заданий на написание кода есть всего в двух онлайн курсах из пяти. При присутствии каких либо заданий в онлайн курса для ни х существует автоматическая проверка. Из всего этого можно сделать вывод, что при разработке онлайн курса наибольший упор нужно сделать на задания на написание кода, так как он является наименее выполняемым, что выделит наш онлайн курс из многих других. В ыбор метода решения По результатам обзора аналогов, определения критериев и сравнения аналогов установлено, что курс по теме “Высокопроизводительные вычисления” должны удовлетворять следующим требованиям: 1) Курс должен содержать видеоматериалы, которые п озволят студентам изучать материал в доступной и наглядной форме, а также готовиться к решению заданий. 2) При разработке курса необходимо сделать упор на реализацию заданий на написание кода, так как у многих онлайн курсов такие задания отсутствуют, что в ыделит наш курс среди них и позволит студентам получить практические навыки по теме курса. 3) Все задачи должны иметь автоматическую проверку. Автоматическая проверка присутствует почти во всех курсах. Ее отсутствие также замедлит образовательный процесс, так как проверка заданий будет необходимо осуществлять преподавателям. При выполнении всех требований онлайн курс поможет снизить нагрузку преподавателей и улучшит образовательный процесс, позволяя студентам изучать материал в доступной им форме и самостоя тельно проверять знания с помощью автоматической проверки. Описание метода решения По результатам обзора предметной области и сравнения аналогов были сформированы критерии, которым должны соответствовать курс по теме “Высокопроизводительные вычисления”. Для реализации курса можно выбрать систему управления образовательными электронными к урсами Moodle. Она позволит создать курс удовлетворяющий всем критериям: добавить видео и текстовые материалы, реализовать как тестовые, задания, так практические задания на написание кода, а также оснастить эти задания автоматической проверкой. В курсе не обходимо сделать упор на задания на написание кода по темам курса. Примеры заданий на написание кода: 1) Дана большая трехмерная матрица чисел, необходимо написать функцию, которая многопоточно считает сумму всех чисел трехмерной матрицы. 2) Необходимо ре ализовать очередь в lock free стиле. В структуре данных необходимо реализовать следующие методы: push принимает значение и добавляет его в очередь, pop удаляет и возвращает элемент очереди, front возвращает ссылку на первый элемент очереди, back во звращает ссылку на последний элемент очереди, isEmpty возвращает True, если очередь пуста, Fаlse в обратном случае. 3) Необходимо реализовать потокобезопасный стек, используя мьютексы. В структуре данных необходимо реализовать следующие методы: push принимает значение и добавляет его в начало очереди, pop удаляет и возвращает последний элемент очереди, head возвращает ссылку на головной элемент стэка, isEmpty возвращает True, если о чередь пуста, Fаlse в обратном случае. Для реализации автомати ческой проверки заданий на написание кода можно выбрать модуль Coderunner для Moodle. Он позволяет с помощью заранее разработанных программ запускать написанный студентами код и проверять корректность его работы. Для написания программ для автоматической п роверки можно выбрать язык программирования Python. Заключение В ходе работы были выполнены все поставленные задачи и достигнута установленная цель. Был проведен обзор предметной области, для этого сначала были отобраны аналоги,  по ним были сформированы критерии и по этим критериям проведено их сравнение. В качестве а налогов были рассмотрены онлайн курсы на различных платформах. С помощью сравнения аналогов были получены требования, которым должны удовлетворять курс по теме “Высокопроизводительные вычисления”. Важным требованием стало наличие практических заданий на на писание кода, а также их автоматическая проверка. Также предложен набор технологий для разработки онлайн курса и приведены примеры практических заданий . 

: изображения, python , файлы, курс, автоматическая проверка, образование Введение На сегодняшний день преподаватели, в основном, проверяют большое количество однотипных зада ний, выполненный студентами, вручную. Это занимает значительную часть рабочего времени, поэтому в последнее время становится всё более распространенными образовательные платформы и задания с автоматической проверкой ответов студентов. Автоматическая провер ка позволяет сэкономить время преподавателей, которое они могут потратить на более важные рабочие моменты: улучшение курса, разработка новых тем, разработка новых заданий и другие. Целью работы является разработка образовательного онлайн курса на платформе Moodle по теме «Работа с файлами и изображениями на Python » . Для достижения цели необходимо решить следующие задачи: 1. Выбрать способы автоматической проверки знаний на платформе Moodle 2. Определи ть критерии, и сравнить существующие аналоги для проверки знаний по темам схожим с «Работа файлами и изображениями на Python » . 3. Определить условия заданий и подготовить теоретический материал для разрабатываемого курса 4. Написать программы для решения заданий 5. Оформить задания и теоретический материал в виде самостоятельного курса Обзор аналогов В качестве рассматриваемых аналогов были отобраны онлайн ресурсы, полностью или частично нацеленные на обучение обработке изображений на языке программирования Python . 

: шашки, оцифровывание, YOLOv 5, FEN нотация Введение В настоящее время существует множество различных настольных игр, по которым проводятся крупные соревнования. Одной из этих игр являются шашки. Безусловно, каждый спортсмен мечтает совершенствовать качество своей игры. В этом ему помогает анализ сыгранных им партий и позиций . Основным элементом анализа является программа, в которую вносится сыгранная партия или возникшая в партии позиция . Анализ, выполняемый посредством специальной программы, показывает совершённы е ошибки, возможные варианты или лучшие ходы в п олучившейся позиции . Сейчас для ввод а одной шашечной позиции в программу для анализа необходимо поставить каждую шашку на определенное поле . Соответственно, чем больше сыграно партий и получено позиций , тем больше тратится времени на расстановку позиции , а это является б о л ь ш и м и в р е м е н н ы ́ м и и з д е р ж к а м и . С т о и т с к а з а т ь , ч т о в н а с т о я щ е е в р е м я н е с у щ е с т в у е т инструмента для автоматического оцифровывания шашечной позиции , но существуют инструменты для оцифровывания ш ахма тных парти й и позиций . Перечень технологий Для оцифровывания шашечной позиции на доске используются методы машинного обучения. Для распознавания шашек будет использоваться моделей обнаружения объектов YOLOv5 [1] с собственными классами. Для обучения б удет использоваться собственный  датасет с размеченными классами. Алгоритм перевода распознанных шашек в FEN формат [2] будет реализован на языке Python [3] с помощью библиотеки PyTorch [4] . Обучение модели обнаружения объектов Для оцифровывания позиции одновременно важны скорость оцифровывания и точность распознавания, также необходимо учитывать тот фактор, что разработанный алгоритм планируется использовать в приложении под Android устройства. Исходя из этого была выбрана модел ь YOLOv 5 , которая наиболее подходит под описанные выше условия. После выбора модели было необходимо создать датасет, содержащий фотографии шашек на шашечной доске. Было сделано около 300 фотографий шашечной доски с различным расположением шашек под различн ым углом. Затем, с помощью приложения labelImg [5] был размечен датасет: было выделено 4 основных класса игровых объектов: белая шашка, чёрная шашка, белая дамка и чёрная дамка. Также был выделен отдельный класс – шашечная доска. Этот класс необходим для т ого, чтобы можно было определить координаты шашек на доске. После создания и разметки датасета модель YOLOv 5 была обучена на полученных данных. Использовалось обучение со следующими параметрами:  количество эпох – 50 ;  размер батча – 6;  качество изображени я – 1280; По итогу обучения был получен файл с весами, который будет использован для распознавания шашек на шашечной доске. Разработка алгоритма оцифровывания шашечной позиции После получения файла с весами был реализован алгоритм перевода распознанных шашек в буквенные координаты. Для начала все изображения были разделены на 2 группы, в свою очередь каждая группа была разделена на 2 подгруппы.  Группа 1 – вертикальное изображение, аналогичное рис. 1а o Подгруппа 1 – начальное расположение чёрных шашек снизу o Подгруппа 2 – начальное расположение белых шашек снизу  Группа 2 – горизонтальное изображение, аналогичное рис. 1б o Подгруппа 1 – начальное расположение белых шашек слева o Подгруппа 2 – начальное расположение чёрных шашек слева Рис. 1. Вариации расположения шашечной доски Сам алгоритм состоит из нескольких этапов: начальная проверка, перевод координат в буквенное описание и перевод буквенного формата в FEN формат. На первом этапе происходит создаётся модель с коэффициентом достоверности 0.5 и проверка наличия класса «Доска». Данная проверка необходима для того, чтобы можно было применять основной алгоритм перевод координат в буквенное описание. Если же класса «Доска » нет в распознанных объектах, то рассчитать координаты шашек не представляется возможным. На втором этапе происходит перевод координат в буквенное описание. Изначально запоминаются координаты доски, относительно которых будут вычисляться координаты шашек на доске с помощью полей xmin , xmax , ymin и ymax , которые содержат крайние точки по осям аб сцисс и ординат. Также вычисляется длина столбца и ряда по координатам x и y соответственно по формулам 푥 _ 푟표푤 _ 푠푖푧푒 = 푥 _ 푚푎푥 − 푥 _ 푚푖푛 8 и 푦 _ 푟표푤 _ 푠푖푧푒 = 푦 _ 푚푎푥 − 푦 _ 푚푖푛 8 Затем для каждого распознанного объекта происходит вычисление координат центра. Именно по этой координате будет вычисляться позиция шашки на доске. Затем для x и y координат подбираются такие i и j , меньшие 8, соответственно, что: 푥 _ 푚푖푛 + 푖 ∗ 푥 _ 푟표푤 _ 푠푖푧푒 ≤ 푥 _ 표푏푗 ≤ 푥 _ 푚푖푛 + ( 푖 + 1 ) ∗ 푥 _ 푟표푤 _ 푠푖푧푒 푦 _ 푚 푖푛 + 푗 ∗ 푦 _ 푟표푤 _ 푠푖푧푒 ≤ 푦 _ 표푏푗 ≤ 푦 _ 푚푖푛 + ( 푗 + 1 ) ∗ 푦 _ 푟표푤 _ 푠푖푧푒 Далее, в зависимости от расположения доски, полученные значения i и j переводятся в буквенные координаты по следующему правилу:  Группа 1 o Подгруппа 1: буква : rowLetters [7 – i ], цифра : j + 1 o Подгруппа 2 : буква : rowLetters [ i ], цифра : 8 – j  Группа 2 o Подгруппа 1: буква : rowLetters [7 – j ], цифра : 8 – i o Подгруппа 2 : буква : rowLetters [ j ], цифра : i + 1 , где объект rowLetters представляет собой соответствие между цифрой и буквой: 0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h' После получения координаты происходит проверка – в список шашек записывается та, которая распозналась с б о ́ льшей точностью. На последнем этапе полученные координаты переводятся в FEN формат. FEN форма т представляет собой выражение вида: « ( ХОД ) : W ( БЕЛЫЕ ) : B ( ЧЕРНЫЕ ) » , где ХОД – очередность хода – буква B ( black ) или W ( white ) , БЕЛЫЕ – перечисление через запятую позиций белых шашек на доске. Если шашка является дамкой, то перед позицией приписывается латин ская буква K , ЧЕРНЫЕ – перечисление через запятую позиций черных шашек на доске. Если шашка является дамкой, то перед позицией приписывается латинская буква K . Например, W:WKb4,c3:Bf6,Kg5 – позиция, в которой первыми ходят белые, шашка белых находится на п оле c 3 , дамка белых находится на поле b 4 , чёрная шашка находится на поле f 6 , а чёрная дамка находится на поле g 5 . Пример работы алгоритма На рис. 2 представлена фотография, с выделенными на ней распознанными шашками. Результатом работы будет следующий вывод: Ход белых : W:Wb4,a1,c1,a7,e1,h2,g3:Bd8,g7,b8,f8,h6,h8,Kf2 Ход чёрных : B:Wb4,a1,c1,a7,e1,h2,g3:Bd8,g7,b8,f8,h6,h8,Kf2 В результате получилось две строки FEN формата – позиция при ходе белых и позиция при ходе черных. Полученный формат можно использовать в различных программах для анализа, а также на сайтах, например, lidraughts [6] . Разработанный алгоритм доступен на платформе GitHub [7] . Рис. 2. Изображени е с распознанными шашками Заключение В данной статье представлена разработка алгоритма для оцифровывания шашечной позиции с помощью модели YOLOv 5. Результатом работы программы строка FEN формата, которая может использоваться в дальнейшем машинном анализе. Несмотря на то, что алгоритм был реализован на языке python для персонального компьютера, необходима реализация мобильного приложения, которое сможет оцифровывать шашечные позиции и обеспечит большую вариативность, так как мобильное устройство, зачастую, н аходится под рукой. Также разработанный алгоритм может лечь в основу алгоритма для оцифровывания целой шашечной партии. 

: криптография, Python, онлайн курс, MOODLE. Введение Такие проблемы, как защита информации, проверки подлинности отправителя и целостности данных, актуальны во все времена . В связи с этим имеется необходимость введения студентов младших курсов технических специальностей в данную область. Для решения этой задачи необходимо разра ботать онлайн курс по криптографии . Для снижения нагрузки на преподавателей необходимо, чтобы решения практических задач проверялись автоматически, что также позволит обучающимся практически мгновенно получить результат. Следовательно, необходимо также разработать программный комплекс для автоматической проверки решений студентов курса. Для непосредственно создания программного комплекса необходимо составить условия задач. Для этого необходимо определить рассматриваемые темы с учётом знаний студентов мла дших курсов. Целью данной статьи является создание онлайн курса «Криптография на Python» на платформе MOODLE с практическими задачами на программирование, имеющих автоматическую проверку. Объект исследования – автоматизация проверки знаний учащихся , предме т исследования – число задач с автоматической проверкой знаний . Для достижения поставленной цели необходимо выполнить следующие задачи: 1. Провести сравнительный анализ существующих онлайн курсов по криптографии. 2. Составить структуру курса. 3. Разработать лекцион ный материал. 4. Составить теоретические и практические задания. 5. Реализовать программный комплекс для автоматической проверки задач на программирование. Обзор предметной области Для определения необходимых требований к разрабатываемому онлайн курсу необходимо рассмотреть существующие аналоги. В качестве рассматриваемых аналогов были отобраны онлайн курсы в открытом доступе, полностью или частично посвящённые криптографии. Были рассмотрены следующие аналоги: 1. «Введение в теоретическую информатику» [1]. В данном курсе криптография рассматривается в одном модуле , в котором рассматриваются протокол Диффи Хеллмана и алгоритм RSA. Существенным отличием данного курса от остальных являются задачи, предполагающие развёрнутые ответы на вопросы , проверяющиеся непосредстве нно преподавателем и не поддающиеся автоматизации. 2. «Математика в кибербезопасности» [2]. Данный курс содержит два модуля, посвящённые данной теме. Рассматриваются шифр ы Цезаря, моноалфавитной замены , Виженера , Вернама и RSA, а также протокол Диффи Хеллмана и хэш функции. Особенностью данного курса является наличие задач перед лекционным материалом для лучшего освоения темы. Представленные задачи являются как теоретическими, так и практическими , но не подразумевающие реализацию. 3. «Основы кибербезопасности» [ 3]. В данном онлайн курсе криптографии посвящён один модуль. В данном модуле основное внимание уделяется прикладным темам : цифровая подпись, электронные платежи и блокчейн. Все задачи данного модуля являются исключительно теоретическими, основываясь на мат ериале лекций. 4. «Введение в современную криптографию» [4]. Данный курс полностью посвящён криптографии. Рассматриваются симметричное и асимметричное шифрования, обеспечение целостности данных, а также прикладные аспекты. После каждой темы имеется тест из 10 теоретических вопросов с выбором ответов по пройденной теме. По окончании курса имеется итоговый тест, недоступный обучающимся на бесплатной основе. 5. «Introduction to Information Security» [5]. Данный курс полностью посвящён криптографии. Курс построен так им образом, что изначально рассматриваются прикладные аспекты криптографии, а затем симметричное и асимметричное шифрования. В отличие от остальных аналогов данный курс является англоязычным. Задачи присутствуют не после каждой лекции. Все задания представлены в виде теста из нескольких вопросов с вариантами ответов. Для сравнения онлайн курсов были выбраны следующие критерии: 1. Доступность курса. 2. Количество рассматриваемых тем. 3. Количество теоретических задач. 4. Количество практических задач. На основан ии приведённых аналогов и критериев был проведён сравнительный анализ, результат которого представлен в таблице 1.  Таблица 1 Сравнение аналогов Название онлайн курс а Доступность курса Количество рассматриваемых тем Количество теоретических задач Количество практических задач Введение в теоретическую информатику Открыто 2 6 0 Математика в кибербезопасности Открыто 7 58 15 Основы кибербезопасности Открыто 3 16 0 Введение в современную криптографию Открыто частично 5 60 0 Introduction to Information Security Открыто 3 27 0 Анализируя аналоги, приходим к заключению , что большинство рассматриваемых курсов являются открытыми и содержат только теоретические задачи. Наилучшим из аналогов является курс «Математика в кибербезопасности», так как он покрывает наибольшее число тем и содержит теоретические и практические задачи. Однако, ни один из рассматриваемых аналогов не включает в себя задачи на программирование, что является недостатком . Выбор метода решения По итогу данной работы должен получи ться онлайн курс по теме «Криптография на Python». Дополненное лекционным материалом и автоматической проверкой данное решение должно помочь снизить нагрузку на преподавателей и ознакомить слушателей курса с криптографией и решением криптографических задач с помощью Python . Анализируя аналоги, было решено разбить курс на следующие модули: 1. « Введение в криптографию » . В данном модуле представлена информация о целях и решаемых задачах криптографии, обзорно о видах алгоритмов шифрования, хэш функциях. М одуль является ознакомительным, содержит только теоретические задачи. 2. « Симметричное шифрование: поточные алгоритмы » . В данном модуле подробнее рассказывается о симметричном шифровании, их видах и предоставляется обзор поточных исторических шифров. Подробно рассм атривается шифр Цезаря и описание колец вычетов и операций в них, так как математическая модель данного шифра основана на них . Практические задачи в данном модуле подразумевают реализацию шифра Цезаря и его взлома по известной части открытого текста вручн ую и с помощью языка программирования Python. Перед программной реализацией алгоритмов студентам предлагаются задачи на вычисление в кольцах вычета. 3. « Симметричное шифрование: блочные алгоритмы » . В данном модуле приводится обзор на симметричные блочные шифр ы. Рассматривается необходимость в режимах блочного шифрования и подробно иллюстрируются режимы коды аутентификации ECB и CBC , их сравнение. Ввиду высокой сложности рассматриваемых алгоритмов приведены шифрование и расшифровка с помощью стороннего модуля P yCryptodome [6]. Студентам предлагается сперва ознакомиться с ним, решив задачу на исправление предоставленного кода, а затем использовать его для шифрования. 4. « Асимметричное шифрование » . В данном модуле подробно объясняется асимметричное шифрование, в част ности протокол Диффи Хеллмана и алгоритм RSA. Перед их рассмотрением приводятся необходимые понятия: функция Эйлера, первообразный корень и мультипликативная инверсия по модулю. Для практического использования приводятся примеры создания ключей, использование алгоритма RSA с помощью модуля PyCryptodome [6]. Практические задачи в данном модуле подразумевают последовательную реализацию алгоритма RSA. Для этого студентам реализовать вычисление закрытого ключа, шифрование и расшифровку. В конце предлагается на практике ознакомиться с асимметричной криптографией в PyCryptodome [6]. 5. « Хэш функции » . В данном модуле студентам предлагается изучить определение хэш функции, обзорно рассмотреть некоторые криптографические хэш функции, а также область их применения с испо льзованием PyCryptodome [6]: коды аутентификации и электронно цифровая подпись. На практике студентам предлагается реализовать код аутентификации NMAC и ознакомиться с применением хэш функций на примере решения прикладной задачи создания электронной цифров ой подписи Заключение В рамках данной работы была достигнута поставленная цель: создан онлайн курса «Криптография на Python» на платформе MOODLE с практическими задачами, в том числе на программирование, имеющих автоматическую проверку. Для этого были расс мотрены существующие аналоги, проведён анализ, в результате которого были определены слабые стороны существующих онлайн курсов. На основе анализа были определены темы курса, разработана структура курса, составлены необходимый лекционный материал, условия т еоретических и практических задачи, разработан программный комплекс для проверки задач на программирование. Дальнейшая работа заключается в тестировании и внедрения данного курса в курс информатики. Также в дальнейшем имеет место расширение курса для более опытных студентов с подробным рассмотрением всех алгоритмов. 

: pdf документ , отсканированный документ , извлечение текста Введение В настоящее время многим людям, особенно в государственных учреждениях, приходится работать с большим количеством различных документов, в том числе и в PDF формате (например, отсканированные рецензии, отзывы). Эта работа заключается в повторении однотипных действий, например, заполнение секретарем ГЭК протоколов данными, которые содержатся в PDF документах. Поэтому, необходим инструмент, который мог бы в автоматическом режиме извлекать нужную информацию из документов, например, сведения о рецензентах (ФИО, должность, ученое звание, степе нь) и записывать её в сводную таблицу . На данный момент инструмент поддерживает набор документов аспиранта : научный доклад ( НД ) , научно квалификационная работа (НКР) , отзыв руководителя , две рецензии , антиплагиат . Также стоит отметить , что данные документы обладают некоторым значительным отличием . Отзыв руководителя и рецензии представляют собой отсканированные документы . Такие документы обрабатывать сложнее тех , которые содержат текст , который можно выделить в любом приложени и для просмотра документов . Для написания приложения был выбран язык программирования Python [1], так как он обладает широким списком готовых библиотек для работы с PDF файлами , изображениями и текстом . Описание работы приложения Из представленного ранее списка документов необходимо получать следующую информацию:  Научный доклад – количество страниц  Научно квалификационная работа – количество страниц , тема , номер и наименование направления подготовки , ФИО студента  Отзыв руководителя – ученая степень , учено е звание , должность и ФИО руководителя , поставленная оценка  Рецензия ученая степень , ученое звание , должность и ФИО рецензента , поставленная оценка  Антиплагиат – процент оригинальности НКР Для извлечения текста с отсканированных документов использовалось приложение для оптического распознавания символов Tesseract [ 2 ] . В приложении реализованы различные методы для извлечения текста из PDF документов . В большинстве случаев извлечение необходимых фрагментов текста происходит с помощью написанных регулярных в ыражений. С извлечением сведений о рецензентах и руководителе возникли сложности , связанные с нестрогой формой их представления в документах . Из за этого нельзя составить регулярное выражение , которое будет точно извлекать данную информацию во всех случаях . Поэтому было принято решение добавить возможность извлекать фрагменты текста , которые пользователь заранее бы выделил . Был реализован метод извлечения фрагментов текста [ 3 ] , выделенных контрастным желтым цветом . На рис . 1 представлен пример работы приложения для данного случая . Рис . 1. Пример извлечения информации из файла с рецензией Для демонстрации работоспособности написанного модуля был реализован интерфейс командной строки , который имеет следующие параметры :  -in, i – путь к PDF файлу или директории . При указании файла необходимо указать следующий параметр. При указании директории необходимо убедиться, что она соответствует необходимой структуре: на каждого аспиранта создана отдельная папка с документами , в н азваниях документов должен отображаться их тип . В данном случае  р езультатом работы приложения будет файл с табли цей , в которой записаны извлеченные данны е.  -type, t – тип документа , необходим , когда входное значение параметра – i путь до PDF файла . Возмож ные значения : nd – научный доклад , nkr – научно квалификационная работа, review – рецензия или отзыв , antiplagiat – антиплагиат На рис. 2 представлен пример вызова приложения для директории и фрагмент результирующей таблицы. Рис . 2. Пример работы приложения с записью в сводную таблицу На рис . 3 представлен пример работы приложения для файла научно квалификационной работы . Рис . 3. Пример работы приложения для файла НКР Заключение В ходе выполнения работы было разработано приложение в виде Python м одуля для извлечения необходимых секретарю ГЭК сведений из PDF документов . На данный момент приложение поддерживает набор документов аспиранта . Для демонстрации  работоспособности приложения был написан консольный интерфейс . Направления дальнейшего исследо вания включают в себя реализацию генерации сводных протоколов на основе шаблона документа и полученной таблицы данных , которую дополнил секретарь , тестирование приложения на большем количестве реальных входных данных , а также интеграция с разрабатываемым в еб интерфейсом . 

: нейросетевые модели, F1 score, cемантическое сходство, микросервис. Введение В современных рекомендательных системах, в частности, в сфере образования, воз никает задача улучшения качества рекомендаций. При выдаче студенту рекомендаций при большом выборе может потребоваться учет семантического сходства текстов . Семан тическое сходство [1] это показатель, определяемый для набора документов или терми нов, в котором идея расстояния между элементами основана на сходстве их значения или семантического содержания, в отличие от лексикографического сходства. Например , сер вис при сопоставлении текста рабочей программы “Веб технологии” и вакансии “Фрон тенд разработчик”, должен констатировать их семантическое сходство, а в случае сравне ния текста рабочей программы “Глубокое обучение” и вакансии “Лингвист” наоборот, д олжен отрицать их семантическое сходство. Способ учёта семантического сходства ис пользование нейронных сетей. Показателем семантического сходства пары текстов в рамках данной задачи выступает число сходства вещественное число от 0 до 1. Чем ближе чис ло к 1, тем более семантически схожи тексты. Очевидно, что для разных корпу сов исследуемых текстов порог числа сходства будет отличаться, поэтому актуальна зада ча поиска данного порога на данной предметной области (рабочие программы, проекты, вакансии). Использование микросервисной архитектуры обусловлено упрощением инте грации с существующими системами и потенциальной необходимостью переиспользо вать решение. Таким образом, актуальна разработка микросервиса для семантического анализа текстов с использова нием нейронных сетей. Целью данной работы является опи сание разработанного микросервиса. Постановка задачи Микросервис должен обеспечивать выполнение следующих действий: 1. Загрузка обучающего набора данных на сервер; 2. Обучение выбранной модели на загру женном наборе данных; 3. Получение числа сходства двух введенных текстов при помощи выбранной модели; 4. Подбор порога числа сходства, при котором метрика F1 score будет максимальной (параллельно с проведением кросс валидации модели относительно множества значений порога); 5. Получение списка доступных моделей. Результат работы микросервиса сервер должен возвращать в виде JSON файла. Описание метода исследования качества работы моделей Для вычисления метрики F1 score и подбора порога числа сходства был сформирован набор данных, представляющий собой 70 пар текстов: рабочая программа учебной дис циплины – проект (вакансия). Помимо текстов элемент набора данных содержит логи ческое значение, отвечающее за сходство или отсутствие семантического сходства межд у текстами. Каждой паре текстов сопоставлено это значение – согласно нему пред определено, должна ли пара сопоставляться или нет. Введем следующие понятия: 1. TP истинно позитивное предсказание (модель верно предсказала семантическоe сходство пары текст ов); 2. TN истинно отрицательное предсказание (модель верно предсказала семантиче ское несовпадение пары текстов); 3. FP ложное положительное предсказание (модель ошибочно предсказала семанти ческое сходство пары текстов); 4. FN ложно отрицательное предсказание (модель ошибочно отвергла сходство пары текстов); 5. Precision точность мера того, сколько из сделанных положительных предсказаний верны; 6. Recall полнота мера того, сколько положительных случаев модель предсказала верно среди всех п оложительных случаев в данных. TP Precision TP FP   TP Recall TP FN   На практике невозможно одновременно [2] максимизировать точность и полноту, поэтому необходима метрика, сочетающая информацию о точности и полноте. Такая метрика называется F1 score и представляет собой среднее гармоническим точности и полноты. 2 1 Recall Precision F Recall Precision   Стоит отдельно затронуть задачу подбора порога числа сходства. Поскольку модель возвращает число от 0 до 1, а в рамках данной задачи требуется бинарный результат (ли бо тексты семантически схожи, либо нет), в список гипе рпараметров метода добавляется порог числа сходства. Алгоритм максимизации выполняется с помощью кросс валидации методом Leave One Out [3]. Метод решения задачи Разрабатываемое решение написано на языке Python 3 с применением backend фреймворка Flask [4]. Способ взаимодействия пользователя или другого сервиса с разрабатываемым – протокол HTTP и метод сериализации JSON. Для упрощения взаимодействия с микросервисом и тестирования его работоспособности выбран инструмент Swagger [5], который позволяет описыват ь интерфейс взаимодействия с сервисом. Для  кэширования результатов работы ресурсоемких функций (например, функции, производящей сопоставление текстов при помощи модели, использующей ар хитектуру “трансформер” [6]) была использована нереляционная СУБД Redis [7]. В качестве используемых моделей были выбраны 2 модели, представляющие собой неглубокие нейронные сети из трех слоев: word2vec [8] и fastText [9]. Для работы с ними выбрана библиотека Gensim [10]. Помимо данных нейронных сетей были выбраны 2 предобуч енных модели, использующих архитектуру “трансформер”. Для взаимодействия с ними был выбрана библиотека SentenceTransformers [11]. Пользователь отправляет запросы на сервер при помощи REST API, в определенных случаях передавая параметры, (например, идентиф икатор модели) и получает ответы (например, число сходства двух текстов). Архитектура микросервиса приведена на рис. 1 . Рис. 1. Архитектура микросервиса Краткое описание работы микросервиса 1 . POST /train/uploadDataset загрузка обучающего набора данн ых на сервер. В качестве тела запроса выступает JSON файл, представляющий обучающий набор данных. При отправке данного запроса на сервере выполнится метод upload_train_data(), который запускается на сервере через URL “ /api/docs/train/uploadDataset”. Данн ый метод сохранит набор данных на сервере для дальнейшего использования и вернет ответ об успешности или неуспешности операции. 2 . GET /train/{modelId} обучение неглубокой сети (word2vec/fastText). В качестве параметров данный запрос принимает идентифик атор модели, после чего запрос выполняется на сервер. При отправке данного запроса на сервере выполнится метод, train_model(name), который запускается через URL “/api/docs/train/<string:name>”. Создаётся экземпляр класса ModelResearcher, который, загружает из памяти сервера считанный датасет, предобрабатывает его (в случае с неглубокими нейросетями разбивает тексты на токены, приводит к нормальной форме, и т. п.), после чего обучает модель при помощи метода train(texts, model, model_path) класса ModelResear cher и сохраняет данную предобученную модель в памяти  сервера, чтобы обеспечить её дальнейшее использование. Сервер возвращает время, затраченное на обучение в случае успеха и сообщение об ошибке в ином случае. 3. POST /match2texts/{modelId} получение числа сходства двух текстов при помощи выбранной модели. В качестве параметров передается название модели, в качестве тела запроса – пара текстов, которые предполагается семантически сравнить. При отправке данного запроса на сервере выполнится метод match2texts(name), который запускается через URL “/api/docs/match2texts/<string:name>”. Создаётся экземпляр класса ModelResearcher, который, загружает из памяти сервера требуемую модель, и при помощи метода predict_sentences_similarity(text_1, text _2, model) производит семантическое сравнение пары и возвращает число сходства в случае успеха, в случае ошибки соответствующее сообщение. 4. POST /maximize f1 score crossvalid loo/{modelId} подбор порога числа сходства, при котором F1 score будет макс имальной при проведении кросс валидации методом Leave One Out. В качестве параметров передается название модели, в качестве тела запроса – текстовый файл, представляющий собой последовательность пар текстов, для которых заранее предопределено, должны ли он и сопоставиться или нет. Информация об этом так же находится в данном файле. При отправке данного запроса на сервере выполнится метод, maximize_f1_score_loo(name), который запускается через URL “maximize f1 score crossvalid loo/<string:name>”. Создаётся экземпляр класса ModelResearcher, который, за гружает из памяти сервера требуемую модель, и при помощи метода maximize_f1_score_loo(texts_json, model, step) производится кросс валидация модели мето дом Leave One Out относительно порога числа сходства. В ка честве ответа сервер воз вращает json файл, в котором находится порог, соответствующий ему F1 score, а также другие метрики качества (Precision и Recall). 5. GET /get list of allowed models – получение списка доступных моделей. Заключение В ходе данной раб оты рассмотрен разработанный микросервис для семантического анализа текстов с использованием нейронных сетей, который позволяет сравнивать тек сты на семантическое сходство при помощи нейронных сетей, обучать неглубокие нейросети, а также максимизировать м етрику качества F1 score при проведении кросс валидации. Дальнейшее развитие предполагает увеличение количества моделей для ис пользования в микросервисе. Предполагается дальнейшая интеграция с ИС “Личный ка бинет партнёра”. 

: образование, GitHub, Moodle, Google Sheets, API, автоматизация Введение Каждый учебный год студенты загружают большое количество л абораторных работ в соответствующие репозитории GitHub [1]. Проверка данных работ (проверка исходного кода, проверка отчета, проверка задачи на Moodle, выставление оценок по результатам защиты) является трудоемкой задачей, требующей большого количества одн отипных действий, особенно при большом количестве студентов. На данный момент существующие решения [2] выполняют часть таких задач, однако некоторые из них, такие как рассылка приглашений в репозитории для студентов, перенос оценок за защиту из Moodle [3] в репозиторий, проверка идентичности исходного кода лабораторной работы, загруженного в Moodle и в репозиторий, не были реализованы и занимают немалую часть времени (до нескольких часов) при их ручном выполнении. В данной статье рассматривается подход умен ьшения участия преподавателей в рутинных процессах проверки лабораторных работ студентов. Приводятся алгоритмы автоматизации перечисленных задач с использованием GitHub, которые могут значительно упростить процесс проверки, позволят преподавателям сократит ь время, затрачиваемое на выполнение однотипных задач проверки лабораторных работ, и сосредоточиться на более важных задачах в образовательном процессе. Перечень технологий Существующие решения по проверке лабораторных работ реализованы на языке программи рования Python [4], значит, для обеспечения совместимости разрабатываемых автоматизированных задач также будет использоваться Python. Библиотеки, упомянутые далее, являются библиотеками данного языка программирования . Для получения доступа к данным при HTT P запросе [5] к API используемых сервисов (GitHub, Moodle, Google Sheets [6]) необходимо передавать токен, который позволяет  серверу идентифицировать пользователя и отвечать на запросы с соответствующими для данного токена правами. Отправку HTTP запросов к Moodle API [7] и получение ответов позволит в полной мере реализовать библиотека requests [8]. Все последующие запросы к Moodle API будут осуществляться по URL пути /webservice/rest/server.php (может использоваться любой хост, где используется система Moo dle). Библиотека PyGithub [9] позволит выполнять необходимые действия над указанными репозиториями и их содержимым с помощью определённых в ней методов взаимодействия, использующих GitHub API [10]. Для работы с Google Sheets будет использована библиотека g spread [11], которая позволит получать данные из Google таблиц в удобном для их обработки формате. В некоторых из перечисленных задач будет необходимо обрабатывать html разметку. Для работы с разметкой понадобится библиотека html [12] . Методы библиотеки datetime [13] будут использованы для работы со временем, что применительно для задачи добавления студентов в репозитории . Автоматизация добавления студентов в репозитории GitHub Условие: перед рассылкой приглашений в репозитории происходит сбор информации в Google таблицу, в которую студенты через форму вносят свои данные (фамилия, имя, номер группы, имя пользователя GitHub и др.). По листам из таблицы преподаватели вручную добавляют студентов в соответствующие репозитории, названия которых имеют формат: <к раткое название предмета> <год> <номер группы> (например, oop 2019 9303). Необходимо автоматизировать данную задачу, основываясь на данных из Google таблицы . Название репозитория, в который будет добавлен студент, можно определить следующим образом: пусть названия листов имеют краткое название предмета, а текущий год будет определяться с помощью атрибута year из возвращаемого значения метода datetime.now(). Таким образом, обрабатывая каждую запись с информацией о студенте, зная номер группы, точно определяе тся, в какой репозиторий его следует добавить . Алгоритм добавления студентов в репозитории будет повторяться для каждого листа таблицы. Получение объекта таблицы для работы с ней осуществляется методом open_by_url() библиотеки gspread, где в качестве аргум ента указывается ссылка на обрабатываемую таблицу. 

: веб интерфейс, документ, анализ, протоколы Введение Секретарю ГЭК требуется без ручного указания шаблонных данных (ФИО рецензентов и студентов, вопросы комиссии) генерировать протоколы и сводные ведомости по результатам заседани я ГЭК; интерфейс, в сравнении с аналогами, должен уменьшить количество действий пользователя, требуемых для генерации документов; предоставлять актуальную информацию о состоянии системы, быть отзывчивым в случае потери интернет соединения, передавать данны е в зашифрованном виде. Существующие интерфейсы не в полной мере реализуют данные требования: может быть уменьшено количество кликов пользователя, необходимое для реализации основного варианта использования системы, при временной потере интернет соединения может происходить потеря информации (не отображаться альтернативный текст у контентной статики, отсутствие уведомлений об актуальном состоянии системы), передача данных в незашифрованном виде. Объектом исследования являются интерфейсы инструментов генерации документов. Предметом исследования является UX при использовании инструмента автоматизации генерации протоколов при использовании различных интерфейсов. Целью исследования является создание прототипа веб интерфейса для инструмента генерации прот околов и сводных ведомостей по результатам заседания ГЭК. Задачи исследования: 1. Сформулировать требования к интерфейсу: уменьшение, в сравнении с аналогами, количества действий пользователя, требуемых для генерации документов, обеспечение отзывчивости интер фейса в случае потери интернет соединения, передача данных в зашифрованном виде; 2. Разработать прототип веб интерфейса, удовлетворяющий сформулированным критериям: уменьшенным, в сравнении с аналогами, числом кликов для реализации основного варианта испол ьзования, с обеспечением отображения актуального статуса системы, с передачей данных в зашифрованном виде. Определение требований к интерфейсу В результате исследования предметной области и определения перечня критериев, которым должен удовлетворять веб интерфейс, можно сформулировать требования к разрабатываемому веб интерфейсу. • Веб интерфейс должен обеспечивать генерацию протоколов и сводных ведомостей по результатам заседания ГЭК не более чем за 8 10 кликов пользователя, оптимально за 2 4 клика. • Веб интерфейс должен иметь русскую и английскую локализации, поскольку основными пользователями являются носители русского или английского языков. • Веб интерфейс должен позволять загружать шаблонные данные, на основе которых производить генерацию тексто вых документов. • Веб интерфейс должен предоставлять актуальную информацию о состоянии системы, поскольку 100% точность при анализе пользовательских документов недостижима. При соблюдении всех вышеперечисленных требований веб интерфейс сможет полностью вып олнить поставленную перед ним цель: автоматизировать генерацию протоколов и сводных ведомостей по результатам заседания ГЭК. Описание метода решения Для решения поставленной задачи по разработке прототипа веб интерфейса, удовлетворяющего сформулированным в ыше требованиям, были выбраны следующие технологии для реализации веб интерфейса: библиотека NextJS [1], позволяющая за счет технологии SSR [2] оптимизировать загрузку веб страниц. В качестве библиотеки базового набора компонентов используется Material UI [3], поскольку она позволяет гибко настраивать внешний вид компонентов интерфейса. Для обеспечения аутентификации пользователей по протоколу OAuth с использованием API популярных сервисов, предоставляющих возможности создания учетных записей (Yandex, Googl e, VK) была выбрана библиотека NextAuth [4]. На основе сформулированных ограничений по используемым технологиям были разработаны макеты экранов для основных состояний приложения. Для предоставления возможности генерации текстовых документов на основании ша блонов и шаблонных данных у интерфейса предполагается наличие двух форм для загрузки соответствующих документов: с шаблоном и с данными. Для обеспечения отображения актуальной информации о состоянии системы (на данном этапе о максимальном допустимом  количе стве загружаемых изображений) под формами для загрузки присутствует индикатор степени использования ресурсов в рамках одной загрузки. Для предоставления подробной информации о том, как правильно использовать приложение, предусмотрено наличие справочного ди алогового окна, для предотвращения случайного удаления пользователем загруженных документов предусмотрено наличие диалогового окна, подтверждающего действие. Для предоставления пользователю полной информации о состоянии системы, помимо текстовых индик а торо в о возможности загрузки файлов, а также линейного прогресса, отображающего уровень прогресса генерации документа, был разработан вид уведомлений двух типов. Информационные уведомления позволяют пользователю получить обратную связь о начале генерации докум ентов, качестве распознавания шаблонных данных, окончании генерации документов. Уведомления об ошибках предоставляют пользователю информацию об ошибках подключения к сервису, распознавания данных, загрузки исходных данных или сохранения результата. Пользов ателю также предоставляется возможность скачивания и редактирования шаблонных данных, использованных в ходе генерации документов. Реализация прототипов представлены на рисунках ниже: Рис. 1. Стартовый экран неавторизованного пользователя Рис. 2. Состояние экрана после загрузки документов  Рис. 3. Диалоговое окно с обучением пользования сервисом Рис. 4. Уведомления о ходе обработки документов Заключение В ходе исследования были выполнены все поставленные задачи: на основе анализа предметной области были сформулированы требования к веб интерфейсу для инструмента генерации протоколов и сводных ведомостей по результатам заседания ГЭК (минимизация количества кликов пользователя для реализации основного варианта использования приложения , наличие возможности загрузки пользовательских документов шаблонов, наличие уведомлений о состоянии системы), был создан прототип веб интерфейса, удовлетворяющий поставленным требованиям. В частности, в рамках прототипа предполагается, что для реализации основного варианта использования пользователю понадобится от 4 до 6 кликов, предусмотрена возможность загрузки пользователем как документов шаблонов, так и данных, на основе которых будет производиться генерация документов, предусмотрено наличие уведомлени й и маркеров прогресса, для предоставления полной информации о состоянии системы. 

: автоматическая проверка, python, sklearn, pandas, классификация, кластеризация Введение В течение каждого учебного года студенты в процессе обучения на специальностях, связанных с информационными технологиями, решают различные учебные задачи путем написания кода. Это порождает нехватку времени у преподавателей для проверки всех работ. В данной статье рассматривается проблема автоматизации проверк и работ студентов на курсе « Кластеризация, классификация и регрессия в scikit learn [3] ». Приводятся задачи на ключевые темы машинного обучения, представленных в названии курса , а также вводные з адачи для базовых навыков работы с python библиотекой Pandas [4] . Описаны алгоритмы автоматизированной проверки для реализованных заданий. Перечень технологий Для реализации и решения задач используется б иблиотека для машинного обучения scikit learn, написа нная на языке python, так же как и библиотеки pandas и numpy, используемые для анализа и предв арительной обработки данных. Задачи будут размещены в Moodle [6] . На данной платформе существует расширение «CodeRunner» [7] , позволяющее реализовывать задачи, треб ующие написание кода. Также, данный инструмент позволяет реализовывать собственные алгоритмы проверки задач. Именно поэтому для разработки заданий был выбран именно этот плагин. План курса Перед началом разработки заданий был составлен план будущего курса: 1. Обработка данных с помощью Pandas: a. Необходимая теория для решения задач b. Простые задачи i. у даление колонки ; ii. добавление колонки ; iii. у даление элементов таблицы по заданному условию c. Работа с DataFrame i. з агрузка данных в виде numpy массиво в; ii. с оздание объекта DataFrame; iii. конкатенация двух объектов DataFrame; iv. р асчет матрицы корреляции 2. Линейная регрессия a. н еобходимая теория для решения задачи b. загрузка данных, разделение на обучающую и тестовые выборки c. обучение модели 3. Логистическая регрессия a. необходимая теория для решения задачи b. загрузка данных c. разделение на обучающую и тестовые выборки d. обучение модели, предсказание 4. Кластеризация методом k средних a. необходимая теория для решения задачи b. загрузка данных c. обучение модели d. вывод результатов 5. Классификация с помощью Наивног о Байесовского алгоритма a. необходимая теория для решения задачи b. загрузка данных c. разделение на обучающую и тестовые выборки d. обучение модели e. вывод точности модели Описание реализации раздела «Предобработка данных с помощью Pandas В первом разделе представлена теория и задачи, требующие написания кода. Теоретическая выкладка содержит описание двух основных объектов в pandas, а именно: Series и DataFrame, описание некоторых методов и атрибутов этих объектов, а также функции для поиска данных в объект е DataFrame. При необходимости предлагается ознакомиться с официальной документацией библиотеки Pandas [4] . Задания в этом разделе нацелены на закрепление описанной выше теории, а также на выработку минимальных навыков для использования библиотеки Pandas [4] в будущих разделах курса. Раздел содержит следующие задачи: 1. Загрузка данных в .csv формате; 2. Преобразование массива в объект DataFrame; 3. Конкатенация двух объектов DataFrame; 4. Расчет матрицы корреляции; 5. Добавление колонки в DataFrame; 6. Удаление колонки; 7. У даление данных с пустыми строками из DataFrame. Описание реализации разделов «Линейная регрессия» и «Логистическая регрессия»  В данных разделах представлены теоретические материалы по одноименным темам и задачи, требующие написания кода с использованием библиотеки scikit learn [3] . Теория содержит как математическое описание алгоритмов Линейной и Логистической регрессии [1] , так и их использование в scikit learn [3] . Понимание устройства используемых алгоритмов  должно помочь студентам в применении уже готовы х реализаций и избежать многих ошибок. Практическая часть в этих разделах представлена как декомпозиция задачи обработки данных с использованием алгоритмов регрессии. Ее можно представить следующим образом, разбив на подзадачи: 1. Загрузка данных 2. Разделение д анных на обучающую и тестовую выборки 3. Обучение модели 4. Предсказание с помощью полученной модели Описание реализации разделов «Кластеризация методом k средних»  В разделе «Кластеризация методом k средних» аналогично предыдущим двух разделам представлены те оретические материалы с математическим описанием используемого алгоритма, а также практическая часть в виде нескольких связанных друг с другом задач, при этом в данном разделе разбивать данные на обучающую и тестовую выборки не нужно из за специфики рассма триваемого алгоритма. Пример задачи: «Необходимо обучить модель KMeans с числом кластеров 3, random_state=42, n_init="auto". В качестве ответа функция должна вернуть центры кластеров.» Описание реализации разделов «Классификация с помощью Наивного Байесовс кого алгоритма» В заключительном разделе «Классификация с помощью Наивного Байесовского алгоритма» теоретические материалы представляют собой математическое описание используемого алгоритма, а также обзор всех представленных в библиотеке scikit learn [3] об ъектов байесовских классификаторов. В практической части студенту предлагается на одних и тех же данных обучить каждую из существующих версий Байесовского классификатора [2] и определить наиболее подходящую. Пример задания в данном разделе: «Требуется обучи ть модель Гауссовского классификатора, выполнить предсказание с помощью полученной модели. В качестве ответа вернуть точность предсказанных данных.» Описание алгоритма проверки Проверка кода студентов осуществляется с использованием языка python и всех вышеперечисленных библиотек. При отправке кода студентом на проверку, запускается python скрипт, который создает файл prog.py, в него записываются используемые библиотеки, код студента и запуск сравнения результатов работы “эталонной функции” и функции, на писанной студентом. Если ответы совпадают, студент получает сообщение об успешном выполнении задачи, если нет, то скрипт вернет название функции, где ответ отличается от верного. На рисунке 1 представлена activity UML диаграмма, описывающая алгоритм провер ки задач CodeRunner. Рис. 1. UML диаграмма алгоритма проверки Заключение В данной статье был описан разработанный онлайн курс по теме “Кластеризация, классификация и регрессия в scikit learn”. Также был разработан алгоритм автоматизированной  проверки д ля этих задач на языке python. Дальнейшим развитием курса может быть расширение основной части курса путем добавления новых разделов с задачами для проверки знаний по другим областям машинного обучения, которые впоследствии могут потребовать изменения текущих алгоритмов проверки, что дает возможность для продолжения исследований в данном направлении. 

: система доменных имен, мониторинг, DNS, WHOIS. Введение В настоящее время мониторинг и учет доменных име н играют важную роль в процессе администрирования, так как с их помощью можно своевременно узнать о недоступности сайта по доменному имени или об окончании срока регистрации домена; обнаружить несанкционированные изменения регистрационной информации и ресу рсных записей доменных имен. Существующие решения для мониторинга и учета доменных имен реализованы на стороне регистраторов, поэтому пользователям для проверки состояния доменных имен приходится перемещаться от одного личного кабинета на сайте регистратора к другому. Таким образом, пользователи затрачивают непозволительно много времени и усилий для того, чтобы проанализировать текущее состояние зарегистрированных доменов. Кроме того, и меются решения, позволяющие пользователю отслеживать домены в рамках единой системы, но они либо являются платными, либо не поддерживают распределенный мониторинг. Цель данной работы: разработка серверной части веб приложения для распределенного мониторинг а изменений ресурсных записей и регистрационной информации доменных имен gTLD и ccTLD. Для достижения данной цели были поставлены следующие задачи: 1. Формирование критериев оценки существующих программных решений и их последующий сравнительный анализ. 2. Опреде ление необходимой функциональности разрабатываемой программной системы с учетом результатов сравнительного анализа. 3. Программная реализация системы. Обзор предметной области Для формирования требований к разрабатываемой программной системе мониторинга и уче та доменных имен были рассмотрены системы, обладающие следующей функциональностью: обнаружение изменений ресурсных записей DNS [1] и регистрационной информации доменов, ведение истории изменений с возможностью уведомления пользователей по крайней мере чере з один канал связи (почта, системы обмена сообщениями); уведомление о скором окончании срока регистрации доменов. Были проанализированы следующие решения, удовлетворяющие поставленным требованиям: ping admin [2], DomainTools [3], Odin [4], Domain Monitor [ 5], StatusCake [6]. В табл. 1 приведен сравнительный анализ существующих решений по следующим критериям: 1. Возможность размещения на собственной инфраструктуре ( self hosted ) : система должна предоставлять пользователям возможность самостоятельно развернуть си стему на своих серверах, чтобы не зависеть от каких либо внеш них сервисов. 2. Распределенный мониторинг : мониторинг необходимо производить из различных точек, поскольку обращение к серверам WHOIS [7] и DNS из одной точки может привести к получению неполной ил и недостоверной информации – некоторые сервера могут временно перестать работать или предоставлять неактуальную информацию. 3. Ведение истории изменений : для того, чтобы пользователь имел возможность просмотреть всю историю изменен ий информации о доменах, нео бходимо сохранять к аждый факт изменения информации. 4. Отсутствие оплаты : необходимо, чтобы система была бесплатной, так как если пользователь в какой то момент не оплатит услугу, то история изменении и другая сопутствующая информация могут быть утеряны. Таблица 1 Self hosted Распределенный мониторинг Ведение истории изменений Отсутствие оплаты ping admin + + DomainTools + + Odin + + Domain Monitor + + StatusCake + + По результатам сравненительного анализа можно сделать вывод о том , что ни один из аналогов не удовлетворяет всем необходимым критериям. Например, только один аналог дает возможность развернуть систему на собственной и нфраструктуре и является бесплатным. Также не все рассмотренные решения поддерживают распределенны й мониторинг и ведение истории изменени я информации о доменах. Выбор метода решения В резул ьтате обзора предметной области, определения перечня критериев, которым должно удовлетворять решение, и сравнения аналогов между собой по данным критериям можно сформулировать следующие требования к разрабатываемой программной сист еме:  возможность для пользователя самостоятельно разверну ть систему на рабочей станции (персональный компьютер или сервер) с ОС Linux и тем самым уменьшить зависимости от каких либо внешних сервисов;  поддержка распределенного мониторинга, чтобы система могла обращаться к сервисам WHOIS или DNS из географически р аспределенных точек и не зависеть от работоспосо бности конкретных серверов WHOIS или DNS и актуальнос ти предоставляемой ими информации;  решение должно обеспечивать ведение истории изменений регистрационной информации доменных имен, чтобы пользователь мог о тследить все факты изменения информации о домене;  открытый исходный код и отсутствие платы за использование . Описание метода решения Разработанная система представляет собой набор микросервисов: inspector и emitter . Высокоуровневая архитектура системы пред ставлена на рис. 1. Inspector – statefull сервис, который отвечает за инициацию процесса проверки доменных имен (проверка DNS серверов, регистрационной информации домена, обнаружение изменени я информации о домене и обновление информации о домене в хранилищ е данных), отправку уведомлени й и взаимодействие с базой данных. В нем периодически (время пери ода задается через конфигурационный файл) происходит чтение из базы данных всех доменов, информация о которых давно не обновлялась, и запускается процесс проверк и этих доменных имен. Проверка каждого доменного имени происходит параллельно, а не последовательно, что позволяет уменьшить общее время проверки всех доменов. Поскольку сервера WHOIS имеют ограничение на количество запросов за определенный промежуток врем ени (например, у WHOIS серверов для домена .RU оно составляет 120 запросов в минуту), нельзя выполнять параллельную проверку всех отслеживаемых доменов одновременно , так как при превышении лимита на количество или частоту запросов это может привести к ограничению доступа к WHOIS серверам (временно или навсегда) . Для решения данной проблемы использован шаблон конкурентного программирования worker pool , в котором создается определенное количество процессов ( worker ) и контейнер неогран иченного объема с необработанными задачами; каждый процесс по мере готовности берет задачу из контейнера и выполняет ее. Данный паттерн также используется при проверке синхронизации DNS серверов домена, чтобы ускорить скорость выполнения проверки. Таким о бразом ограничивается нагрузка на сервера WHOIS и DNS.  C ервис предоставляет RPC API, описанный в OpenAPI спецификации. Emitter – stateless сервис, который ответственен за взаимодействие с DNS и WHOIS серверами. Наличие данного сервиса позволяет выполнять р аспределенный мониторинг. Рис. 1. Высокоуровневая архитектура разработанной системы Оба сервиса разработаны на высокоуровневом языке программирования GoLang. Данный язык был выбран, поскольку он является компилируемым (скорость работы выше, чем у интерпр етируемых) и статически типизированным (системы, написанные на языках с такой типизацией, проще в поддержке). Также стоит отметить, что в GoLang присутствуют реализованные на уровне языка механизмы конкурентного программирования: горутины . Именно они испол ьзуются в inspector для распараллеливания процесса обновления доменов. В качестве СУБД выбран а PostreSQL, так как реляционная модель данных – универсальное решение, и в этой СУБД имеются надежные механизмы транзакции и репликации, также имеется поддержка с лабоструктурированных данных в формате JSON. Для удобного  развертывания системы выбран инструмент для контейнеризаций приложений Docker, который позволит пользователям без дополнительной настройки окружения запустить отдельные компоненты системы на рабочих станциях. Inspector и emitter взаимодействуют с помощью gRPC , который характеризуется высоким быстродействием и оптимален для организации микро сервисного взаимодействия. Балансировка нагрузки на сервис emitter выполнена на стороне сервиса inspector (клие нта). Это также можно сделать на стороне proxy сервера, но при этом добавится еще один сетевой узел на пути прохождения запроса. Исходный код приложения размещен на GitHub ( https://github.com/muratom/domain monitoring ). Заключение В ходе выполнения работы была достигнута поставленная цель – разработана серверная часть веб приложения для распределенного мониторинга изменени й ресурсных записей и регистрационной информации домен ных имен gTLD и ccTLD. Б ыли сформированы критерии оценки существующих программных решени й , после чего проведен сравнительный анализ аналогов по полученным критериям. По результатам сравнения была определена необходимая функциональность разрабатываемой сист емы. Разработанное решение успешно отслеживает изменения в информации о доменных именах, но система не имеет клиентской части и не отслеживает правильность настройки DNS серверов. Также в дальнейшем необходимо провести исследование времени работы системы и создаваемой ей нагрузки на процессор. 

: курс, парадигмы программирования, python Введение Проверка знаний студентов — это важная составляющая образова тельного процесса, которая помогает определить уровень понимания студентами учебного материала и их успеваемость. Но с каждым годом количество студентов увеличивается, что влечет за собой высокую нагрузку на преподавателей и вследствие этого понижение уров ня образования. Одним из способов решения проблемы автоматической проверки знаний может являться использование курса. В данной статье рассматривается проблема уменьшения участия преподавателей в проверке знаний студентов. Приводятся требования к курсу, а также приводится пример прототипа курса по теме «Парадигмы программирования на Python». Выбор метода решения В результате анализа существующих курсов [1 5] , затрагивающих тему «Парадигмы программирования на Python», были определены требования к разрабатывае мым заданиям и урокам курса: 1. Для практического закрепления усвоенного материала в курсе должны быть добавлены задачи на написание кода. У курса должно быть средство автоматической проверки заданий для экономии времени учащихся и преподавателей; 2. Курс должен быть структурирован, с постепенным вводом в рассматриваемую тему, начиная от функций и классов в Python. Условия задач и уроки должны быть понятны без дополнительной информации, отсутствующей в курсе; 3. Для полноценного понимания курса вся информация в нем должна быть изложена на русском языке; 4. Курс должен содержать информацию о различных парадигмах программирования, чтобы студент мог ориентироваться в них и выбирать наиболее подходящую к решаемой задаче; 5. Курс должен быть открыт для каждого студента, а также быть бесплатным. Разработанный курс будет в полной мере удовлетворять всем требованиям выше. Описание метода решения Для соответствия выявленным критериям, в прототипе курса будут представлены «объектно ориентированное программирование» и «функциональное программирование». После каждой рассмотренной темы в курсе будет 1 2 задания на написание кода. В первом задании студент ознакомится с реализацией представленной темы в Python, а во втором задании он должен будет применить полученные знания. Тем самым буде т поддерживаться структурированность курса и его ориентированность на новичков. Описание раздела «Функциональное программирование» Для введения в функциональное программирование необходимо предоставить информацию о функциях и генераторах в Python. Была сос тавлена следующая информация: «Функция — это фрагмент программного кода, который решает какую либо задачу. Его можно вызывать в любом месте основной программы. Функции помогают избегать дублирования кода при многократном его использовании. Генератор — это итерируемый объект, как список или кортеж. Он генерирует последовательность значений, которую можно перебрать. Эту последовательность можно использовать для итерации в цикле for, но нельзя проиндексировать (т. е. перебрать ее можно только один раз)». При н еобходимости в дополнении теоретических сведений предлагается воспользоваться официальной документацией языка Python [6][7] . В качестве условия задания для закрепления полученных знаний было сформулировано следующее: «Напишите функцию sum(), которая принима ет два аргумента и возвращает их сумму». «Реализуйте генератор fib(n), который принимает количество чисел Фибоначчи и генерирует их (начиная с 0). Также реализуйте функцию Solve(n), которая принимает количество чисел Фибоначчи и возвращает сумму первых n ч исел Фибоначчи». Далее для демонстрации реализации функционального программирования на Python было предложено рассмотреть lambda функцию. Был составлен следующий материал: «Небольшие анонимные функции могут быть созданы с помощью ключевого слова lambda. Ля мбда функции можно использовать везде, где требуются функциональные объекты. Как и при определении вложенных функций, лямбда функции могут ссылаться на переменные из содержащей их области». Для закрепления материала была предложена следующая задача: «Реали зуйте функцию SortMarks(), которая принимает список картежей вида ('Предмет', Оценка). Функция должна возвращать сортированный список по уменьшению оценки и по алфавитному порядку названия предмета. В SortMarks() должна использоваться lambda функция». Дале е для демонстрации реализации функционального программирования на Python было предложено рассмотреть часть встроенных функций. Были выбраны функции map, filter и any. По данным функциям был составлен следующий теоретический материал: «map() встроенная фу нкция, которая позволяет обрабатывать и преобразовывать все элементы в итерируемом объекте без использования явного цикла for. Функция map() полезна, когда необходимо применить функцию преобразования к каждому элементу в коллекции или в массиве и преобразо вать их в новый массив. Функция filter() возвращает итератор из тех элементов iterable, для которых функция имеет значение True. iterable может быть либо последовательностью, контейнером, поддерживающим итерацию, либо итератором. Если функция равна None, f ilter() выступает как функция идентификации, то есть удаляет все элементы iterable, которые являются False. Функция any возвращает True, если какой либо элемент итерируемого объекта (списка, генератора) имеет значение True. Если итерируемый объект пуст, возвращает значение False». При необходимости дополнить материал другими встроенными функциями Python, рекомендуется использовать официальную документацию [8] . В качестве задания на написание кода были предложены следующие задачи: «Реализуйте функцию Solve( ), которая принимает список строк. Функция должна преобразовать все строки в список строк, состоящих из одной буквы, и возвращать его. В Solve() должна присутствовать функция map()». «Дано два списка строк: text содержит текст, разбитый на список слов; b an_words содержит список запрещенный слов. Необходимо реализовать функцию Solve(), которая принимает text и ban_words. Функция возвращает строку, составленную из text и не содержащую запрещенные слова. В Solve() должна использоваться функция filter()». « Вам даны два генератора gen_1() и gen_2(), которые итерируются по некоторому списку чисел (списки равной длины). Необходимо реализовать функцию is_different(gen_1, gen_2), которая возвращает True, если списки не идентичны и наоборот. В функции is_different () необходимо использовать any()». Описание раздела «Объектно ориентированное программирование» Для введения в объектно ориентированное программирование необходимо предоставить информацию о классах в Python. Была составлена следующая информация: «Классы пр едоставляют средства объединения данных и функций. Создание нового класса создает новый тип объекта, позволяя создавать новые экземпляры этого типа. К каждому экземпляру класса могут быть прикреплены атрибуты для поддержания его состояния. Экземпляры класс а также могут иметь методы (определяемые его классом) для изменения его состояния. Также классы в Python поддерживают наследование. Выполнение определения производного класса происходит так же, как и для базового класса. Когда объект класса создается, базо вый класс запоминается. Это используется для разрешения ссылок на атрибуты: если запрошенный атрибут не найден в классе, поиск продолжается в базовом классе. Это правило применяется рекурсивно, если сам базовый класс является производным от какого либо дру гого класса». При необходимости в дополнении теоретических сведений предлагается воспользоваться официальной документацией языка Python [9] . Для закрепления полученных знаний были созданы следующие задания: «Создайте класс Solution, который при создании пол учает строку в виде римского числа (все буквы заглавные). Класс должен содержать метод to_int(), который будет возвращать int представление римского числа». «Создайте класс SortList, который наследуется от класса list. 

: автома тическая проверка, онлайн курс, Moodle , конечные автоматы, python . Введение В настоящее время для обучения широко применяются дистанционные курсы с автоматической проверкой, которые позволяют сократить время преподавателей на проверку и оценку знаний студентов. В данной статье рассматривается создание собственного онлайн курса на платформе Moodle [6] кафедры МО ЭВМ, который станет решением проблемы по организации средств автоматической проверки знаний студентов по теме «Конечные автоматы и формальные языки». Обзор предметной области Для формирования требований к разрабатываемому д истанционному курсу с автоматической проверк ой задач по теме «Конечные автомат ы и формальны е язык и» необходимо рассмотреть существующие и доступные системы автоматической проверки знаний, которые полностью или частично посвящены данной теме. Таким образом, для сравнения и формирования требований были взяты следующие аналоги: 1. Онлайн курс "Математика в тестировании дискретных систем" на платформе Stepik [1] . В курсе представлены видеолекции и система оценивания новых знаний и навыков, которая включает тестовые вопросы и тренажер, имитирующий процесс тестирования дискретной системы. 2. Онлайн курс "Введение в теоретическую информатику" на платформе Stepik [2] . В курсе представлены видеолекции и система оценивания новых знаний и навыков, которая включает тестовые во просы и задания, отправляемые на проверку, без автоматического выставления баллов. 3. Онлайн курс "Математическая логика и теория алгоритмов" на платформе Stepik [3] . В курсе представлены видеолекции и система оценивания новых знаний и навыков, которая включает тестовые вопросы и задания на программирование. 4. Онлайн курс "Theory of Automata | Theory of Computation & Formal Language" на платформе Udemy [4] . В курсе представлены видеолекции, статьи и тестовые вопросы. 5. Онлайн курс "Formal Language and Automata" на платформе Udemy [5] . В курсе представлены видеолекции и тестовые вопросы. Представленные выше аналоги сравнивались по пяти критериям: 1. Тестовые вопросы: наличие тестовых вопросов (открытых, закрытых, с несколькими вариантам и ответа) по теме "Конечные автоматы и формальные языки" в курсе и их количество. 2. Практические задания на программирование: наличие практических заданий на программирование в курсе и их количество. 3. Автоматическая проверка знаний: проверка заданий без участ ия преподавателя и с обратной связью в виде количества баллов, полученных за решение. 4. Доступность: прохождение курса бесплатно. 5. Русский язык: весь материал курса представлен на русском языке. Результаты сравнительного анализа аналогов представлены в таблице 1. Таблица 1 Сравнение аналогов Критерий Аналог Тестовые вопросы Практические задания на программирование Автоматическая проверка знаний Доступность Язык Онлайн курс "Математика в тестировании дискретных систем" [1] 54 + + + Онлайн курс "Введение в теоретическую информатику" [2] 26 + + + Онлайн курс "Математическая логика и теория алгоритмов" [3] 17 6 + + + Онлайн курс "Theory of Automata | Theory of Computation & Formal Language" [ 4 ] 11 + Онлайн курс "Formal Language and Automata" [ 5 ] 10 + + По результатам проведенного анализа аналогов были сделаны следующие выводы: 1. Все рассмотренные курсы подходят по двум критериям: «Тестовые вопросы» и «Автоматическая проверка знаний». 2. Только один из пяти онлайн курсов, а именно курс «Математическая логика и теория алгоритмов» [3] , удовлетворяет критерию «Практические задания на программирование». 3. Оба курса на платформе Udemy не удовлетворяют критерию «Русский язык», что может сделать их прохождение для студентов затруднительным. 4. Прохождение курса " Theory of Automata | Theory of Computation & Formal Language " [4] является платным, следовательно закрытым для части людей. Выбор метода решения На основе анализа существующих систем автоматической проверки знаний были сформулированы тр ебования к разрабатываемому дистанционному курсу: 1. Так как курс ориентирован на русскоговорящих студентов, то весь материал должен быть представлен на русском языке. 2. Прохождение курса должно быть бесплатным. 3. Все задания должны проверяться автоматически. 4. В курсе должны присутствовать задания на написание кода на языке программирования Python , решающего задачи по теме курса. 5. Весь материал курса должен соответствовать теме «Конечные автоматы и формальные языки». В качестве платформы для размещения онлайн кур са была выбрана платформа Moodle [6] кафедры МО ЭВМ. Данный выбор обусловлен тем, что вуз стремится к сокращению использования сторонних ресурсов и продвижению собственных. Описание метода решения На основе сформулированных выше требований был разработан дистанционный курс с автоматической проверкой задач по теме «Конечные автоматы и формальные языки» на платформе Moodle [6] . Онлайн курс был разбит на три раздела: «Конечные автоматы распознаватели», «Конечные автоматы и регулярные выражения» и «Конечные автоматы с магазинной памятью». Каждый раздел состоит из следующих элементов: 1. Лекция с теоретическим материалом по теме раздела. 2. Тест с вопросами для закрепления материала. 3. Вводное задание для трениров ки представления конечного автомата на языке программирования Python . 4. Задачи по теме раздела решением в виде написания кода на языке программирования Python . Платформа Moodle [6] предоставляет возможность выбора типа задания. Из предложенного списка для реш ения задач был выбран тип « CodeRunner » [7] , который проверяет код и позволяет настраивать шаблон для проверки для выбранного языка программирования. Автоматическая проверка задач на написание кода осуществляется с использованием python по следующему алгори тму: 1. Отправка студентом решения на проверку. 2. Сохранение решения студента в файл prog.py. 3. Генерация исходных данных ( тестов ) . 4. Сравнение результатов «эталона» и решения студента для всех сгенерированных тестов: 4.1 Запуск кода студента на заданных данных и сохранение результата работы программы. 4.2 Сохранение результата выполнения «эталона» для тех же исходных данных. 4.3 Сравнение полученных результатов. 4.4 Повторение пунктов 4.1 4.3. 5. Если все тесты прошли успешно, то студент получает уведомление о том, что задача ре шена верно, иначе выводятся сообщение о том, что задача решена неверно, и два теста, в которых ответ студента отличается от верного. Под «эталоном» в представленном алгоритме следует понимать одно из возможных решений проверяемой задачи на языке программир ования Python . Заключение В данной статье был проведен обзор существующих систем автоматической проверки знаний , н а основе которого были сформулированы требования к разрабатываемому дистанционному курсу . Также был описан реализован ный на платформе Moodle [6] онлайн курс по теме «Конечные автоматы и формальные языки» , включающий в себя теоретический материал, тестовые вопросы и задачи с разработанным шаблоном автоматической. В дальнейшем курс может быть дополнен новыми разделами и задачами по данной теме. П ри этом в шаблоне автоматической проверки нужно будет изменять только «эталон» и исходные данные для тестов. 

: ReactJS ,  JavaScript , веб разработка, э ффективность использования ReactJS . Введение Современный мир интернет технологий продолжает развиваться, и появляются новые инструменты, которые могут значительно упростить разработку сайтов и приложений. Одним из таких инструментов является ReactJS – библиотека JavaScript , предназначенная д ля создания пользовательских интерфейсов. В последнее время все больше компаний включают ReactJS в свой технологический стек, и это вызывает интерес к исследованию его эффективности. Преимущества ReactJS включают многократное использование компонентов в ко де и рендеринг с помощью сервера, что увеличивает скорость загрузки страницы. Инструмент веб разработки ReactJS В настоящее время к современным средствам веб разработки относятся Angular, Vue и ReactJS. Однако, у первых двух возможны проблемы совместимости при использовании разных библиотек, необходимость регулярного обновления и дополнительное время, затрачиваемое на настройку среды разработки . Поэтому ReactJS одно из лучших современных средств веб разработки, благодаря простоте и интуитивно понятному инте рфейсу, гибкой настройке и высокой производительности. Рис. 1. П риложение ReactJS React (иногда React.js или ReactJS) – JavaScript библиотека с открытым исходным кодом для разработки пользовательских интерфейсов [2] . React разрабатывается и поддерживается Facebook, Instagram и сообществом отдельных разработчиков и корпораций. React может использоваться для разработки одностраничных и мобильных сайтов и приложений. Его цель – предоставить высокую скорость разработки, простоту и масштабируемост ь . В процессе исследования были проанализированы основные преимущества и недос татки использования ReactJS, а также собственный опыт работы с React , позволяющие определить его эффективность. Достоинства использования ReactJS Одн о из основных преимуществ Rea ct JS – это возможность управлять состоянием приложения, используя только JavaScript, что упрощает разработку. Кроме того, библиотека предоставляет удобный интерфейс для работы с виртуальным DOM, что позволяет избежать ненужных перерисовок элементов страниц ы. DOM (Document Object Model) – это специальная древовидная структура, которая позволяет управлять HTML разметкой из JavaScript кода [1] . Управление обычно состоит из добавления и удаления элементов, изменения их стилей и содержимого. React JS позволяет ра ботать с кодом на JavaScript, что расширяет возможности программиста и дает ему свободу выбора инструментов. Менее заметным, но не менее важным является тот факт, что React JS позволяет создавать очень гибкую архитектуру приложения с минимальными затратами на работу. Использование React также упрощает поддержку приложения , благодаря уровню абстракции, с которым работает библиотека. Код приложения может быть скопирован и перенесен на другие технологии без особых трудностей. Такой уровень абстракции, который п редоставляет React, позволяет разделять компоненты на более мелкие и независимые части, что делает их переносимыми и повторно используемыми. Кроме того, благодаря использованию JSX, разметка компонентов также может быть перенесена или использована в других проектах. Это делает процесс масштабирования приложения гораздо более простым и эффективным. Недостатки использования ReactJS Однако, при использовании React JS можно столкнуться с недостатками или сложностями . Например, приложения могут стать громоздкими и сложными для поддержки, если в них будет большое количество вложенных к омпонентов. Кроме того, в React JS нет встроенной поддержки маршрутизации, поэтому для этого необходимо использовать сторонние библиотеки. Также начинающий разработчик может столкнут ься с трудностями в изучении. Кроме этого, некоторые функции являются неподдерживаемыми для ReactJS , которые доступны в других фреймворках. Эффективность использования ReactJS в веб разработке Несмотря на указанные выше недостатки, использование технологии ReactJS считается эффективной, и востребована она разработчиками самых разных уровней . Начинающие проектировщики сайтов часто используют ReactJS, благодаря его простоте, хорошей документации и большому количеству самоучителей и образовательных ресурсов. R eactJS также позволяет начинающим разработчикам легко создавать интерактивные и динамические пользовательские интерфейсы без необходимости использования сложных технологий, таких как jQuery. Однако специалисты с опытом часто используют ReactJS из за его мо щных возможностей и взаимодействия с другими технологиями и библиотеками. Он также обеспечивает высокую производительность, оптимизацию рендеринга и легкость поддержки больших масштабных приложений. Кроме того, ReactJS имеет большое сообщество разработчико в, которые активно помогает друг другу и делятся своим опытом. Эффективность веб разработки – это способность проекта достигать поставленных целей в условиях минимальных затрат. Она определяется комплексом факторов, таких как качество кода, скорость работы, производительность, надежность и удобство использования. Под эффективностью обычно понимают ряд показателей, которые можно измерить. Эффективность использования ReactJS характеризуется следующими показателями: 1. Быстрое время разработки – ReactJS име ет удобный и интуитивно понятный синтаксис, что позволяет разработчикам быстро создавать компоненты и простые пользовательские интерфейсы. Это уменьшает время разработки и снижает затраты на проект. 2. Высокая производительность – ReactJS использует виртуальн ый DOM для ускорения работы с интерфейсом, что позволяет избежать постоянной перерисовки всего документа. В результате, приложения на ReactJS работают быстро и плавно, даже при большом количестве пользователей. 3. Удобство масштабирования – ReactJS позволяет разработчикам создавать многокомпонентные веб приложения, которые легко масштабируются и модифицируются. Это упрощает процесс поддержки и развития приложения в будущем. 4. Кросс браузерная совместимость – ReactJS работает совместно со многими браузерами, что позволяет разработчикам создавать высококачественные веб приложения для любой аудитории. 5. Широкие возможности интеграции – ReactJS легко интегрируется с другими библиотеками и фреймворками, что позволяет использовать множество сторонних решений для создания более эффективных приложений. Опыт показал, что использование ReactJS может ускорить разраб отку веб приложений, повысить их производительность и сделать код более понятным и легким для поддержки [3] . Примеры использования библиотеки в различных проектах, таких как социальные сети, онлайн магазины и игровые платформы, подтверждают ее высокую эффективность. Заключение Результаты исследования подтве рждают, что использование React JS может быть эффективным при веб разработке [4] . Однако, перед выбором фреймворк а, необходимо учитывать его особенности и соответствие задачам. Несмотря на некоторые недостатки, React JS остается одним из наиболее популярных фреймворков и успешно применяется в веб разработке. В целом, React JS – это мощный инструмент, который может зн ачительно упростить веб разработку и ускорить её запуск. 

: Каузальная Байесовская машина, алгоритм машинного обучения, наборы данных, причинно с ледственная связь . Введение С развитием машинного обучения и искусственного интеллекта, все больше сфер человеческой деятельности получают новые возможности для автоматизации рутинных процессов. Однако, при принятии важных решений на основе результатов моделей машинного обучения, становится невозможным выявить причи н но следственную связь и понять, каким образом модель принимает решения. В связи с этим, возникает необходимость разработки программ для объяснения результатов модели машинного обучения. Одним из перспективных подходов является применение каузальной Байесовской машины, которая позволяет оценивать причинность и зависимость между различными переменными. В данной статье представляется про грамм а для объяснения результатов модели машинного обучения на основе каузальной Байесовской машины. Данная программа позволяет  сделать выводы о причинно следственной связи между переменными и определить влияние каждой переменной на результат модели. Прогр амма предполагает применение в различных областях, таких как медицина, экономика, инженерия и другие. Например, в медицинской сфере, она может быть применена для определения факторов, которые повышают риск конкретны х заболевани й . В статье [1] было показано , что при использовании каузального искусственного интеллекта к оличество ошибочных диагнозов, посчитанное моделью в процессе работы, будет меньше на 30% при k > 5 (где k максимальная ошибка алгоритм а), чем при обработке аналогичными инструментами, не исп ользующих причинно следственный вывод. Таким образом, разработка программы для объяснения результатов модели машинного обучения на основе каузальной Байесовской машины является актуальной задачей для научного сообщества, которая может существенно улучшить понимание работы моделей машинного обучения и повысить достоверность принятых на их основе решений. Перечень используемых технологий Разработанный инструмент состоит из двух частей: из сервера и пользовательского интерфейса. Сервер реализован с помощью язы ка программирования Python [ 2]. Python был выбран, поскольку он обладает широкой совместимостью, а также, на нем уже реализованы библиотеки, содержащие необходимые инструменты для программирования алгоритма объяснения результатов модели машинного обучения. Сервер использует следующие библиотеки Python: NumPy [ 3] для выполнения численных операций, в том числе линейной алгебры, Scikit Learn [ 4 ] для выполнени я статистических операций, таких как, например, вычисление корреляции , библиотека Causal Ai [ 8 ] для выполнения операций, связанных с выполнением причинно следственного вывода. В данном случае, CausalAi применяется для построения причинно следственного графа и вычисления причинно следственного вывода. Для организации передачи данных между сервером и п ользовательским интерфейсом был использован Flask [19] . Пользовательский интерфейс реализован в виде web сайта на языке программирования JavaScript [ 9 ] с использованием React [ 10]. Р а з работка пользовательского интерфейса в виде web сайта была выбрана, поск ольку это даёт кроссплатформенность. JavaScript с использованием React был выбран для разработки пользовательского интерфейса, поскольку React использует Virtual DOM, а это уменьшает количество операций и повышает производительность [ 10]. Для визуализации причинно следственного графа была использована библиотека React cytoscapejs [20] . Входным и значени ями для разрабатываемого инструмента явля ю тся : т абличный набор данных в формате CSV [1 1 ] и значения Target Variable , Treatment Variables , Condition Variables , используемые для вычисления причинно следственного вывода . Подробное описание и назначение каждого из описанных раннее значений представлено в пункте “ Описание вычисления причинно следственного вывода ” . Выходными значениями являются: п оказатель Estimate A TE [1 2 ] , предполагающий результат причинно следственного вмешательства , а также отражающий влияние на в ходной набор данных в процентах и п ричинно следственный граф [1 3 ] . Описание работы инструмента Разработанный инструмент состоит из двух частей: из сервер а и пользовательского интерфейса.  На пользовательском интерфейсе осуществляется загрузка табличного набора данных в формате CSV и ввод значений Target Variable , Treatment Variables , Condition Variables для последующей отправки на сервер. Заполненные поля приводятся к формату JSON [1 4 ] , вид которого показан на рисунке 1: Рис. 1 Набор данных в JSON формате На сервере, в свою очередь осуществляется обработка полученного JSON объекта с использованием пос троения причинно следственного графа, а также вычисление значения Estimate ATE . Данные функции были использованы посредством библиотеки CausalAi [ 8 ] . После выполнения соответствующих операций, сервер отправляет причинно следственный граф и Estimate ATE на пользовательский интерфейс. Пользовательский интерфейс принимает причинно следственн ый граф и значение Estimate ATE, которые в свою очередь графически отображает. Графическое отображение полученных переменных представлено на рисунке 2: Рис. 2 Результ ат ответа сервера Описание построения причинно следственного графа Алгоритм PC является одним из алгоритмов построения причинно следственного графа в каузальной Байесовской машине. Он основан на идее о том, что если две переменные X и Y независимы при условии набора переменных Z, то между X и Y нет причинно следст венной связи [ 1 5]. Для построения причинно следственного графа дл я каузальной Байесовской  машины определ яются вершины и дуги графа. Вершины соответствуют переменным, влияющим на другие переменн ые, а дуги направленным связям между этими переменными. Поскольку входным значением разрабатываемого инструмента является табличный набор данных в формате CSV , вершинами причинно следственного графа являются столбцы входного набора данных. Далее, вычисля ется коэффициент корреляции, если он достаточно большой, предполагается что между переменными имеется причинно следственная связь . В разработанном инструменте используется алгоритм PC, при котором корреляция меж ду двумя переменными, а также существование о бщих соседей этих переменных в графе будут свидетельствовать о наличии скрытой переменной, которая будет предполагать наличие причинно следственной связи. Далее, происходит удаление ненужных связей из графа, а также уточнение направлений дуг между узлами, после чего построение причинно следственного графа завершается. Описание вычисления причинно следственного вывода Причинно следственное вмешательство используется для оценки эффекта воздействия на целевую переменную при наличии других факторов, которые могут влиять на результат [1 6 ] . Для проведения причинно следственного вмешательства производится деление табличного входного набора данных случайным обра зом на две группы, именуемые следующим образом: Control Group и Treatment Group. Control Group не изменяется, а на Treatment Group оказывается воздействие [1 7 ] . Осуществляется выбор Target Variable , Treatment s Variable , Condition Variables . Target Variable является целевой переменной исследования . Treatment Variable s и Condition V ariable s это переменные , которые могут влиять на Target Variable . Treatment Variable это переменная, которая изменяется для Treatment Group, но не изменяется для Control Group . Condition V ariable это переменная, которая не изменяется для обеих групп, при этом оказывает воздействие на Target Variable. Treatment Value и Condition Value являются значениями для переменных Treatment Variable и Condition V ariable , соответствен но. Далее , происходит обработка Treatment Group методом машинного обучения MLP Regression [1 8 ] , с учётом Target Variable , Treatment Variable s , Condition Variable s . П ричинно следственн ым в ыводом явля ется оценка эффекта воздействия Estimate ATE в процентах, которая описывает разницу между средним и значени ями исходов в Treatment Group и Control Group. Заключение В ходе выполнения исследования был разработан инструмент для объяснения результатов модели машинного обучения на основе каузальной Байесовской машины. В статье описана актуальность данного инструмента, перечень используемых им технологий, а также принцип е го работы. В дальнейшем, будет проведено улучшение разработанного инструмента, путём добавления дополнительных методов машинного обучения для построения причинно следственного графа. Кроме того, будет произведен анализ, касающийся уменьшения потребления па мяти и алгоритмической сложности работы инструмента . 

: солн ечный ветер, МГД моделирование, прогноз космической погоды Введение Солнечным ветром называют поток плазмы, исходящий от солнечной короны в космос. Моделирование солнечного ветра является важной задачей, т.к. он может провоцировать сбои радиосвязи и навигации, вызывать магнитные бури на Земле, а также представлять опасность для космонавтов в открытом космосе. Моделируя поведение солнечного ветра на несколько суток вперед, можно спрогнозировать возможные опасности и прин ять меры для их предотвращения. В США прогнозированием занимается Центр прогноза космической погоды в составе Национального управления океанических и атмосферных исследований (Space Weather Prediction Center, NOAA SWPC) [1]. В SWPC используется трёхмерная МГД модель солнечного ветра ENLIL [2]. В России подобная служба разработана под руководством Горной астрономический станции  (ГАС ГАО) [3], однако она основана на кинетической модели [4] , которая признана менее точной. МГД уравнения Используя уравнения маг нитной гидродинамики (МГД), можно моделировать движение солнечной плазмы подобно движению жидкости. В ENLIL для решения системы МГД уравнений, используется метод уменьшения полной вариации с разностной схемой Лакса Фридрихса [5]. Код программы моделировани я не опубликован в открытом доступе. В данной работе разработана программа, реализующая функциональность ENLIL . Она включает в себя библиотеку PLUTO [6], которая предоставляет численные методы решения систем уравнений в частных производных, в т. ч. для нес кольких видов МГД уравнений. Граничные условия Эмпирическая модель Wang Sheeley Arge [7] (WSA) используется для расчета внутренних граничных условий для МГД уравнений. Входными данными модели WSA является синоптическая карта магнитограммы Солнца. Результа том моделирования являются корональные карты (граничные условия) скорости частиц и напряженности магнитного поля на границе внешней короны (5 Rs), которые затем экстраполируются до границ моделирования (22.5 Rs). В настоящей работе используются граничные у словия, рассчитанные с помощью WSA 2.2 на основе магнитограмм сети обсерваторий GONG [8], регулярно выгружаемые с сайта NOAA. Архитектура службы На Рис. 1 изображена схема связи модулей разработанной службы. Рис. 1. Иллюстрация взаимодействия компонент службы ● Модуль регулярного получения граничных условий Данный модуль реализован в виде скрипта на языке Python, который ежесуточно запрашивает данные с веб сайта NOAA. ● Модуль запуска PLUTO На вход подаются выгруженные граничные условия, представленные в фо рмате NetCDF и обрабатываются библиотекой netcdf c. Как только данные будут получены, запускается МГД моделирование PLUTO, поддерживающее распараллеливание вычислений с помощью интерфейса передачи сообщений (Message Passing Interface, MPI). Результатом мо делирования являются трёхмерные карты плотности и скорости частиц на дискретной сетке размера 512х60х180 в виде 121 файла в формате *.dbl, сгенерированные на каждый час для 5 суток симуляции. Модуль реализован на языке C для совместимости c кодом PLUTO. ● Модуль генерации графического отображения модели Полученные трёхмерные карты скорости и плотности солнечного ветра преобразуются в двумерный срез в плоскости, параллельной плоскости солнечного экватора и пересекающей Землю и срез в плоскости YZ СК HEEQ мет одом трилинейной интерполяции. Для формирования изображений с полученными срезами и дополнительной информацией о параметрах солнечного ветра используется библиотека двумерной графики Cairo [9], под держивающая возможность отрисовки без создания окна, что уд обно при запуске на сервере, не имеющем устройства для вывода графической информации. При расчёте на 6 ядрах процессора AMD EPYC 7742 симуляция на 5 суток занимает 278 минут. ● Веб сайт Построенные изображения конвертируются с помощью пакета FFmpeg в видеоф айл формата mp4 с передачей информации о количестве кадров в секунду, который затем передается на разработанный веб сайт прогноза солнечного ветра [10]. Большинство браузеров поддерживают свойство currentTime элемента <video>, что при наличии информации о количестве кадров в секунду, позволяет реализовать покадровое перемещение по видео. Таким образом на сайте реализована полоса прокрутки для выбора отдельных кадров из видеофайла. Данный подход достаточно эффективен, так как представляет возможность просмот ра прогноза на каждый час без необходимости передавать отдельные изображения. Объем данных, передаваемых на клиентскую систему, составляет около 1.5 Мбайт для 5 суток моделирования. Анализ результатов моделирования Для сравнения результатов использовалась следующая метрика: 푀 ( 푥 푝푙푢푡표 , 푦 ) = 푀퐴퐸 ( 푥 푝푙푢푡표 , 푦 ) / 푚푒푎푛 ( 푥 푝푙푢푡표 ) , где 푥 — значения скорости/плотности результатов PLUTO, а 푦 — результатов SWPC/CCMC. Было проведено сравнение построенных карт с архивными данными аналогичной службы S WPC (рис. 2a), где 푀 ( 푣 푝푙푢푡표 , 푣 푠푤푝푐 ) = 3 . 7% , а 푀 ( 휌 푝푙푢푡표 , 휌 푠푤푝푐 ) = 14 . 3% . Сравнение с результатом службой удаленного запуска алгоритмов моделирования космической погоды с пользовательскими параметрами CCMC [11] (рис. 2b) показало 푀 ( 푣 푝 푙 푢푡표 , 푣 푐푐푚푐 ) = 11 . 2% и 푀 ( 휌 푝푙푢푡표 , 휌 푐푐푚푐 ) = 32 . 4% . Сравнение с данными о скорости и плотности солнечного ветра вблизи Земли, собираемыми космическими аппаратами Ace и Wind, предоставляемыми службой OMNI [12] представлено на рис. 3. Рис. 2 . Карты скорости и плотности солнечного ветра в (a, слева) PLUTO (сверху) и SWPC (снизу) и в (b, справа) PLUTO (сверху) и CCMC (снизу). Рис. 3. Графики плотности и скорости солнечного ветра вблизи Земли. Заключение Был разработан прототип службы регулярн ого прогнозирования солнечного ветра по трехмерной МГД модели на основе математического пакета PLUTO. Ежедневно обновляемые прогнозы на 5 суток демонстрируются на сайте [1 0 ]. Полученные карты солнечного ветра в целом соответствуют зарубежным аналогам при о динаковых граничных условиях моделирования. Неточности результатов могут возникать из за различий в реализациях математически эквивалентных МГД уравнений и численных схем. В качестве дальнейшего развития работы планируется добавить моделирование корональны х выбросов массы и учитывание дополнительных эффектов при моделировании. Так же с помощью наблюдательных данных [13] Кисловодской ГАС планируется рассчитывать собственные граничные условия для создания полностью независимой службы. 

: машинное обучение, алгоритмы сортировки, идентификация алгоритмов Введение В настоящее время в образовательных целях широко применяются онлайн курсы с автоматизированной проверкой реализованных алгоритмов. Простые автоматизированные проверки заключаются в сравнени и результата работы реализованного студентом алгоритма с эталонным результатом . Данный подход не проверяет, был ли реализован требуемый алгоритм для решения задачи. Для решения одной и той же задачи может существ овать множество различных алгоритмов, одной из таких задач является задача сортировки данных. Программная система для иден тификации алгоритма сортировки позволит автоматизировать процесс проверки заданий, обеспечивая при этом реализацию требуемого алгоритма сортировки. Существует несколько подходов к решению задачи идентификации алгоритмов сортировки. В статье [1] описываетс я подход, основанный на использовании дерева принятия решений для классификации реализаций. В статье [2] авторы предлагают подход, основанный на использовании свёрточной нейронной сети. В данной статье описывается и оценивается программная система для иден тификации алгоритмов сортировки по программному коду, основанная на получении характеристик реализации и использовании метода случайного леса для классификации. Для обучения модели был составлен набор данных, состоящий из реализаций различных алгоритмов со ртировки на языке программирования Python . Сбор характеристик реализации Первым шагом в работе программной системы является получение характеристик реализации, по которым будет проводиться идентификация. Были выбраны характеристики, которые не зависят от я зыка реализации алгоритма сортировки. Данное свойство характеристик позволит в дальнейшем использовать модель для идентификации реализаций на любом языке программирования. На данный момент программная система осуществляет сбор характеристик только для реал изаций на языке программирования Python . Получаемые характеристики алгоритма сортировки можно разделить на две категории : характеристики производительности и синтаксические характеристики. Характеристики производительности – характеристики, которые получа ются во время работы реализации. К характеристикам производительности относятся : 55 1. Количество сравнений между элементами при сортировке различных наборов данных ; 2. Стабильность алгоритма сортировки. Синтаксические характеристики – характеристики, которые получаются при анализе абстрактного синтаксического дерева реализации. Абстрактное синтаксическое дерево — конечное помеченное ориентированное дерево, в котором внутренние вершины сопоставлены с операторами языка программирования, а листья — с соответствую щими операндами. К синтаксическим характеристикам относятся : 1. Рекурсивность ; 2. Количество циклов ; 3. Количество вложенных циклов. Для получения характеристик производительности и синтаксических характеристик были реализованы два класса : PerformanceAnalyzer и S yntaxAnalyzer . PerformanceAnalyser использует класс Element . Element подсчитывает количество сравнений, произведённых над экземплярами класса. Также каждый экземпляр класса Element хранит своё изначальное положение в массиве данных для проверки стабильност и алгоритма сортировки. SyntaxAnalyzer использует классы RecursiveFunctionsFinder и CycleCounter для нахождения рекурсивных функций и подсчёта циклов соответственно. Данные классы наследуются от класса NodeVisitor из стандартной библиотеки ast для работы с абстрактными синтаксическими деревьями в языке Python . UML диаграмма классов представлена на рис. 1. Рис. 1. UML диаграмма классов программной системы Пример полученных программной системой характеристик производительности представлен в т абл. 1. Пример полученных программной системой синтаксических характеристик представлен в табл. 2. Таблица 1 Пример полученных характеристик производительности Алгоритм Количество сравнений Стабильность Упорядоченные данные Обратно упорядоченные данные Перемешанные данные Почти упорядоченные данные Bubble sort 5049 5049 5049 5049 + Selection sort 5049 5049 5049 5049 Insertion sort 198 5049 2899 251 + Merge sort 415 455 643 448 + Quicksort 5049 5049 719 3213 Timsort 296 297 1831 2006 + Таблица 2 Пример полученных синтаксических характеристик Алгоритм Рекурсивность Количество циклов Количество вложенных циклов Bubble sort 2 1 Selection sort 2 1 Insertion sort 2 1 Merge sort + 3 0 Quicksort + 2 0 Timsort 11 2 Метод случайного леса Полученные признаки реализации классифицируются при помощи метода случайного леса [ 3 ] . В основе метода случайного леса лежит использовани е деревьев принятия решений. Дерево принятия решений представляет собой древовидную структуру, где каж дый внутренний узел обозначает проверку признака , каждая ветвь представляет результат проверки, каждый конечный узел содержит метку класса , которая является результатом классификации . Обучение дерева заключается в пошаговом разделении исходной выборки на подмножества . Выбор разбиения осуществляется на основе определённой метрики. В данной работе в качестве метрики используется критерий Джини, который отражает, насколько часто случайно выбранный элемент из набора неверно помечается . На каждом шаге построени я дерева выбирается разбиение, которое минимизирует критерий Джини. Разбиение на подмножества повторяется, пока каждое из подмножеств не состоит из объектов одного класса, или пока не достигнута заданная максимальная глубина дерева. Метод случайного леса з аключается в использовании ансамбля из деревьев принятия решений. Классификация объектов проводится путём голосования деревьев. Выбор в пользу метода случайного леса в качестве классификатора был сделан из за большого количества получаемых характеристик. П ри использовании одиночного дерева принятия решений задействования всех характеристик можно достичь путём увеличения максимальной глубины дерева. Но увеличение значения глубины дерева приводит к переобучению модели. Метод случайного леса в свою очередь с по соб ен эффективно обрабатывать данные с большим числом признаков и классов . Полученные результаты Для обучения модели был составлен набор данных [ 4 ] из реализаций алгоритмов сортировки на языке программирования Python , которые были опубликованы на платформе GitHub . Для оценки модели была использована k блочная кросс валидация с количеством блоков равным 5. k блочная кросс валидация заключается в разбиении выборки на k блоков. На каждом шаге валидации один из блоков явл яется тестовой выборкой, остальные блоки составляют обучающую выборку. Оценка точности была повторно проведена 20 раз. В результате среднее значение точности идентификации составило 96%. Заключение В данной статье была описана и оценена программная система для идентификации алгоритмов сортировки по программному коду. Программная система извлекает характеристики программного кода и использует метод случайного леса для классификации. Средняя точность идентификации составила 96 %. Отличительной особенностью про граммной системы является использование для идентификации характеристик, которые не зависят от языка реализации. Разработанная программная система может быть использована для автоматизированной проверки работ студентов. Исходный код представлен в репозитор ии проекта на платформе GitHub [5]. В дальнейшей работе над программной системой планируется модификация программной системы для работы с образовательной платформой Moodle и оценка точности системы на работах студентов. 